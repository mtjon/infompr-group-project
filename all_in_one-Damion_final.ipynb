{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+LiT8tvvCL1/M9GhJP8VW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtjon/infompr-group-project/blob/all_in_one/all_in_one-Damion_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this notebook elemets were taken from:\n",
        "1. https://www.tensorflow.org/text/tutorials/nmt_with_attention, and;\n",
        "2. https://www.tensorflow.org/text/tutorials/transformer\n",
        "\n",
        "For the RNN + GRU, bi-directional layer was removed. For the transformer, all sub-classing has been copied, as well as custom learning schedule.\n",
        "\n",
        "Data-preprocessing has been adopted to fit the dataset used, which can be found here:\n",
        "- Data loading: https://github.com/EagleW/Writing-editing-Network/blob/master/split_data.py\n",
        "- Dataset: https://github.com/EagleW/ACL_titles_abstracts_dataset\n",
        "\n",
        "We've manually adjusted the dataset to remove the empty rows between title-abstract pairs, and adjusted the data loading code to work with the changes accordingly."
      ],
      "metadata": {
        "id": "Q7k2Rb8uLP14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing and loading Required packages"
      ],
      "metadata": {
        "id": "YIdpCzRxMTLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the most re version of TensorFlow to use the improved\n",
        "# masking support for `tf.keras.layers.MultiHeadAttention`.\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q -U tensorflow-text==2.11.* tensorflow==2.11.*\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "S-xUpwPLMTBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2749cb-c338-49db-c73e-798a8a3a4c99"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcudnn8 is already the newest version (8.1.0.77-1+cuda11.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n",
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping keras as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-estimator as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-text as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "# For data loading and shuffling\n",
        "import random\n",
        "from random import shuffle\n",
        "\n",
        "# for shape checking -> used in RNN and GRU, see class below\n",
        "import einops"
      ],
      "metadata": {
        "id": "Uy5TSM4NMeVX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "metadata": {
        "id": "bR5vmAK5Msbc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "acobDY2eMGRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "TMkQ7LwANOOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modified data externally to remove all blank lines\n",
        "random.seed(42)\n",
        "def write_data(f, ext, mod):\n",
        "    # Code van https://github.com/EagleW/Writing-editing-Network/blob/master/split_data.py\n",
        "    file1=open(f, 'r')\n",
        "    lines=file1.readlines()\n",
        "    print(len(lines))\n",
        "    file1.close()\n",
        "    abs_t = []\n",
        "    abstracts = []\n",
        "    titles = []\n",
        "    i = 0\n",
        "    # TODO: possibly generates wrong tibs/abs when encounter\n",
        "    for line in lines:\n",
        "        if i % mod == 0:\n",
        "            titles.append(line)\n",
        "        elif i % mod == 1:\n",
        "            abstracts.append(line)\n",
        "        i += 1\n",
        "    for i in range(len(abstracts)):\n",
        "        if len(titles[i]) > 0 and len(abstracts[i]) > 0:\n",
        "            h_a_pair = (titles[i], abstracts[i])\n",
        "            abs_t.append(h_a_pair)\n",
        "    shuffle(abs_t)\n",
        "    total = len(abs_t)\n",
        "    dev = total//10\n",
        "    train  = total - dev - dev\n",
        "    i = 0\n",
        "    file1=open(\"val{}.txt\".format(ext), 'w')\n",
        "    for i in range(dev):\n",
        "        file1.writelines(abs_t[i][0])\n",
        "        file1.writelines(abs_t[i][1])\n",
        "    #    file1.writelines(\"\\n\")\n",
        "    file1.close()\n",
        "    file1=open(\"test{}.txt\".format(ext), 'w')\n",
        "    for i in range(dev, 2 * dev):\n",
        "        file1.writelines(abs_t[i][0])\n",
        "        file1.writelines(abs_t[i][1])\n",
        "    #    file1.writelines(\"\\n\")\n",
        "    file1.close()\n",
        "    file1=open(\"train{}.txt\".format(ext), 'w')\n",
        "    for i in range(2 * dev, total):\n",
        "        file1.writelines(abs_t[i][0])\n",
        "        file1.writelines(abs_t[i][1])\n",
        "    #    file1.writelines(\"\\n\")\n",
        "    file1.close()\n",
        "\n",
        "def get_abs_and_titles_from_raw(path_to_file):\n",
        "    abstracts, titles = [], []\n",
        "    abscount, titcount = 0, 0\n",
        "    with open(path_to_file) as data:\n",
        "        lines = data.readlines()\n",
        "        print(len(lines))\n",
        "        for abs in lines[1::2]:\n",
        "            abstracts.append(abs.strip())\n",
        "            abscount += 1\n",
        "        for title in lines[0::2]:\n",
        "            # // TODO: check if we need to add start and end tokens\n",
        "            titles.append(title.strip())\n",
        "            titcount+=1\n",
        "            # titles.append('[START] ' + title.strip() + ' [END]')\n",
        "    print(abscount, titcount)\n",
        "    # print(titles[-1],'\\n',titles[-2])\n",
        "    return abstracts, titles"
      ],
      "metadata": {
        "id": "7jhRoUQrMHwf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data\n",
        "\n",
        "Make sure to have the modified dataset uploaden (i.e., ACL title+abs data set with empty rows removed).\n",
        "\n",
        "### Writing and loading text files"
      ],
      "metadata": {
        "id": "ph95j8o-NRHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "write_data(\"acl_titles_and_abstracts_mod.txt\", \"\", 2) # writes train, val, test.txt"
      ],
      "metadata": {
        "id": "WYrrf-LoMH40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fb54ef-038d-4242-ff83-9c1443c10064"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, train_labels = get_abs_and_titles_from_raw('train.txt')\n",
        "val_text, val_labels = get_abs_and_titles_from_raw('val.txt')\n",
        "test_text, test_labels = get_abs_and_titles_from_raw('test.txt')"
      ],
      "metadata": {
        "id": "yKWdenZIMIAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957e3f81-0c4b-43c7-9ef5-efae31467970"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17402\n",
            "8701 8701\n",
            "2174\n",
            "1087 1087\n",
            "2174\n",
            "1087 1087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity checks"
      ],
      "metadata": {
        "id": "nhYaxPDwMIJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels[0])\n",
        "print(train_text[0])"
      ],
      "metadata": {
        "id": "Hvc13xoNMIhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1477d065-9c58-457e-bba6-7b4c77e5b1ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heideltime : tuning english and developing spanish resources\n",
            "in this paper , we describe our participation in the tempeval-3 challenge . with our multilingual temporal tagger heideltime , we addressed task a , the extraction and normalization of temporal expressions for english and spanish . exploiting heideltimes strict separation between source code and languagedependent parts , we tuned heideltimes existing english resources and developed new spanish resources . for both languages , we achieved the best results among all participants for task a , the combination of extraction and normalization . both the improved english and the new spanish resources are publicly available with heideltime .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_labels[0])\n",
        "print(val_text[0])"
      ],
      "metadata": {
        "id": "jU9dcSVdMIpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2969d1-42ab-4f4d-8d31-04ac52347637"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computational analysis to explore authors depiction of characters cecilia ovesdotter alm\n",
            "this study involves automatically identifying the sociolinguistic characteristics of fictional characters in plays by analyzing their written speech . we discuss three binary classification problems : predicting the characters gender ( male vs. female ) , age ( young vs. old ) , and socioeconomic standing ( upper-middle class vs. lower class ) . the text corpus used is an annotated collection of august strindberg and henrik ibsen plays , translated into english , which are in the public domain . these playwrights were chosen for their known attention to relevant socioeconomic issues in their work . linguistic and textual cues are extracted from the characters lines ( turns ) for modeling purposes . we report on the dataset as well as the performance and important features when predicting each of the sociolinguistic characteristics , comparing intra- and inter-author testing .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[0])\n",
        "print(test_text[0])"
      ],
      "metadata": {
        "id": "87huQf8NMIxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc467798-7229-4ef7-d4e0-95ea83e6cac7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recognizing named entities in tweets\n",
            "the challenges of named entities recognition ( ner ) for tweets lie in the insufficient information in a tweet and the unavailability of training data . we propose to combine a k-nearest neighbors ( knn ) classifier with a linear conditional random fields ( crf ) model under a semi-supervised learning framework to tackle these challenges . the knn based classifier conducts pre-labeling to collect global coarse evidence across tweets while the crf model conducts sequential labeling to capture fine-grained information encoded in a tweet . the semi-supervised learning plus the gazetteers alleviate the lack of training data . extensive experiments show the advantages of our method over the baselines as well as the effectiveness of knn and semisupervised learning .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batching"
      ],
      "metadata": {
        "id": "GEYzfYsdMI4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_text, train_labels)).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_text, val_labels)).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_text, test_labels)).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Xz5sFZzTMJI5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for abs, tit in train_dataset.take(1):\n",
        "    print('> Abstract examples:')\n",
        "    for i, a in enumerate(abs.numpy()):\n",
        "        print(i+1, a.decode('utf-8'))\n",
        "        \n",
        "    print()\n",
        "    \n",
        "    print('> Title examples:')\n",
        "    for i, t in enumerate(tit.numpy()):\n",
        "        print(i+1, t.decode('utf-8'))\n",
        "    \n",
        "    counter += 1\n",
        "    if counter == 10:\n",
        "        break"
      ],
      "metadata": {
        "id": "oMAJuyKRMJPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd58a832-8150-45a6-83ad-d09695846bbd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Abstract examples:\n",
            "1 in this paper , we describe our participation in the tempeval-3 challenge . with our multilingual temporal tagger heideltime , we addressed task a , the extraction and normalization of temporal expressions for english and spanish . exploiting heideltimes strict separation between source code and languagedependent parts , we tuned heideltimes existing english resources and developed new spanish resources . for both languages , we achieved the best results among all participants for task a , the combination of extraction and normalization . both the improved english and the new spanish resources are publicly available with heideltime .\n",
            "2 we present three novel methods of compactly storing very large n-gram language models . these methods use substantially less space than all known approaches and allow n-gram probabilities or counts to be retrieved in constant time , at speeds comparable to modern language modeling toolkits . our basic approach generates an explicit minimal perfect hash function , that maps all n-grams in a model to distinct integers to enable storage of associated values . extensions of this approach exploit distributional characteristics of n-gram data to reduce storage costs , including variable length coding of values and the use of tiered structures that partition the data for more efficient storage . we apply our approach to storing the full google web1t n-gram set and all 1-to-5 grams of the gigaword newswire corpus . for the 1.5 billion n-grams of gigaword , for example , we can store full count information at a cost of 1.66 bytes per n-gram ( around 30 % of the cost when using the current stateof-the-art approach ) , or quantized counts for 1.41 bytes per n-gram . for applications that are tolerant of a certain class of relatively innocuous errors ( where unseen n-grams may be accepted as rare n-grams ) , we can reduce the latter cost to below 1 byte per n-gram .\n",
            "3 a poll consists of a question and a set of predefined answers from which voters can select . we present the new problem of vote prediction on comments , which involves determining which of these answers a voter selected given a comment she wrote after voting . to address this task , we exploit not only the information extracted from the comments but also extra-textual information such as user demographic information and inter-comment constraints . in an evaluation involving nearly one million comments collected from the popular sodahead social polling website , we show that a vote prediction system that exploits only textual information can be improved significantly when extended with extra-textual information .\n",
            "4 this paper examines two problems in document-level sentiment analysis : ( 1 ) determining whether a given document is a review or not , and ( 2 ) classifying the polarity of a review as positive or negative . we first demonstrate that review identification can be performed with high accuracy using only unigrams as features . we then examine the role of four types of simple linguistic knowledge sources in a polarity classification system .\n",
            "5 tree kernel is an effective technique for relation extraction . however , the traditional syntactic tree representation is often too coarse or ambiguous to accurately capture the semantic relation information between two entities . in this paper , we propose a new tree kernel , called feature-enriched tree kernel ( ftk ) , which can enhance the traditional tree kernel by : 1 ) refining the syntactic tree representation by annotating each tree node with a set of discriminant features ; and 2 ) proposing a new tree kernel which can better measure the syntactic tree similarity by taking all features into consideration . experimental results show that our method can achieve a 5.4 % f-measure improvement over the traditional convolution tree kernel .\n",
            "6 the work reported in this article presents a computational model of interpretation . the model proposes a cognitive architecture for intelligent agents to reason about competing analyses during interpretation and leverages the positive reinforcement principle .\n",
            "7 this article describes the construction of a morphological , syntactic and semantic analyzer to operate a high-grade search engine for hebrew texts . a good search engine must be complete and accurate . in hebrew or arabic script most of the vowels are not written , many particles are attached to the word without space , a double consonant is written with one letter , and some letters signify both vowels and consonants . thus , almost every string of characters may designate many words ( the average in hebrew is almost three words ) . as a consequence , deciphering a word necessitates reading the whole sentence . our model is fillmores framework of an expression with a verb as its center . the engine eliminates readings of words unsuited to the syntax or the semantic structure of the sentence . in every verbal entry of our conceptual dictionary the features of the noun phrases ( nps ) required by the verb are included . when all the correct readings of all the strings of characters in the sentence have been identified , the program chooses the proper occurrences of the searched word in the text . approximately 95 % of the results by our search engine match those in the query .\n",
            "8 in this paper we present a family of kernel functions , named syntagmatic kernels , which can be used to model syntagmatic relations . syntagmatic relations hold among words that are typically collocated in a sequential order , and thus they can be acquired by analyzing word sequences . in particular , syntagmatic kernels are defined by applying a word sequence kernel to the local contexts of the words to be analyzed . in addition , this approach allows us to define a semi supervised learning schema where external lexical knowledge is plugged into the supervised learning process . lexical knowledge is acquired from both unlabeled data and hand-made lexical resources , such as wordnet . we evaluated the syntagmatic kernel on two standard word sense disambiguation tasks ( i.e . english and italian lexical-sample tasks of senseval-3 ) , where the syntagmatic information plays a crucial role . we compared the syntagmatic kernel with the standard approach , showing promising improvements in performance .\n",
            "9 we introduce new features for incorporating semantic predicate-argument structures in machine translation ( mt ) . the methods focus on the completeness of the semantic structures of the translations , as well as the order of the translated semantic roles . we experiment with translation rules which contain the core arguments for the predicates in the source side of a mt system , and observe that using these rules significantly improves the translation quality . we also present a new semantic feature that resembles a language model . our results show that the language model feature can also significantly improve mt results .\n",
            "10 the most accurate unsupervised word segmentation systems that are currently available ( brent , 1999 ; venkataraman , 2001 ; goldwater , 2007 ) use a simple unigram model of phonotactics . while this simplifies some of the calculations , it overlooks cues that infant language acquisition researchers have shown to be useful for segmentation ( mattys et al , 1999 ; mattys and jusczyk , 2001 ) . here we explore the utility of using bigram and trigram phonotactic models by enhancing brents ( 1999 ) mbdp-1 algorithm . the results show the improved mbdp-phon model outperforms other unsupervised word segmentation systems ( e.g. , brent , 1999 ; venkataraman , 2001 ; goldwater , 2007 ) .\n",
            "11 word sense induction aims to discover different senses of a word from a corpus by using unsupervised learning approaches . once a sense inventory is obtained for an ambiguous word , word sense discrimination approaches choose the best-fitting single sense for a given context from the induced sense inventory . however , there may not be a clear distinction between one sense and another , although for a context , more than one induced sense can be suitable . graded word sense method allows for labeling a word in more than one sense . in contrast to the most common approach which is to apply clustering or graph partitioning on a representation of first or second order co-occurrences of a word , we propose a system that creates a substitute vector for each target word from the most likely substitutes suggested by a statistical language model . word samples are then taken according to probabilities of these substitutes and the results of the co-occurrence model are clustered . this approach outperforms the other systems on graded word sense induction task in semeval-2013 .\n",
            "12 we consider the problem of answering complex questions that require inferencing and synthesizing information from multiple documents and can be seen as a kind of topicoriented , informative multi-document summarization . the stochastic , graph-based method for computing the relative importance of textual units ( i.e . sentences ) is very successful in generic summarization . in this method , a sentence is encoded as a vector in which each component represents the occurrence frequency ( tf*idf ) of a word . however , the major limitation of the tf*idf approach is that it only retains the frequency of the words and does not take into account the sequence , syntactic and semantic information . in this paper , we study the impact of syntactic and shallow semantic information in the graph-based method for answering complex questions .\n",
            "13 this paper presents our system to address the cogalex-iv 2014 shared task of identifying a single word most semantically related to a group of 5 words ( queries ) . our system uses an implementation of a neural language model and identifies the answer word by finding the most semantically similar word representation to the sum of the query representations . it is a fully unsupervised system which learns on around 20 % of the ukwac corpus . it correctly identifies 85 exact correct targets out of 2,000 queries , 285 approximate targets in lists of 5 suggestions .\n",
            "14 this paper describes a series of french semantic role labelling experiments which show that a small set of manually annotated training data is superior to a much larger set containing semantic role labels which have been projected from a source language via word alignment . using universal part-of-speech tags and dependencies makes little difference over the original fine-grained tagset and dependency scheme . moreover , there seems to be no improvement gained from projecting semantic roles between direct translations than between indirect translations .\n",
            "15 the brown and the berkeley parsers are two state-of-the-art generative parsers . since both parsers produce n-best lists , it is possible to apply reranking techniques to the output of both of these parsers , and to their union . we note that the standard reranker feature set distributed with the brown parser does not do well with the berkeley parser , and propose an extended set that does better . an ablation experiment shows that different parsers benefit from different reranker features .\n",
            "16 this paper presents our error tolerable system for coreference resolution in conll2011 ( pradhan et al , 2011 ) shared task ( closed track ) . different from most previous reported work , we detect mention candidates based on packed forest instead of single parse tree , and we use beam search algorithm based on the bell tree to create entities . experimental results show that our methods achieve promising results on the development set .\n",
            "17 we describe our approach to the construction and evaluation of a large-scale database called catvar which contains categorial variations of english lexemes . due to the prevalence of cross-language categorial variation in multilingual applications , our categorial-variation resource may serve as an integral part of a diverse range of natural language applications . thus , the research reported herein overlaps heavily with that of the machine-translation , lexicon-construction , and information-retrieval communities . we apply the information-retrieval metrics of precision and recall to evaluate the accuracy and coverage of our database with respect to a human-produced gold standard . this evaluation reveals that the categorial database achieves a high degree of precision and recall . additionally , we demonstrate that the database improves on the linkability of porter stemmer by over 30 % .\n",
            "18 a general characteristic of most biomedical disciplines is their primarily experimental character . discoveries are obtained through molecular biology and biochemical techniques that allow understanding of biological processes at the molecular level . to qualify biological events , it is of practical significance to detect specific types of negations that can imply either that a given event is not observed under specific conditions or even the opposite , that a given event is true by altering the bio-entities studied ( e.g . introducing specific modifications like mutations ) . of special interest is also to determine if a detected assertion is linked to experimental support provided by the authors . finding experimental qualifier cues and detecting experimental technique mentions is of great interest to the biological community in general and particularly for annotation databases . a short overview of different types of negations and biological qualifiers of practical relevance will be provided .\n",
            "19 an external lexicon quality measure called the l-measure is derived from the f-measure ( rijsbergen , 1979 ; larsen and aone , 1999 ) . the typically small sample sizes available for minority languages and the evaluation of semitic language lexicons are two main factors considered . large-scale evaluation results for the maltilex corpus are presented ( rosner et al. , 1999 ) .\n",
            "20 vector-based distributional models of semantics have proven useful and adequate in a variety of natural language processing tasks . however , most of them lack at least one key requirement in order to serve as an adequate representation of natural language , namely sensitivity to structural information such as word order . we propose a novel approach that offers a potential of integrating order-dependent word contexts in a completely unsupervised manner by assigning to words characteristic distributional matrices . the proposed model is applied to the task of free associations . in the end , the first results as well as directions for future work are discussed .\n",
            "21 this paper presents the carnegie mellon university statistical transfer mt system submitted to the 2009 wmt shared task in french-to-english translation . we describe a syntax-based approach that incorporates both syntactic and non-syntactic phrase pairs in addition to a syntactic grammar . after reporting development test results , we conduct a preliminary analysis of the coverage and effectiveness of the systems components .\n",
            "22 sentence types typical to swedish clinical text were extracted by comparing sentence part-of-speech tag sequences in clinical and in standard swedish text . parsings by a syntactic dependency parser , trained on standard swedish , were manually analysed for the 33 sentence types most typical to clinical text . this analysis resulted in the identification of eight error types , and for two of these error types , preprocessing rules were constructed to improve the performance of the parser . for all but one of the ten sentence types affected by these two rules , the parsing was improved by pre-processing .\n",
            "23 wouldnt it be helpful if your text editor automatically suggested papers that are relevant to your research wouldnt it be even better if those suggestions were contextually relevant in this paper we name a system that would accomplish this a context-based citation recommendation ( cbcr ) system . we specifically present citation resolution , a method for the evaluation of cbcr systems which exclusively uses readily-available scientific articles . exploiting the human judgements that are already implicit in available resources , we avoid purpose-specific annotation . we apply this evaluation to three sets of methods for representing a document , based on a ) the contents of the document , b ) the surrounding contexts of citations to the document found in other documents , and c ) a mixture of the two .\n",
            "24 results from psychology show a connection between a speakers expertise in a task and the language he uses to talk about it . in this paper , we present an empirical study on using linguistic evidence to predict the expertise of a speaker in a task : playing chess . instructional chess literature claims that the mindsets of amateur and expert players differ fundamentally ( silman , 1999 ) ; psychological science has empirically arrived at similar results ( e.g. , pfau and murphy ( 1988 ) ) . we conduct experiments on automatically predicting chess player skill based on their natural language game commentary . we make use of annotated chess games , in which players provide their own interpretation of game in prose . based on a dataset collected from an online chess forum , we predict player strength through svm classification and ranking . we show that using textual and chess-specific features achieves both high classification accuracy and significant correlation . finally , we compare our findings to claims from the chess literature and results from psychology .\n",
            "25 this work explores the utility of sentiment and arguing opinions for classifying stances in ideological debates . in order to capture arguing opinions in ideological stance taking , we construct an arguing lexicon automatically from a manually annotated corpus . we build supervised systems employing sentiment and arguing opinions and their targets as features . our systems perform substantially better than a distribution-based baseline . additionally , by employing both types of opinion features , we are able to perform better than a unigrambased system .\n",
            "26 in this paper , we put forward an information theoretic definition of the redundancy that is observed across the sound inventories of the worlds languages . through rigorous statistical analysis , we find that this redundancy is an invariant property of the consonant inventories . the statistical analysis further unfolds that the vowel inventories do not exhibit any such property , which in turn points to the fact that the organizing principles of the vowel and the consonant inventories are quite different in nature .\n",
            "27 search-based structured prediction andreas vlachos and mark craven department of biostatistics and medical informatics university of wisconsin-madison { vlachos , craven } @ biostat.wisc.edu abstract in this paper we describe our approach to the bionlp 2011 shared task on biomedical event extraction from abstracts and full papers . we employ a joint inference system developed using the search-based structured prediction framework and show that it improves on a pipeline using the same features and it is better able to handle the domain shift from abstracts to full papers . in addition , we report on experiments using a simple domain adaptation method .\n",
            "28 named entity phrases are some of the most difficult phrases to translate because new phrases can appear from nowhere , and because many are domain specific , not to be found in bilingual dictionaries . we present a novel algorithm for translating named entity phrases using easily obtainable monolingual and bilingual resources . we report on the application and evaluation of this algorithm in translating arabic named entities to english . we also compare our results with the results obtained from human translations and a commercial system for the same task .\n",
            "29 this paper studies the impact of written language variations and the way it affects the capitalization task over time . a discriminative approach , based on maximum entropy models , is proposed to perform capitalization , taking the language changes into consideration . the proposed method makes it possible to use large corpora for training . the evaluation is performed over newspaper corpora using different testing periods . the achieved results reveal a strong relation between the capitalization performance and the elapsed time between the training and testing data periods .\n",
            "30 mental modeling is crucial for natural humanrobot interactions ( hri ) . yet , effective mechanisms that enable reasoning about and communication of mental states are not available . we propose to utilize adverbial cues , routinely employed by humans , for this goal and present a novel algorithm that integrates adverbial modifiers with belief revision and expression , phrasing utterances based on gricean conversational maxims . the algorithm is demonstrated in a simple hri scenario .\n",
            "31 much natural language processing still depends on the euclidean ( cosine ) distance function between two feature vectors , but this has severe problems with regard to feature weightings and feature correlations . to answer these problems , we propose an optimal metric distance that can be used as an alternative to the cosine distance , thus accommodating the two problems at the same time . this metric is optimal in the sense of global quadratic minimization , and can be obtained from the clusters in the training data in a supervised fashion . we confirmed the effect of the proposed metric distance by a synonymous sentence retrieval task , document retrieval task and the k-means clustering of general vectorial data . the results showed constant improvement over the baseline method of euclid and tf.idf , and were especially prominent for the sentence retrieval task , showing a 33 % increase in the 11-point average precision .\n",
            "32 in this paper , we propose a novel method for semi-supervised learning of nonprojective log-linear dependency parsers using directly expressed linguistic prior knowledge ( e.g . a nouns parent is often a verb ) . model parameters are estimated using a generalized expectation ( ge ) objective function that penalizes the mismatch between model predictions and linguistic expectation constraints . in a comparison with two prominent unsupervised learning methods that require indirect biasing toward the correct syntactic structure , we show that ge can attain better accuracy with as few as 20 intuitive constraints . we also present positive experimental results on longer sentences in multiple languages .\n",
            "33 we propose a structure called dependency forest for statistical machine translation . a dependency forest compactly represents multiple dependency trees . we develop new algorithms for extracting string-todependency rules and training dependency language models . our forest-based string-to-dependency system obtains significant improvements ranging from 1.36 to 1.46 bleu points over the tree-based baseline on the nist 2004/2005/2006 chinese-english test sets .\n",
            "34 the extension to new languages is a well known bottleneck for rule-based systems . considerable human effort , which typically consists in re-writing from scratch huge amounts of rules , is in fact required to transfer the knowledge available to the system from one language to a new one . provided sufficient annotated data , machine learning algorithms allow to minimize the costs of such knowledge transfer but , up to date , proved to be ineffective for some specific tasks . among these , the recognition and normalization of temporal expressions still remains out of their reach . focusing on this task , and still adhering to the rule-based framework , this paper presents a bunch of experiments on the automatic porting to italian of a system originally developed for spanish . different automatic rule translation strategies are evaluated and discussed , providing a comprehensive overview of the challenge .\n",
            "35 a hybrid system is described which combines the strength of manual rulewriting and statistical learning , obtaining results superior to both methods if applied separately . the combination of a rule-based system and a statistical one is not parallel but serial : the rule-based system performing partial disambiguation with recall close to 100 % is applied first , and a trigram hmm tagger runs on its results . an experiment in czech tagging has been performed with encouraging results .\n",
            "36 we explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums , an increasingly popular means of providing customer service . in particular , we investigate the effectiveness of various features and machine learners for this task . while a simple bag-of-words approach provides a solid baseline , we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance ; learners that account for sequential dependencies ( crfs ) show the best performance . we report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data .\n",
            "37 we address the problem dealing with a large collection of data , and investigate the use of automatically constructing category hierarchy from a given set of categories to improve classification of large corpora . we use two wellknown techniques , partitioning clustering , means and a to create category hierarchy . -means is to cluster the given categories in a hierarchy . to select the proper number of , we use a which measures the degree of our disappointment in any differences between the true distribution over inputs and the learners prediction . once the optimal number of is selected , for each cluster , the procedure is repeated . our evaluation using the 1996 reuters corpus which consists of 806,791 documents shows that automatically constructing hierarchy improves classification accuracy .\n",
            "38 techniques that compare short text segments using dependency paths ( or simply , paths ) appear in a wide range of automated language processing applications including question answering ( qa ) . however , few models in ad hoc information retrieval ( ir ) use paths for document ranking due to the prohibitive cost of parsing a retrieval collection . in this paper , we introduce a flexible notion of paths that describe chains of words on a dependency path . these chains , or catenae , are readily applied in standard ir models . informative catenae are selected using supervised machine learning with linguistically informed features and compared to both non-linguistic terms and catenae selected heuristically with filters derived from work on paths . automatically selected catenae of 1-2 words deliver significant performance gains on three trec collections .\n",
            "39 the main area of this paper concerns the neural methods for mapping scientific and technical information ( articles , patents ) and for assisting a user in carrying out the complex process of analysing large quantities of such information . in the procedure of information analysis , like in the domain of patent analysis , the complexity of the studied topics and the accuracy of the question to be answered may often lead the analyst to partition his reasoning into viewpoints . most of the classical information analysis tools can only manage an analysis of the studied domain in a global way . the information analysis tool that will be considered in our study is the multisom tool whose core model represents a significant extension of the classical kohonen som neural model . the multisom neural-based tool introduces the concepts of viewpoints and dynamics into the information analysis with its multi-maps displays and its intermap communication process . the dynamic information exchange between maps can be exploited by an analyst in order to perform cooperative deduction between several different analyzes that have been performed on the same data . the paper demonstrates the efficiency of a viewpoint-oriented-analysis as compared to a global analysis in the domain of patents . both objective and subjective quality criteria are taken into account for quality evaluation . the experimental context of the paper is constituted by a patent database of 1000 patents related to oil engineering . the patents structure and the patents field semantics are firstly exploited in order to generate different viewpoints corresponding to different areas of interest for the analysts .\n",
            "40 social media texts are significant information sources for several application areas including trend analysis , event monitoring , and opinion mining . unfortunately , existing solutions for tasks such as named entity recognition that perform well on formal texts usually perform poorly when applied to social media texts . in this paper , we report on experiments that have the purpose of improving named entity recognition on turkish tweets , using two different annotated data sets . in these experiments , starting with a baseline named entity recognition system , we adapt its recognition rules and resources to better fit twitter language by relaxing its capitalization constraint and by diacritics-based expansion of its lexical resources , and we employ a simplistic normalization scheme on tweets to observe the effects of these on the overall named entity recognition performance on turkish tweets . the evaluation results of the system with these different settings are provided with discussions of these results .\n",
            "41 prior work has shown that generalization of data in an example based machine translation ( ebmt ) system , reduces the amount of pre-translated text required to achieve a certain level of accuracy ( brown , 2000 ) . several word clustering algorithms have been suggested to perform these generalizations , such as kmeans clustering or group average clustering . the hypothesis is that better contextual clustering can lead to better translation accuracy with limited training data . in this paper , we use a form of spectral clustering to cluster words , and this is shown to result in as much as 29.08 % improvement over the baseline ebmt system .\n",
            "42 developing better methods for segmenting continuous text into words is important for improving the processing of asian languages , and may shed light on how humans learn to segment speech . we propose two new bayesian word segmentation methods that assume unigram and bigram models of word dependencies respectively . the bigram model greatly outperforms the unigram model ( and previous probabilistic models ) , demonstrating the importance of such dependencies for word segmentation . we also show that previous probabilistic models rely crucially on suboptimal search procedures .\n",
            "43 this paper presents a chinese word segmentation system for the closed track of cips-sighan word segmentation bakeoff 2010. this system adopts a character-based joint approach , which combines a character-based generative model and a character-based discriminative model . to further improve the crossdomain performance , we use an additional semi-supervised learning procedure to incorporate the unlabeled corpus . the final performance on the closed track for the simplified-character text shows that our system achieves comparable results with other state-of-the-art systems .\n",
            "44 identification of transliterated names is a particularly difficult task of named entity recognition ( ner ) , especially in the chinese context . of all possible variations of transliterated named entities , the difference between prc and taiwan is the most prevalent and most challenging . in this paper , we introduce a novel approach to the automatic extraction of diverging transliterations of foreign named entities by bootstrapping cooccurrence statistics from tagged and segmented chinese corpus . preliminary experiment yields promising results and shows its potential in nlp applications .\n",
            "45 traditional question answering systems adopt the following framework : parsing questions , searching for relevant documents , and identifying/generating answers . however , this framework does not work well for questions with hidden assumptions and implicatures . in this paper , we describe a novel idea , a cascading guidance strategy , which can not only identify potential traps in questions but further guide the answer extraction procedure by recognizing whether there are multiple answers for a question . this is the first attempt to solve implicature problem for complex qa in a cascading fashion using n-gram language models as features . we here investigate questions with implicatures related to biography facts in a web-based qa system , powerbio . we compare the performances of decision tree , nave bayes , svm ( support vector machine ) , and me ( maximum entropy ) classification methods . the integration of the cascading guidance strategy can help extract answers for questions with implicatures and produce satisfactory results in our experiments .\n",
            "46 in this paper , we explore the use of automatic syntactic simplification for improving content selection in multi-document summarization . in particular , we show how simplifying parentheticals by removing relative clauses and appositives results in improved sentence clustering , by forcing clustering based on central rather than background information . we argue that the inclusion of parenthetical information in a summary is a reference-generation task rather than a content-selection one , and implement a baseline reference rewriting module . we perform our evaluations on the test sets from the 2003 and 2004 document understanding conference and report that simplifying parentheticals results in significant improvement on the automated evaluation metric rouge .\n",
            "47 patent images are very important for patent examiners to understand the contents of an invention . therefore there is a need for automatic labelling of patent images in order to support patent search tasks . towards this goal , recent research works propose classification-based approaches for patent image annotation . however , one of the main drawbacks of these methods is that they rely upon large annotated patent image datasets , which require substantial manual effort to be obtained . in this context , the proposed work performs extraction of concepts from patent images building upon a supervised machine learning framework , which is trained with limited annotated data and automatically generated synthetic data . the classification is realised with random forests ( rf ) and a combination of visual and textual features . first , we make use of rfs implicit ability to detect outliers to rid our data of unnecessary noise . then , we generate new synthetic data cases by means of synthetic minority over-sampling technique ( smote ) . we evaluate the different retrieval parts of the framework by using a dataset from the footwear domain . the results of the experiments indicate the benefits of using the proposed methodology .\n",
            "48 this study investigates similarity judgments from two angles . first , we look at models suggested in the psychology and philosophy literature which capture the essence of concept similarity evaluation for humans . second , we analyze the properties of many metrics which simulate such evaluation capabilities . the first angle reveals that non-experts can judge similarity and that their judgments need not be based on predefined traits . we use such conclusions to inform us on how gold standards for word sense disambiguation tasks could be established . from the second angle , we conclude that more attention should be paid to metric properties before assigning them to perform a particular task .\n",
            "49 the purpose of this study is to construct a semantic analysis method for disambiguating japanese compound verbs . japanese speakers produce a rich variety of compound verbs , making it difficult to process them by computer . we construct a method employing 110 disambiguation rules based on the semantic features of the first verb of a compound and syntactic patterns consisting of co-occurrence between verbs and nouns . the disambiguation rules are evaluated by applying them to compound verbs in the dictionary . the obtained accuracy is 87.19 % for our rules . this result shows the advantage of our method .\n",
            "50 our submission was a reduced version of the system described in haghighi and klein ( 2010 ) , with extensions to improve mention detection to suit the ontonotes annotation scheme . including exact matching mention detection in this shared task added a new and challenging dimension to the problem , particularly for our system , which previously used a very permissive detection method . we improved this aspect of the system by adding filters based on the annotation scheme for ontonotes and analysis of system behavior on the development set . these changes led to improvements in coreference f-score of 10.06 , 5.71 , 6.78 , 6.63 and 3.09 on the muc , b3 , ceaf-e , ceaf-m and blanc , metrics , respectively , and a final task score of 47.10 .\n",
            "51 recent evaluation techniques applied to corpusbased systems have been introduced that can predict quantitatively how well surface realizers will generate unseen sentences in isolation . we introduce a similar method for determining the coverage on the fuf/surge symbolic surface realizer , report that its coverage and accuracy on the penn treebank is higher than that of a similar statistics-based generator , describe several bene ts that can be used in other areas of computational linguistics , and present an updated version of surge for use in the nlg community .\n",
            "52 our research organization has been constructing a large scale database named shachi by collecting detailed meta information on language resources ( lrs ) in asia and western countries . the metadata database contains more than 2,000 compiled lrs such as corpora , dictionaries , thesauruses and lexicons , forming a large scale metadata of lrs archive . its metadata , an extended version of olac metadata set conforming to dublin core , have been collected semi-automatically . this paper explains the design and the structure of the metadata database , as well as the realization of the catalogue search tool .\n",
            "53 we present a novel model , freestyle , that learns to improvise rhyming and fluent responses upon being challenged with a line of hip hop lyrics , by combining both bottomup token based rule induction and top-down rule segmentation strategies to learn a stochastic transduction grammar that simultaneously learns both phrasing and rhyming associations . in this attack on the woefully under-explored natural language genre of music lyrics , we exploit a strictly unsupervised transduction grammar induction approach . our task is particularly ambitious in that no use of any a priori linguistic or phonetic information is allowed , even though the domain of hip hop lyrics is particularly noisy and unstructured . we evaluate the performance of the learned model against a model learned only using the more conventional bottom-up token based rule induction , and demonstrate the superiority of our combined token based and rule segmentation induction method toward generating higher quality improvised responses , measured on fluency and rhyming criteria as judged by human evaluators . to highlight some of the inherent challenges in adapting other algorithms to this novel task , we also compare the quality of the responses generated by our model to those generated by an out-ofthe-box phrase based smt system . we tackle the challenge of selecting appropriate training data for our task via a dedicated rhyme scheme detection module , which is also acquired via unsupervised learning and report improved quality of the generated responses . finally , we report results with maghrebi french hip hop lyrics indicating that our model performs surprisingly well with no special adaptation to other languages .\n",
            "54 this paper presents an unsupervised topic identification method integrating linguistic and visual information based on hidden markov models ( hmms ) . we employ hmms for topic identification , wherein a state corresponds to a topic and various features including linguistic , visual and audio information are observed . our experiments on two kinds of cooking tv programs show the effectiveness of our proposed method .\n",
            "55 in this paper , we present a word sense disambiguation ( wsd ) based system for multilingual lexical substitution . our method depends on having a wsd system for english and an automatic word alignment method . crucially the approach relies on having parallel corpora . for task 2 ( sinha et al , 2009 ) we apply a supervised wsd system to derive the english word senses . for task 3 ( lefever & hoste , 2009 ) , we apply an unsupervised approach to the training and test data . both of our systems that participated in task 2 achieve a decent ranking among the participating systems . for task 3 we achieve the highest ranking on several of the language pairs : french , german and italian .\n",
            "56 statistical machine translation relies heavily on available parallel corpora , but smt may not have the ability or intelligence to make full use of the training set . instead of col-lecting more and more parallel training cor-pora , this paper aims to improve smt performance by exploiting the full potential of existing parallel corpora . we first iden-tify literally translated sentence pairs via lexical and grammatical compatibility , and then use these data to train smt models . one experiment indicates that larger train-ing corpora do not always lead to higher de-coding performance when the added data are not literal translations . and another ex-periment shows that properly enlarging the contribution of literal translation can im-prove smt performance significantly .\n",
            "57 consumers increasingly rate , review and research products online ( jansen , 2010 ; litvin et al , 2008 ) . consequently , websites containing consumer reviews are becoming targets of opinion spam . while recent work has focused primarily on manually identifiable instances of opinion spam , in this work we study deceptive opinion spamfictitious opinions that have been deliberately written to sound authentic . integrating work from psychology and computational linguistics , we develop and compare three approaches to detecting deceptive opinion spam , and ultimately develop a classifier that is nearly 90 % accurate on our gold-standard opinion spam dataset . based on feature analysis of our learned models , we additionally make several theoretical contributions , including revealing a relationship between deceptive opinions and imaginative writing .\n",
            "58 this paper describes the system used by the lipn team in the task 10 , multilingual semantic textual similarity , at semeval 2014 , in both the english and spanish sub-tasks . the system uses a support vector regression model , combining different text similarity measures as features . with respect to our 2013 participation , we included a new feature to take into account the geographical context and a new semantic distance based on the bhattacharyya distance calculated on cooccurrence distributions derived from the spanish google books n-grams dataset .\n",
            "59 data preprocessing plays a crucial role in phrase-based statistical machine translation ( pb-smt ) . in this paper , we show how single-tokenization of two types of multi-word expressions ( mwe ) , namely named entities ( ne ) and compound verbs , as well as their prior alignment can boost the performance of pb-smt . single-tokenization of compound verbs and named entities ( ne ) provides significant gains over the baseline pb-smt system . automatic alignment of nes substantially improves the overall mt performance , and thereby the word alignment quality indirectly . for establishing ne alignments , we transliterate source nes into the target language and then compare them with the target nes . target language nes are first converted into a canonical form before the comparison takes place . our best system achieves statistically significant improvements ( 4.59 bleu points absolute , 52.5 % relative improvement ) on an englishbangla translation task .\n",
            "60 real document collections do not fit the independence assumptions asserted by most statistical topic models , but how badly do they violate them we present a bayesian method for measuring how well a topic model fits a corpus . our approach is based on posterior predictive checking , a method for diagnosing bayesian models in user-defined ways . our method can identify where a topic model fits the data , where it falls short , and in which directions it might be improved .\n",
            "61 transforming syntactic representations in order to improve parsing accuracy has been exploited successfully in statistical parsing systems using constituency-based representations . in this paper , we show that similar transformations can give substantial improvements also in data-driven dependency parsing . experiments on the prague dependency treebank show that systematic transformations of coordinate structures and verb groups result in a 10 % error reduction for a deterministic data-driven dependency parser . combining these transformations with previously proposed techniques for recovering nonprojective dependencies leads to state-ofthe-art accuracy for the given data set .\n",
            "62 most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features . this approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones . to overcome this problem , we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision . each tier builds on the previous tiers entity cluster output . further , our model propagates global information by sharing attributes ( e.g. , gender and number ) across mentions in the same cluster . this cautious sieve guarantees that stronger features are given precedence over weaker ones and that each decision is made using all of the information available at the time . the framework is highly modular : new coreference modules can be plugged in without any change to the other modules . in spite of its simplicity , our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora . this suggests that sievebased approaches could be applied to other nlp tasks .\n",
            "63 this paper presents a cross platform multilingual multimedia indian sign language ( isl ) dictionary building tool . isl is a linguistically under-investigated language with no source of well documented electronic data . research on isl linguistics also gets hindered due to a lack of isl knowledge and the unavailability of any educational tools . our system can be used to associate signs corresponding to a given text . the current system also facilitates the phonological annotation of indian signs in the form of hamnosys structure . the generated hamnosys string can be given as input to an avatar module to produce an animated sign representation .\n",
            "64 efforts to automatically acquire world knowledge from text suffer from the lack of an easy means of evaluating the resulting knowledge . we describe initial experiments using mechanical turk to crowdsource evaluation to nonexperts for little cost , resulting in a collection of factoids with associated quality judgements . we describe the method of acquiring usable judgements from the public and the impact of such large-scale evaluation on the task of knowledge acquisition .\n",
            "\n",
            "> Title examples:\n",
            "1 heideltime : tuning english and developing spanish resources\n",
            "2 storing the web in memory : space efficient language models with constant time retrieval\n",
            "3 vote prediction on comments in social polls\n",
            "4 examining the role of linguistic knowledge sources in the automatic identification and classification of reviews\n",
            "5 a feature-enriched tree kernel for relation extraction\n",
            "6 interpretation in a cognitive architecture\n",
            "7 uzzi ornan scientific director , multitext , multidimensional publishing systems\n",
            "8 a word sense disambiguation case study\n",
            "9 comparing representations of semantic roles for\n",
            "10 improving word segmentation by simultaneously learning phonotactics computer & information sciences linguistics & cognitive science\n",
            "11 ai-ku : using substitute vectors and co-occurrence modeling for word\n",
            "12 improving the performance of the random walk model for answering\n",
            "13 predicting sense convergence with distributional semantics : an\n",
            "14 experiments with french\n",
            "15 reranking the berkeley and brown parsers ahmet engin ural\n",
            "16 ets : an error tolerable system for coreference resolution\n",
            "17 a categorial variation database for english\n",
            "18 importance of negations and experimental qualifiers in biomedical\n",
            "19 adaptation of the f-measure to cluster based lexicon quality\n",
            "20 towards a matrix-based distributional model of meaning fzi forschungszentrum informatik\n",
            "21 an improved statistical transfer system for frenchenglish\n",
            "22 adapting a parser to clinical text by simple pre-processing rules\n",
            "23 citation resolution : a method for evaluating context-based citation\n",
            "24 picking the amateurs mind predicting chess player strength from and language processing\n",
            "25 recognizing stances in ideological on-line debates the intelligent systems program\n",
            "26 redundancy ratio : an invariant property of the consonant inventories of the worlds languages\n",
            "27 biomedical event extraction from abstracts and full papers using\n",
            "28 translating named entities using monolingual and bilingual resources\n",
            "29 language dynamics and capitalization using maximum entropy\n",
            "30 through adverbial cues\n",
            "31 learning nonstructural distance metric by minimum cluster distortions atr spoken language translation\n",
            "32 semi-supervised learning of dependency parsers using generalized expectation criteria\n",
            "33 dependency forest for statistical machine translation\n",
            "34 evaluating knowledge-based approaches to the multilingual extension of a temporal expression normalizer povo - trento , italy\n",
            "35 serial combination of rules and statistics : a case study in czech\n",
            "36 classifying dialogue acts in one-on-one live chats su nam kim , lawrence cavedon and timothy baldwin\n",
            "37 a comparison of manual and automatic constructions of category hierarchy for classifying large corpora\n",
            "38 feature-based selection of dependency paths in ad hoc information retrieval\n",
            "39 intelligent patent analysis through the use of a neural network : experiment of multi-viewpoint analysis with the multisom model shadi al shehabi\n",
            "40 experiments to improve named entity recognition on turkish tweets\n",
            "41 spectral clustering for example based machine translation\n",
            "42 contextual dependencies in unsupervised word segmentation\n",
            "43 a character-based joint model behavior design corporation\n",
            "44 automatic discovery of named entity variants grammar-driven approaches to non-alphabetical transliterations\n",
            "45 handling biographical questions with implicature donghui feng eduard hovy\n",
            "46 syntactic simplication for improving content selection in multi-document\n",
            "47 and proximity-driven generation of synthetic data\n",
            "48 similarity judgments : philosophical , psychological and mathematical\n",
            "49 a disambiguation method for japanese compound verbs\n",
            "50 mention detection : heuristics for the ontonotes annotations\n",
            "51 wide coverage symbolic surface realization\n",
            "52 construction of an infrastructure for providing users with suitable language resources hitomi tohyama shunsuke kozawa kiyotaka uchimoto\n",
            "53 learning to freestyle : hip hop challenge-response induction via transduction rule segmentation\n",
            "54 unsupervised topic identification by integrating linguistic and visual information based on hidden markov models\n",
            "55 coleur and colslm : a wsd approach to multilingual lexical\n",
            "56 train the machine with what it can learn corpus selection for smt\n",
            "57 finding deceptive opinion spam by any stretch of the imagination\n",
            "58 lipn : introducing a new geographical context similarity measure and a statistical similarity measure based on the bhattacharyya coefficient em priego sanchez\n",
            "59 handling named entities and compound verbs in phrase-based statistical machine translation\n",
            "60 bayesian checking for topic models\n",
            "61 graph transformations in data-driven dependency parsing\n",
            "62 a multi-pass sieve for coreference resolution\n",
            "63 a multilingual multimedia indian sign language dictionary tool\n",
            "64 evaluation of commonsense knowledge with mechanical turk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "6YE74HgtRlwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def title_preprocessor(text):\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.strip(text)\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text\n",
        "\n",
        "def abstract_preprocessor(text):\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.strip(text)\n",
        "    # Added start and end tokens. read somewhere its important for the RNNs\n",
        "    # not for transformer.. Idk.\n",
        "    # - Damion\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text\n",
        "\n",
        "# def abstract_preprocessor_mk2(text):\n",
        "#     # from: https://www.tensorflow.org/text/tutorials/nmt_with_attention#text_preprocessing\n",
        "#     # I've included this below code for preprocessing, since in the abstract,\n",
        "#     # punctuation etc isnt important - perhaps. Only for the titles. \n",
        "#     # So, perhaps performance increase\n",
        "#     # - Damion\n",
        "\n",
        "#     # Additionally, the start and end token seem to do something\n",
        "#     # for the RNN's?\n",
        "#     # Split accente d characters.\n",
        "    \n",
        "#     #text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "#     #text = tf.strings.lower(text)\n",
        "    \n",
        "#     # Keep space, a to z, and select punctuation.\n",
        "#     #text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "#     text = tf.strings.regex_replace(text, '[^ a-z]', '')\n",
        "    \n",
        "#     # Add spaces around punctuation.\n",
        "#     #text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "    \n",
        "#     # Strip whitespace.\n",
        "#     text = tf.strings.strip(text)\n",
        "\n",
        "#     text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "#     return text\n",
        "\n",
        "abs_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=abstract_preprocessor,\n",
        "    ragged=True,\n",
        "    output_mode='int'\n",
        "    )\n",
        "\n",
        "# abs_text_processor = tf.keras.layers.TextVectorization(\n",
        "#     standardize=abstract_preprocessor_mk2,\n",
        "#     ragged=True,\n",
        "#     output_mode='int'\n",
        "#     )\n",
        "\n",
        "tit_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=title_preprocessor,\n",
        "    ragged=True,\n",
        "    output_mode='int'\n",
        "    )\n",
        "\n",
        "abs_text_processor.adapt(train_dataset.map(lambda abs, tit: abs))\n",
        "tit_text_processor.adapt(train_dataset.map(lambda abs, tit: tit))\n",
        "\n",
        "def process_text(context, target):\n",
        "    context = abs_text_processor(context).to_tensor()\n",
        "    target = tit_text_processor(target)\n",
        "    targ_in = target[:,:-1].to_tensor()\n",
        "    targ_out = target[:,1:].to_tensor()\n",
        "    return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_dataset.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_dataset.map(process_text, tf.data.AUTOTUNE)\n",
        "test_ds = test_dataset.map(process_text, tf.data.AUTOTUNE)\n",
        "\n"
      ],
      "metadata": {
        "id": "LdZwW7FwMJoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c17c60-7e27-4398-dc0f-5f1f02d19890"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "    print(ex_context_tok[0, :10].numpy()) \n",
        "    print()\n",
        "    print(ex_tar_in[0, :10].numpy()) \n",
        "    print(ex_tar_out[0, :10].numpy())"
      ],
      "metadata": {
        "id": "tWz6GNDBMJvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0efc7a67-e699-4e6a-8685-982d48068ed1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  16    9   15   27    4   10  112   24 1296    9]\n",
            "\n",
            "[   2 2793    9  740   95    6  454  529  150    0]\n",
            "[2793    9  740   95    6  454  529  150    3    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models + components"
      ],
      "metadata": {
        "id": "EHJAZYiwMJ1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN + GRU components"
      ],
      "metadata": {
        "id": "i8X0JFHTMJ6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units, GRU=False):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    # self.rnn = tf.keras.layers.Bidirectional(\n",
        "    #     merge_mode='sum',\n",
        "    #     layer=tf.keras.layers.GRU(units,\n",
        "    #                         # Return the sequence and state\n",
        "    #                         return_sequences=True,\n",
        "    #                         recurrent_initializer='glorot_uniform'))\n",
        "    if not GRU:\n",
        "        self.rnn = (tf.keras.layers \\\n",
        "                    .SimpleRNN(units,\n",
        "                    # Return the sequence and state\n",
        "                    return_sequences=True,\n",
        "                    recurrent_initializer='glorot_uniform'))\n",
        "    else:\n",
        "        self.rnn = (tf.keras.layers\n",
        "                    .GRU(units,\n",
        "                    # Return the sequence and state\n",
        "                    return_sequences=True,\n",
        "                    recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context"
      ],
      "metadata": {
        "id": "OSwUQAd0MJ_P"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttentionRNN(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        "\n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "ibffKtxVR_Dx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(tf.keras.layers.Layer):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, text_processor, units, GRU=True):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_size = text_processor.vocabulary_size()\n",
        "        self.word_to_id = tf.keras.layers.StringLookup(\n",
        "            vocabulary=text_processor.get_vocabulary(),\n",
        "            mask_token='', oov_token='[UNK]')\n",
        "        self.id_to_word = tf.keras.layers.StringLookup(\n",
        "            vocabulary=text_processor.get_vocabulary(),\n",
        "            mask_token='', oov_token='[UNK]',\n",
        "            invert=True)\n",
        "        self.start_token = self.word_to_id('[START]')\n",
        "        self.end_token = self.word_to_id('[END]')\n",
        "        print('Did start- and end-token get stored properly?')\n",
        "        print(self.start_token, self.end_token)\n",
        "\n",
        "        self.units = units\n",
        "\n",
        "\n",
        "        # 1. The embedding layer converts token IDs to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                                    units, mask_zero=True)\n",
        "\n",
        "        # 2. The RNN keeps track of what's been generated so far.\n",
        "        if not GRU:\n",
        "            self.rnn = (tf.keras.layers \\\n",
        "                        .SimpleRNN(units,\n",
        "                        # Return the sequence and state\n",
        "                        return_sequences=True,\n",
        "                        return_state=True,\n",
        "                        recurrent_initializer='glorot_uniform'))\n",
        "        else:\n",
        "            self.rnn = (tf.keras.layers \\\n",
        "                        .GRU(units,\n",
        "                        # Return the sequence and state\n",
        "                        return_sequences=True,\n",
        "                        return_state=True,\n",
        "                        recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "        # 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = CrossAttentionRNN(units)\n",
        "\n",
        "        # 4. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.output_layer = tf.keras.layers.Dense(self.vocab_size)\n",
        "\n",
        "    def call(self,\n",
        "            context, x,\n",
        "            state=None,\n",
        "            return_state=False):  \n",
        "        shape_checker = ShapeChecker()\n",
        "        shape_checker(x, 'batch t')\n",
        "        shape_checker(context, 'batch s units')\n",
        "\n",
        "        # 1. Lookup the embeddings\n",
        "        x = self.embedding(x)\n",
        "        shape_checker(x, 'batch t units')\n",
        "\n",
        "        # 2. Process the target sequence.\n",
        "        x, state = self.rnn(x, initial_state=state)\n",
        "        shape_checker(x, 'batch t units')\n",
        "\n",
        "        # 3. Use the RNN output as the query for the attention over the context.\n",
        "        x = self.attention(x, context)\n",
        "        self.last_attention_weights = self.attention.last_attention_weights\n",
        "        shape_checker(x, 'batch t units')\n",
        "        shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "        # Step 4. Generate logit predictions for the next token.\n",
        "        logits = self.output_layer(x)\n",
        "        shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "        if return_state:\n",
        "            return logits, state\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "    def get_initial_state(self, context):\n",
        "        batch_size = tf.shape(context)[0]\n",
        "        start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "        done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "        embedded = self.embedding(start_tokens)\n",
        "        return start_tokens, done, self.rnn.get_initial_state(embedded)[0]\n",
        "    \n",
        "    def tokens_to_text(self, tokens):\n",
        "        words = self.id_to_word(tokens)\n",
        "        result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "        result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "        result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "        return result\n",
        "\n",
        "    def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "        logits, state = self(\n",
        "        context, next_token,\n",
        "        state = state,\n",
        "        return_state=True) \n",
        "\n",
        "        if temperature == 0.0:\n",
        "            next_token = tf.argmax(logits, axis=-1)\n",
        "        else:\n",
        "            logits = logits[:, -1, :]/temperature\n",
        "            next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "        # If a sequence produces an `end_token`, set it `done`\n",
        "        done = done | (next_token == self.end_token)\n",
        "        # Once a sequence is done it only produces 0-padding.\n",
        "        next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "\n",
        "        return next_token, done, state"
      ],
      "metadata": {
        "id": "dUrqxE8-SENh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(tf.keras.Model):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, units,\n",
        "                context_text_processor,\n",
        "                target_text_processor,\n",
        "                GRU=True):\n",
        "        super().__init__()\n",
        "        # Build the encoder and decoder\n",
        "        # GRU False will result in SimpleRNN instead of GRU\n",
        "        self.encoder = EncoderRNN(context_text_processor, units, GRU=GRU)\n",
        "        self.decoder = DecoderRNN(target_text_processor, units, GRU=GRU)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        context, x = inputs\n",
        "        context = self.encoder(context)\n",
        "        logits = self.decoder(context, x)\n",
        "\n",
        "        #TODO(b/250038731): remove this\n",
        "        try:\n",
        "            # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        return logits\n",
        "    \n",
        "    def translate(self,\n",
        "                texts, *,\n",
        "                max_length=50,\n",
        "                temperature=0.0):\n",
        "        # Process the input texts\n",
        "        context = self.encoder.convert_input(texts)\n",
        "        batch_size = tf.shape(texts)[0]\n",
        "\n",
        "        # Setup the loop inputs\n",
        "        tokens = []\n",
        "        attention_weights = []\n",
        "        next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            # Generate the next token\n",
        "            next_token, done, state = self.decoder.get_next_token(\n",
        "                context, next_token, done,  state, temperature)\n",
        "\n",
        "            # Collect the generated tokens\n",
        "            tokens.append(next_token)\n",
        "            attention_weights.append(self.decoder.last_attention_weights)\n",
        "\n",
        "            if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "                break\n",
        "\n",
        "        # Stack the lists of tokens and attention weights.\n",
        "        tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "        self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "        result = self.decoder.tokens_to_text(tokens)\n",
        "        return result"
      ],
      "metadata": {
        "id": "-ejJ7fX0SnbW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Component"
      ],
      "metadata": {
        "id": "zdNrC7w4MKDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbeddingT(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "        self.pos_encoding = self.positional_encoding(length=2048, depth=d_model)\n",
        "    \n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "    \n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "        return x\n",
        "    \n",
        "    def positional_encoding(self, length, depth):\n",
        "        depth = depth/2\n",
        "\n",
        "        positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "        depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "        angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "        angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "        pos_encoding = np.concatenate(\n",
        "            [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "            axis=-1) \n",
        "\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class BaseAttentionT(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "class CrossAttentionT(BaseAttentionT):\n",
        "    def call(self, x, context):\n",
        "        attn_output, attn_scores = self.mha(\n",
        "            query=x,\n",
        "            key=context,\n",
        "            value=context,\n",
        "            return_attention_scores=True)\n",
        "        # Cache the attention scores for plotting later.\n",
        "        self.last_attn_scores = attn_scores\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "class GlobalSelfAttentionT(BaseAttentionT):\n",
        "    def call(self, x):\n",
        "        attn_output = self.mha(\n",
        "            query=x,\n",
        "            value=x,\n",
        "            key=x)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "class CausalSelfAttentionT(BaseAttentionT):\n",
        "    def call(self, x):\n",
        "        attn_output = self.mha(\n",
        "            query=x,\n",
        "            value=x,\n",
        "            key=x,\n",
        "            use_causal_mask = True)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "class FeedForwardT(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.seq = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "    def call(self, x):\n",
        "        x = self.add([x, self.seq(x)])\n",
        "        x = self.layer_norm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "F_NNvdiJMKIJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayerT(tf.keras.layers.Layer):\n",
        "    def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attention = GlobalSelfAttentionT(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=d_model,\n",
        "            dropout=dropout_rate)\n",
        "\n",
        "        self.ffn = FeedForwardT(d_model, dff)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.self_attention(x)\n",
        "        x = self.ffn(x)\n",
        "        return x\n",
        "\n",
        "class EncoderT(tf.keras.layers.Layer):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads,\n",
        "                dff, vocab_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Wanneer we translator maken moeten we het volgende gebruiken:\n",
        "        # self.text_processor = text_processor\n",
        "        # self.vocab_size = vocab_size\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbeddingT(\n",
        "            vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "        self.enc_layers = [\n",
        "            EncoderLayerT(d_model=d_model,\n",
        "                            num_heads=num_heads,\n",
        "                            dff=dff,\n",
        "                            dropout_rate=dropout_rate)\n",
        "            for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "        # `x` is token-IDs shape: (batch, seq_len)\n",
        "        x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "        # Add dropout.\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x)\n",
        "\n",
        "        return x  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    def convert_input(self, texts):\n",
        "        pass"
      ],
      "metadata": {
        "id": "he59iwfiTOf9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayerT(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayerT, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttentionT(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "    \n",
        "    self.cross_attention = CrossAttentionT(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForwardT(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x\n",
        "\n",
        "class DecoderT(tf.keras.layers.Layer):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "                dropout_rate=0.1):\n",
        "        super(DecoderT, self).__init__()\n",
        "        ### TODO:\n",
        "        # word_to_id etc, zie RNN decoder van Nick en Jan\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbeddingT(vocab_size=vocab_size,\n",
        "                                                    d_model=d_model)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.dec_layers = [\n",
        "            DecoderLayerT(d_model=d_model, num_heads=num_heads,\n",
        "                            dff=dff, dropout_rate=dropout_rate)\n",
        "            for _ in range(num_layers)]\n",
        "\n",
        "        self.last_attn_scores = None\n",
        "\n",
        "    def call(self, x, context):\n",
        "        # `x` is token-IDs shape (batch, target_seq_len)\n",
        "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x  = self.dec_layers[i](x, context)\n",
        "\n",
        "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "        return x"
      ],
      "metadata": {
        "id": "P8_myjAATnb9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "                input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = EncoderT(num_layers=num_layers, d_model=d_model,\n",
        "                                num_heads=num_heads, dff=dff,\n",
        "                                vocab_size=input_vocab_size,\n",
        "                                dropout_rate=dropout_rate)\n",
        "\n",
        "        self.decoder = DecoderT(num_layers=num_layers, d_model=d_model,\n",
        "                                num_heads=num_heads, dff=dff,\n",
        "                                vocab_size=target_vocab_size,\n",
        "                                dropout_rate=dropout_rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "        # first argument.\n",
        "        context, x = inputs\n",
        "\n",
        "        context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "        x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "        # Final linear layer output.\n",
        "        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "        try:\n",
        "            # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "            # b/250038731\n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        # Return the final output and the attention weights.\n",
        "        return logits"
      ],
      "metadata": {
        "id": "X3F7avH3Tnqt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "gE75RbueMKMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training functions"
      ],
      "metadata": {
        "id": "QZzYkh4BMKQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "    mask = label != 0\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "    loss = loss_object(label, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "    pred = tf.argmax(pred, axis=2)\n",
        "    label = tf.cast(label, pred.dtype)\n",
        "    match = label == pred\n",
        "\n",
        "    mask = label != 0\n",
        "\n",
        "    match = match & mask\n",
        "\n",
        "    match = tf.cast(match, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "tJPDgRnQMKVU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used for transformer\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "  \n",
        "  def get_config(self):\n",
        "      config = {\n",
        "      'd_model': self.d_model,\n",
        "      'warmup_steps': self.warmup_steps,\n",
        "\n",
        "        }\n",
        "      return config"
      ],
      "metadata": {
        "id": "KOAN3jYDMKZf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models setup (with hyper-pars)"
      ],
      "metadata": {
        "id": "KkbRafPUMKw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "RNN_UNITS = 32\n",
        "modelRNN = Translator(RNN_UNITS, abs_text_processor, tit_text_processor, GRU=False)\n"
      ],
      "metadata": {
        "id": "Jtyvjc7uVDNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705bfd47-4b57-495a-f16b-b829fe3e57a6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did start- and end-token get stored properly?\n",
            "tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU\n",
        "GRU_UNITS = 32\n",
        "modelGRU = Translator(GRU_UNITS, abs_text_processor, tit_text_processor, GRU=True)"
      ],
      "metadata": {
        "id": "9xL9yyf-VurD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c64942-2cbb-4953-f869-57c63ea83229"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did start- and end-token get stored properly?\n",
            "tf.Tensor(2, shape=(), dtype=int64) tf.Tensor(3, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer hyper pars\n",
        "num_layers = 1\n",
        "d_model = 16\n",
        "dff = 32\n",
        "num_heads = 1 # was 8\n",
        "dropout_rate = 0.1\n",
        "\n",
        "# Training pars\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "# Load model\n",
        "modelT = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=len(abs_text_processor.get_vocabulary()),\n",
        "    target_vocab_size=len(tit_text_processor.get_vocabulary()),\n",
        "    dropout_rate=dropout_rate)"
      ],
      "metadata": {
        "id": "5JOx9eLFVwBL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile"
      ],
      "metadata": {
        "id": "K7ZeY0yuWd4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelGRU.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer='Adam',\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "AWXO-6XOVDU1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelRNN.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer='Adam',\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "JbYQVdOvVDex"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelT.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "B-qpqkWmVDiu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Gv9_kbxBk-s9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train RNN"
      ],
      "metadata": {
        "id": "TW8e8ez8VDm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    historyRNN = modelRNN.fit(train_ds,\n",
        "                            epochs=30,\n",
        "                            validation_data=val_ds,\n",
        "                            callbacks=tf.keras.callbacks.EarlyStopping(\n",
        "                                monitor='val_loss',\n",
        "                                patience=3))"
      ],
      "metadata": {
        "id": "pPtY-POqVDqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151af01a-debf-4801-af77-083f21d63cc9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "136/136 [==============================] - 108s 728ms/step - loss: 7.5685 - masked_accuracy: 0.0506 - val_loss: 6.7872 - val_masked_accuracy: 0.0951\n",
            "Epoch 2/30\n",
            "136/136 [==============================] - 68s 497ms/step - loss: 6.5060 - masked_accuracy: 0.1085 - val_loss: 6.4865 - val_masked_accuracy: 0.1214\n",
            "Epoch 3/30\n",
            "136/136 [==============================] - 53s 390ms/step - loss: 6.0733 - masked_accuracy: 0.1410 - val_loss: 6.2185 - val_masked_accuracy: 0.1549\n",
            "Epoch 4/30\n",
            "136/136 [==============================] - 53s 388ms/step - loss: 5.6849 - masked_accuracy: 0.1774 - val_loss: 6.0577 - val_masked_accuracy: 0.1738\n",
            "Epoch 5/30\n",
            "136/136 [==============================] - 54s 393ms/step - loss: 5.3540 - masked_accuracy: 0.2110 - val_loss: 5.9715 - val_masked_accuracy: 0.1863\n",
            "Epoch 6/30\n",
            "136/136 [==============================] - 53s 388ms/step - loss: 5.0685 - masked_accuracy: 0.2401 - val_loss: 5.9406 - val_masked_accuracy: 0.1888\n",
            "Epoch 7/30\n",
            "136/136 [==============================] - 53s 390ms/step - loss: 4.7991 - masked_accuracy: 0.2656 - val_loss: 5.9212 - val_masked_accuracy: 0.1934\n",
            "Epoch 8/30\n",
            "136/136 [==============================] - 53s 388ms/step - loss: 4.5418 - masked_accuracy: 0.2882 - val_loss: 5.9466 - val_masked_accuracy: 0.1911\n",
            "Epoch 9/30\n",
            "136/136 [==============================] - 53s 386ms/step - loss: 4.3054 - masked_accuracy: 0.3096 - val_loss: 5.9848 - val_masked_accuracy: 0.1891\n",
            "Epoch 10/30\n",
            "136/136 [==============================] - 53s 391ms/step - loss: 4.0839 - masked_accuracy: 0.3298 - val_loss: 6.0693 - val_masked_accuracy: 0.2002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train GRU"
      ],
      "metadata": {
        "id": "JC2vwjx8VDvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    historyGRU = modelGRU.fit(train_ds,\n",
        "                            epochs=30,\n",
        "                            validation_data=val_ds,\n",
        "                            callbacks=tf.keras.callbacks.EarlyStopping(\n",
        "                                monitor='val_loss',\n",
        "                                patience=3))"
      ],
      "metadata": {
        "id": "uv5avzTeVDxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22474f0-3c1c-4807-dcff-5a589ce7e8e6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "136/136 [==============================] - 37s 200ms/step - loss: 7.5511 - masked_accuracy: 0.0942 - val_loss: 6.8085 - val_masked_accuracy: 0.0951\n",
            "Epoch 2/30\n",
            "136/136 [==============================] - 8s 61ms/step - loss: 6.5778 - masked_accuracy: 0.1025 - val_loss: 6.5535 - val_masked_accuracy: 0.1201\n",
            "Epoch 3/30\n",
            "136/136 [==============================] - 8s 61ms/step - loss: 6.1419 - masked_accuracy: 0.1392 - val_loss: 6.2124 - val_masked_accuracy: 0.1519\n",
            "Epoch 4/30\n",
            "136/136 [==============================] - 8s 61ms/step - loss: 5.7337 - masked_accuracy: 0.1760 - val_loss: 6.0225 - val_masked_accuracy: 0.1810\n",
            "Epoch 5/30\n",
            "136/136 [==============================] - 8s 62ms/step - loss: 5.4070 - masked_accuracy: 0.2108 - val_loss: 5.9029 - val_masked_accuracy: 0.1916\n",
            "Epoch 6/30\n",
            "136/136 [==============================] - 8s 62ms/step - loss: 5.1252 - masked_accuracy: 0.2360 - val_loss: 5.8192 - val_masked_accuracy: 0.2005\n",
            "Epoch 7/30\n",
            "136/136 [==============================] - 8s 61ms/step - loss: 4.8617 - masked_accuracy: 0.2586 - val_loss: 5.8051 - val_masked_accuracy: 0.2060\n",
            "Epoch 8/30\n",
            "136/136 [==============================] - 8s 62ms/step - loss: 4.6433 - masked_accuracy: 0.2748 - val_loss: 5.7888 - val_masked_accuracy: 0.2087\n",
            "Epoch 9/30\n",
            "136/136 [==============================] - 8s 61ms/step - loss: 4.4239 - masked_accuracy: 0.2951 - val_loss: 5.8078 - val_masked_accuracy: 0.2063\n",
            "Epoch 10/30\n",
            "136/136 [==============================] - 8s 62ms/step - loss: 4.2067 - masked_accuracy: 0.3152 - val_loss: 5.8745 - val_masked_accuracy: 0.2091\n",
            "Epoch 11/30\n",
            "136/136 [==============================] - 8s 62ms/step - loss: 4.0041 - masked_accuracy: 0.3346 - val_loss: 5.8506 - val_masked_accuracy: 0.2102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Transformer"
      ],
      "metadata": {
        "id": "3-MoQyFAVD2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    historyT = modelT.fit(train_ds,\n",
        "                            epochs=30,\n",
        "                            validation_data=val_ds,\n",
        "                            callbacks=tf.keras.callbacks.EarlyStopping(\n",
        "                                monitor='val_loss',\n",
        "                                patience=3))"
      ],
      "metadata": {
        "id": "hz1cUqc9VD5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a84ab29-f3fe-4f3f-b6c3-c8fb3c2cfb70"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "136/136 [==============================] - 53s 314ms/step - loss: 9.2250 - masked_accuracy: 8.0066e-04 - val_loss: 9.1436 - val_masked_accuracy: 0.0040\n",
            "Epoch 2/30\n",
            "136/136 [==============================] - 4s 32ms/step - loss: 8.9524 - masked_accuracy: 0.0161 - val_loss: 8.7246 - val_masked_accuracy: 0.0284\n",
            "Epoch 3/30\n",
            "136/136 [==============================] - 5s 33ms/step - loss: 8.3556 - masked_accuracy: 0.0274 - val_loss: 8.0338 - val_masked_accuracy: 0.0281\n",
            "Epoch 4/30\n",
            "136/136 [==============================] - 4s 32ms/step - loss: 7.5400 - masked_accuracy: 0.0280 - val_loss: 7.2748 - val_masked_accuracy: 0.0281\n",
            "Epoch 5/30\n",
            "136/136 [==============================] - 4s 31ms/step - loss: 6.8666 - masked_accuracy: 0.0776 - val_loss: 6.9076 - val_masked_accuracy: 0.0951\n",
            "Epoch 6/30\n",
            "136/136 [==============================] - 5s 34ms/step - loss: 6.6124 - masked_accuracy: 0.0968 - val_loss: 6.7817 - val_masked_accuracy: 0.0951\n",
            "Epoch 7/30\n",
            "136/136 [==============================] - 5s 36ms/step - loss: 6.3882 - masked_accuracy: 0.1110 - val_loss: 6.6032 - val_masked_accuracy: 0.1202\n",
            "Epoch 8/30\n",
            "136/136 [==============================] - 4s 32ms/step - loss: 6.1160 - masked_accuracy: 0.1364 - val_loss: 6.4709 - val_masked_accuracy: 0.1516\n",
            "Epoch 9/30\n",
            "136/136 [==============================] - 4s 31ms/step - loss: 5.8756 - masked_accuracy: 0.1577 - val_loss: 6.3874 - val_masked_accuracy: 0.1663\n",
            "Epoch 10/30\n",
            "136/136 [==============================] - 5s 33ms/step - loss: 5.6749 - masked_accuracy: 0.1741 - val_loss: 6.3556 - val_masked_accuracy: 0.1749\n",
            "Epoch 11/30\n",
            "136/136 [==============================] - 5s 34ms/step - loss: 5.5084 - masked_accuracy: 0.1867 - val_loss: 6.4178 - val_masked_accuracy: 0.1814\n",
            "Epoch 12/30\n",
            "136/136 [==============================] - 4s 31ms/step - loss: 5.3594 - masked_accuracy: 0.1992 - val_loss: 6.4199 - val_masked_accuracy: 0.1896\n",
            "Epoch 13/30\n",
            "136/136 [==============================] - 5s 34ms/step - loss: 5.2283 - masked_accuracy: 0.2085 - val_loss: 6.3230 - val_masked_accuracy: 0.1938\n",
            "Epoch 14/30\n",
            "136/136 [==============================] - 5s 34ms/step - loss: 5.1086 - masked_accuracy: 0.2169 - val_loss: 6.2974 - val_masked_accuracy: 0.1956\n",
            "Epoch 15/30\n",
            "136/136 [==============================] - 5s 34ms/step - loss: 4.9818 - masked_accuracy: 0.2263 - val_loss: 6.3207 - val_masked_accuracy: 0.1995\n",
            "Epoch 16/30\n",
            "136/136 [==============================] - 5s 34ms/step - loss: 4.8658 - masked_accuracy: 0.2347 - val_loss: 6.3619 - val_masked_accuracy: 0.2011\n",
            "Epoch 17/30\n",
            "136/136 [==============================] - 4s 32ms/step - loss: 4.7692 - masked_accuracy: 0.2413 - val_loss: 6.2381 - val_masked_accuracy: 0.1995\n",
            "Epoch 18/30\n",
            "136/136 [==============================] - 4s 32ms/step - loss: 4.6494 - masked_accuracy: 0.2504 - val_loss: 6.2410 - val_masked_accuracy: 0.2015\n",
            "Epoch 19/30\n",
            "136/136 [==============================] - 4s 32ms/step - loss: 4.5396 - masked_accuracy: 0.2601 - val_loss: 6.2442 - val_masked_accuracy: 0.2024\n",
            "Epoch 20/30\n",
            "136/136 [==============================] - 4s 32ms/step - loss: 4.4379 - masked_accuracy: 0.2670 - val_loss: 6.2576 - val_masked_accuracy: 0.1995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training summary"
      ],
      "metadata": {
        "id": "NMSoPdJ-VD-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, model_name):\n",
        "    # Acc's\n",
        "    plt.plot(history.history['masked_accuracy'])\n",
        "    plt.plot(history.history['val_masked_accuracy'])\n",
        "    plt.title(f'model accuracy - {model_name}')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(f'model loss - {model_name}')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "518YdRRIVECE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "hJji4JmeXXvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelRNN.summary()"
      ],
      "metadata": {
        "id": "_hJzotmKXIZm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2033b0a-a6e9-4a62-e23a-e1c2ce66bb75"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"translator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_rnn (EncoderRNN)    multiple                  877184    \n",
            "                                                                 \n",
            " decoder_rnn (DecoderRNN)    multiple                  691923    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,569,107\n",
            "Trainable params: 1,569,107\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(historyRNN, f'RNN ({RNN_UNITS})')"
      ],
      "metadata": {
        "id": "thGXlE1iXIow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "bf380876-ed27-4127-d55d-f70fb2992661"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "T5mzL7-NXXLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelGRU.summary()"
      ],
      "metadata": {
        "id": "fypT0ix6XIte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2177f93-1241-47d5-fa41-b9c5c1fd7cc1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"translator_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_rnn_1 (EncoderRNN)  multiple                  881440    \n",
            "                                                                 \n",
            " decoder_rnn_1 (DecoderRNN)  multiple                  696179    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,577,619\n",
            "Trainable params: 1,577,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_history(historyGRU, f'GRU ({GRU_UNITS})')"
      ],
      "metadata": {
        "id": "eO-8LA35XIzq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "4d324bfe-e5b5-44a4-c005-4739a40f8418"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "TaKCfdFsXWKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelT.summary()"
      ],
      "metadata": {
        "id": "sRrzXLb7XWPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbbf988f-4fc1-4b53-ea72-41a08a1c8eca"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_t (EncoderT)        multiple                  439776    \n",
            "                                                                 \n",
            " decoder_t (DecoderT)        multiple                  172096    \n",
            "                                                                 \n",
            " dense_6 (Dense)             multiple                  179299    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 791,171\n",
            "Trainable params: 791,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for naming\n",
        "pars = dict(L = num_layers, emb = d_model, ff = dff, heads = num_heads)\n",
        "\n",
        "s = ''\n",
        "for k, v in pars.items():\n",
        "    s += f'{k}={v}; '\n",
        "s = s[:-2]\n",
        "\n",
        "# plot history\n",
        "plot_history(historyT, f'Transformer ({s})')"
      ],
      "metadata": {
        "id": "XHCgyzq7XWoR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "03661314-5dd3-4093-8c2d-60cdb1903eb4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEWCAYAAABv+EDhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV9f348df7ZocMskiAAGGTMAQJQ4ZiGeKeqHVUrXV8a2v114W2VtvaWru1rmqdrbVaR0VcDAUUAQmI7D0DIZMsyL6f3x/nBG5Cdu5K7vv5eNzHvffM9z33nvO+n8/5nM8RYwxKKaUCj8PXASillPINTQBKKRWgNAEopVSA0gSglFIBShOAUkoFKE0ASikVoLpVAhCRl0Tk4TZOu19EZnV2OYFARKaKyC4RKReRy3wdT1uIyB0i8ldfx+EJLf12/YWIXC4ih+zfzDgRGS4iG0SkTETu9nV8ACLykIj8y0vrWiYi3/HSui4WkdfbMm23SgDdjYhMt3egchE5LiLG5X25iPT3Uii/Ap4wxkQZY/7npXV2mIiEAj8H/mC/T7O3XXAnljlKRD4WkQIR6fIXz4hIqIi8aScTIyIzmpjmTBFZYf/WckXkB+1YxR+B79m/ma+AnwCfGmOijTGPtyPOe0Vkr4iUisgREflL/fcoIr1E5DV7eImIrBSRSe2IscsSkV+LyCYRqRWRh1zHGWPeA0aKyJjWlqMJwI8ZYz6zd6AoYKQ9uGf9MGPMwfppO3Nwa4MBwJaOzOjhuBCRoCYGXwpsN8YcduOqaoA3gFvduExf+xy4ATjaeISIJAIfAX8HEoAhwKJ2LLvxb6ajv6EFwJnGmBhgFHAGUF+CiALWAuOBeOBl4H0RierAerqa3VhJ9f1mxr8G3N7aQryeAOx/HD8WkY32v9rnRSRZRD60i4dLRCTOZfpLRGSLiBTbxah0l3HjRGS9Pd/rQHijdV1kFzuLReSLtmTEZmK+TUR2i0iRiCwQkT72cLH/keTZ/1A2icgoe9wFIrLVju2wiPyoQxus+Zgesv/B/UtESoGbRWSiiKyyP2+OiDxh/xuun8eIyJ12dU6xiDwpImKPGyIiy+1/UgX1RUgR2QMMAt6z/wmGiUgfezsU2dvltlbiWiYiD9vfQbmIvCciCSLyqr3d1opImssyRojIYnv5O0TkapdxL4nI0yLygYgcB85tYvOcDyx35/Y2xuwwxjxPMwcxEXlKRJ5qbv42fKan7H2g3P4nmyIifxWRYyKyXUTGNVrkBPv3dUxEXhSRcNrBGFNtjPmrMeZzoK6JSf4f8LEx5lVjTJUxpswYs80l5oUiMr+JzxkmIuVAEPC1iOwRkU+wvqcn7M83rB1x7jHGFNcvHnBiJSOMMXuNMX82xuQYY+qMMc8CocBwO5b+9u+8pZJyqIi8Yu+nW0Qk0+Wz9BGRt0QkX0T2iUvVVRv2tdn291YiIk/YsdePa3Jfaw9jzMvGmA+BsmYmWQZc2JYFefUB7AdWA8lAXyAPWA+MwzqAfwI8aE87DDgOzAZCsDLebqwvORQ4ANxrj7sK61/aw/a84+xlT8L6Md5krzvMJY5ZzcT4kstyvgEUAGcCYcDfgBX2uPOAdUBPrC84Hehtj8sBptuv47D+xXRmu6UBBgi23z9kf97LsBJ5BNY/oclAsD39NuAel2UYYKEdb38gH5hrj3sN+Jm9rHBgWqPvbJbL+xXAU/Z0Y+3lfKOFuJbZ39tgIBbYCuwEZtmxvgK8aM/fAzgE3GKPG2dv/wyX76YEmFofaxPbai0wr7lt12ja64DiFh79G00/BDDt/O7a8pkK7O+vfh/YB3wL67f7MFb1iev3sRnoh/XPdyWnfq/9W/k81zURXzYwo9GwT4DHgC+w9qP3Gm+LVj6zAYa4vF8GfMfl/fyW4mziOyq1l5kPnNHMOscClUBsG2N8yJ7+Ans7PwKstsc5sPbtX2AdawYBe4Hz7PHN7mtAItaB+SqsY9O9QG3956flfW1jC9vlqSY+w7+Ah5oYHm9vr5gWt0FnDkodedg/3utd3r8FPO3y/vvA/+zXDwBvuIxzAIeBGcDZwBFAXMZ/4bIjPA38utG6dwDnuMTRlgTwPPB7l3FRWAe4NKzksNP+ITgaLeMgcEdrX0A7tlsapyeAFa3Mcw/wTqOd0vXH9gYw3379CvAskNrMdzbLft0P6x9jtMv4R4CXmosLa+f/mcv7PwEfury/GNhgv74G+KzR/H/n1J+Cl4BXWvncu7ATW1PbrpPfQ0cSQFs+03ON9oFtLu9H43JQtL+PO13eXwDs6cRnaioB7MQ66EzAOkg9DqxsxzJbTAAdjHMo8GsgpYlxMcAm4L52LO8hYInL+wygwn49CTjYaPr7sP+oNLGsk/saVuJe7TJO7G1cnwCa3dc6sE2aSwAh9nfQYtL21TmAXJfXFU28r6/D64P1Lx8AY4wT659UX3vcYWN/WtsBl9cDgB/aRbRiESnGOnj1aWesjWMoBwqBvsaYT4AngCeBPBF5VkRi7EmvxNoxD9jFvbOaWrhd7Kw/qTu9nbEdarSsYXbR/Khd/fJbrH8jrlzre09walv/BOuH+qUd07ebWWcfoMgY41r0PID1nTQZl62t3/kAYFKj7+16IKWV5bs6BkS3Mo03teUztXX71HPdBgdo/++6NRVYB7S1xphK4JfAFBGJdfN62swYswurCq5BVZuIRGCVUFYbYx5p52Ib7w/hYp23GgD0afSd3Y9Vc9HavtYHl+/HPka5fl9t3dc6o/73X9zSRP5+EvgI1hcBWHXuWAfxw1hVLH3tYfVc6/oOAb8xxvR0eUQaY17rZAw9sE6KHQYwxjxujBmP9e9hGPBje/haY8ylQC/gf1j/tk9jjBlpTp3U/aydsTVujfI0sB0YaqyTZvfjUvfY4oKMOWqMuc0Y0wer5PKUiAxpYtIjQLyIuB5g+2Nvj2biao9DwPJG31uUMeb/2rH8jVjfRatE5Hpp2LKq8cMdLa3a8pnaq5/L6/5Y30t9vXdLn+f6Ni5/Iw23s1tbPonI/S3F2cKswVhVifXLCcPav7KxfrfucgjY1+g7izbGXGCPb2lfy8Hl+3E5bgEt72uN/hA2fjzTjvjTgf3GmNKWJvL3BPAGcKGIzBSREOCHQBVWVc8qrHq1u0UkRESuACa6zPsccKeITBJLDxG5sNGBqy1eA24RkbH2j+23wBpjzH4RmWAvPwTrXEUl4BSrid31IhJrjKnBqr90dmI7tFW0va5yERkBtPkAIyLzRCTVfnsMa4c/LWZjzCGs7f+IiISLdWL9VqyiqDssBIaJyI329xpib+f0Vuc85QPgnCaGh9kx1z8cxjrJGdXC4yCcPOEfjlUfjD1/WP2CxTqR+5IHP1Njd4lIqojEY9Unvw5gjDnYyud51SXmMDl18jjU/kz1B7EXgcvt330IVnXs58aYEnveZdKo+WF7GGN+21KcLjF+R0R62a8zsKphltrvQ4A3sUorN9k1BLjMW9/8N60DIX4JlInIT0UkQkSCxGoKPMEe39K+9j5WM8wrxCpN3I1Laa+lfa3RH8LGjztdlhFif3cOINj+7lxbxJ0DfNjah/TrBGCM2YHVTO1vWCfJLgYuNlYLhmrgCuBmoAirnvVtl3mzgNuwqmiOYZ2EvLkDMSzB+vG/hZXZBwPX2qNjsBLNMaxieCF223PgRmC/WMXDO7GK/J72I6wTZmV2XO1pXTABWGP/+1oA/MAYs7eZab+JVa9+BHgHqy57SUeDdmVXLc3B2sZHsIroj2KdgG+r94ARYrfWclGOdbCof3yjHcscYM9T3wqoAuucUr1+WCdjT+Omz9TYv7GaZe4F9mCdKG6vHVifoy/wsf16gB3zJ1j/at/HOgk8BOu3Va/Zz+tmU4FNYrX4+sB+3G+PmwJchLVti+X0qtR+WPtlu5sDG2Pq7GWPxTohXwD8A6sRA7SwrxljCoB5wO+wjglDabit2rOvNec5rO/rm1h/ACqwjjn1vol1nqlF0rAKXanuQURux2plc48X1hUKfA2MsUt83Zr97/UNY8wUX8fSEhH5OZBvjGn1QNidiMjFwI3GmKtbnVYTgFJKBSa/rgJSSinlOZoAlFIqQGkCUEqpAOXRjrraKzEx0aSlpfk6DKWU6jLWrVtXYIxJ6si8fpUA0tLSyMrK8nUYSinVZYjIgdanappWASmlVIDSBKCUUgFKE4BSSgUovzoH0JSamhqys7OprKz0dSgeFR4eTmpqKiEhIb4ORSkVIPw+AWRnZxMdHU1aWhoiberYsssxxlBYWEh2djYDBw70dThKqQDh91VAlZWVJCQkdNuDP4CIkJCQ0O1LOUop/+L3CQDo1gf/eoHwGZVS/qVLJIDW5JZWcqK61tdhKKVUl9LlE0BtnZOi49XsyTtOXmkl7u7dtLi4mKeeeqr1CRu54IILKC5u8W5sSinlU10+AQQHORjaK4qYiGCOllayN/841bV1blt+cwmgtrblEscHH3xAz5493RaHUkq5W5dPAADBzir6x4XTLz6Sypo6duWWc+x4tVtKA/Pnz2fPnj2MHTuWCRMmMH36dC655BIyMjIAuOyyyxg/fjwjR47k2WefPTlfWloaBQUF7N+/n/T0dG677TZGjhzJnDlzqKio6HRcSinVWX7fDNTVL9/bwtYjje9xbKD6BDgcEByBMYaqWid1TkNwkBAaHNTiXdEz+sTw4MUjmx3/u9/9js2bN7NhwwaWLVvGhRdeyObNm08213zhhReIj4+noqKCCRMmcOWVV5KQkNBgGbt27eK1117jueee4+qrr+att97ihhtu6OBWUEop9+gGJQCB4FBw1kFtJSJCeEgQocEOap2Giuo66pzuOy8wceLEBm31H3/8cc444wwmT57MoUOH2LVr12nzDBw4kLFjxwIwfvx49u/f77Z4lFKqo7pUCaClf+qUHYWyHOiRBDF9QYSK6loOFlVQVVtHYlQYKTHhOByda27Zo0ePk6+XLVvGkiVLWLVqFZGRkcyYMaPJtvxhYafu/R0UFKRVQEopv+DREoCI/EBENovIFhHx7M25o5Ktg//xfCg/CkBEaDBDe0WREBVGQXkVu/PLqahu3wni6OhoysrKmhxXUlJCXFwckZGRbN++ndWrV3f6YyillLd4rAQgIqOA24CJQDXwkYgsNMbs9tAKrX/+zjqrNCDBEJWEwyH07RlBdHgw2UUV7M4vJyUmnMSo0DZdfJWQkMDUqVMZNWoUERERJCcnnxw3d+5cnnnmGdLT0xk+fDiTJ0/2yEdTSilPEHe3mz+5YJF5wFxjzK32+weAKmPM75ubJzMz0zS+Icy2bdtIT09v+4qNgaJ9UFUCPQdAZPzJUbV1TrKPVVBaWUNUWDCpcZGEBvvPaZB2f1alVMATkXXGmMyOzOvJo99mYLqIJIhIJHAB0M+D67OIQFwahEZB8QGoLDk5KjjIwYCESFLjIjhRXceuvDKKT1R7PCSllPJHHksAxphtwKPAIuAjYANwWgW8iNwuIlkikpWfn++elTscED8IQiLs0kC56/qI7xHG0F5RhAUHcbDoBIeKTlDndLpn3Uop1UV4tP7DGPO8MWa8MeZs4Biws4lpnjXGZBpjMpOSOnRf46Y5giB+MASFQtFe61oBF2EhQQxO6kFyTDjFJ2o4WFTh9m4klFLKn3m6FVAv+7k/cAXwb0+u7zRBIZAwBMQBRXugtmETTREhOSaclNhwyiprKK6o8Wp4SinlS54+A/qWiGwF3gPuMsZ4v3e04FArCQAU7oG60+v8E6NCiQwNJqe4gpo6rQpSSgUGT1cBTTfGZBhjzjDGLPXkuloUEm5VBzlr7STQsCM3ESE1LoI6AznFepGWUiow+E8bSE8LjbRODNdWWdVBzobno8NDgugVHUZxRQ0lnagKioqK6mykSinlFYGTAADCoq0mojUnrNZBpmF1T1J0GOEhQRwprqBWWwUppbq5wEoAABE9oWd/qC6DY/utC8dsDrsqqLbOydES64Tx/PnzefLJJ09O89BDD/Hwww8zc+ZMzjzzTEaPHs27777r7U+hlFKd1qU6g+PD+XB0k3uWVVcNdVWQPBoufcK6gAyIDA0mMTqM/LIqekaEcM0113DPPfdw1113AfDGG2/w8ccfc/fddxMTE0NBQQGTJ0/mkksu0fv6KqW6lK6VANwpKBQwUFsBZUesfoRsydHhlFbUkl1cwZgzxpKXl8eRI0fIz88nLi6OlJQU7r33XlasWIHD4eDw4cPk5uaSkpLiu8+jlFLt1LUSwPm/c+/yjIGSbCjPsxJCD+tCNIdD6BsXwd78cnJLK5k3bx5vvvkmR48e5ZprruHVV18lPz+fdevWERISQlpaWpPdQCullD8LvHMArkQgNhVCo6E0p0Hz0KiwYBJ6hFJQXsXFl1/Jf/7zH958803mzZtHSUkJvXr1IiQkhE8//ZQDBw748EMopVTHBHYCADsJ9AVTd/I+AvVSYsMJCXIQ23sQZWVl9O3bl969e3P99deTlZXF6NGjeeWVVxgxYoSPgldKqY7rWlVAnhISAZEJcLwAIhOtC8eAIIeDvj0j2F94nMWfryUl1hqemJjIqlWrmlxUeXl5k8OVUsrfaAmgXnRvqzRQeqTB4JiIEOIiQ8kvq2r33cSUUsqfaQKoFxRi3VayqgSqGt4CsndsOEEOIfvYCe0xVCnVbXSJBOC1g26PXlZroJLDDS4QCw5y0KdnOBU1dRSUV3lk1ZpYlFLe5vcJIDw8nMLCQu8cIB0OqyqotgIqihqMio0IISY8hNzSKqpq3FsVZIyhsLCQ8PBwty5XKaVa4vcngVNTU8nOzsZtdwtri7ISOLQBolOsewnY6pyG3NJKig47SIwKw50X/oaHh5Oamuq+BSqlVCv8PgGEhIQwcOBA7670YCm8MAdm3Acz5jcYtWXtQX761iYevmwUN0we4N24lFLKjfy+Csgn+k+CkZfDysesC8RcXJ3Zj6lDEvjdh9s5ovcOUEp1YZoAmjPrIesGMp883GCwiPC7K8ZQ5zTc/84mPXmrlOqyNAE0Jy4NJt0JG16FnK8bjOoXH8mPzxvOsh35vLvhSNPzK6WUn9ME0JLpP4TIePj4Zw2ahQLcNCWNM/v35JfvbfFY01CllPIkTQAtiehpnQje/xns+LDBqCCH8OiVYzheVcdDC7b4KECllOo4TQCtGX8LJA6HxQ9AXcN7BQ9Njub73xjCwo05LN6a66MAlVKqYzQBtCYoGOb8Ggp3Q9YLp42+c8ZghvSK4o8f78Dp1BPCSqmuQxNAWwydA4NmwLJHoOJYg1EhQQ6+d+4QduSWsXR7nk/CU0qpjtAE0BYiMOc3UFEMK/542uiLxvSmX3wET3y6W5uFKqW6DE0AbZUyCs68Edb8HQr3NBgVHOTgjrMH8/WhYlbtKfRRgEop1T6aANrj3J9bvYUueei0UVeNTyUpOoynlu05fT6llPJDmgDaIzoZpt0L2xbAgS8ajAoPCeK26QP5fHcBGw4V+yhApZRqO00A7XXWXRDTFz6+H5zOBqOumzSA2IgQnvp0t4+CU0qpttME0F6hkTDzQTjyFWz6b4NRUWHB3DQljUVbc9mZW9bMApRSyj9oAuiI0fOgzzhY+kuoPtFg1C1T0ogMDeJpPReglPJzmgA6wuGA834LpYdh9ZMNRsX1COW6if1Z8PURDhWdaGYBSinle5oAOmrAFEi/GD77C5Q17AbiO9MHESTC31doKUAp5b80AXTGrF9CXTV82vCeASmx4Vw5vi9vZGWTV1rpo+CUUqplHk0AInKviGwRkc0i8pqIdK+7nicMhkl3wPp/wtHNDUbdcfZgauucPP/5Ph8Fp5RSLfNYAhCRvsDdQKYxZhQQBFzrqfX5zNk/srqNXvrLBoPTEntw0Zg+/Gv1AUpO1DQzs1JK+Y6nq4CCgQgRCQYige53+6yIOJj6A9i1CA592WDU/80YzPHqOl5etd8noSmlVEs8lgCMMYeBPwIHgRygxBizqPF0InK7iGSJSFZ+fr6nwvGsCbdBZCJ8+psGg9N7xzArvRcvrNzH8apaHwWnlFJN82QVUBxwKTAQ6AP0EJEbGk9njHnWGJNpjMlMSkryVDieFRZldRGxdxnsX9lg1P/NGELxiRpe+/Kgb2JTSqlmeLIKaBawzxiTb4ypAd4Gpnhwfb414VaISrFKAS5dQo8fEMfkQfE899leqmrrfBigUko15MkEcBCYLCKRIiLATGCbB9fnWyER1k3kD6yEfcsbjLrr3CHkllbxzvrDPgpOKaVO58lzAGuAN4H1wCZ7Xc96an1+YfxNEJMKnzQsBUwbksiY1FieXr6H2jpnCwtQSinv8WgrIGPMg8aYEcaYUcaYG40xVZ5cn88Fh1nNQrO/hN1LTg4WEb47YzAHCk/wweajPgxQKaVO0SuB3W3s9dCz/2nnAuZkpDA4qQdP6W0jlVJ+QhOAuwWHwjk/tbqL3vHBycEOh/DdGUPYfrSMT3fozeOVUr6nCcATxlwL8YPh0982uGnMJWP70LdnBE98oqUApZTvaQLwhKBgmDEfcjfDtndPDg4JcnDnOYNYf7CYNfuKfBigUkppAvCcUVdC0gj49BFwnmr/Py+zH4lRoTypt41USvmYJgBPcQRZpYCCHbD57ZODw0OCuHXaID7bVcCm7BIfBqiUCnSaADwp/VJIHgXLHoG6U30B3TC5P9HhwTy1TEsBSinf0QTgSQ4HzLgPivbAxtdPDo4OD+HmKWl8tOUou/P05vFKKd/QBOBpIy6E3mNh+aNQd+q+ADdPSSMs2MHTy/b6MDilVCDTBOBpInDuz6D4AHz1r5ODE6LC+ObE/ry74TDZx/Tm8Uop79ME4A1DZ0PqBFjxR6g91RvGbdMHIQLPrdBSgFLK+zQBeEN9KaA0G9a9fHJwn54RXDEulf+sPUR+WffuJkkp5X80AXjLoBkwYCp89ieoqTg5+M4Zg6mpc/LcZ1oKUEp5lyYAbxGBc++H8qOQ9cLJwQMTe3D5uFReWrmfA4XHfRigUirQaALwprRpMPAc+PwvUH3qYP+TucMJDhJ+8373vV+OUsr/aALwtm/8HI7nw5en7o2THBPOXecOYdHWXFbuLvBhcEqpQKIJwNv6TYQhs2HlY1BZenLwrdMG0i8+gl+9t1XvGqaU8gpNAL5w7v1QcQzWPHNyUHhIEPefn86O3DJeW3vIh8EppQKFJgBf6HsmDL8QvnjCSgS2uaNSmDwonj8v2kHJiZoWFqCUUp2nCcBXzr0Pqkpg1VMnB4kIv7hoJCUVNfx16U4fBqeUCgSaAHwlZTRkXAqrn4YTp24Ok9Enhmsn9ueVVQe0ozillEdpAvClGfdBdbl1QtjFD2cPIzI0iF8t3Ka3jlRKeYwmAF/qlQ6jr7KahJafulF8QlQYP5g5lBU78/UG8kopj9EE4GvnzIfaSvjgRw1uGvOts9IYlNiDhxduo7pWm4UqpdxPE4CvJQ6BmQ/C1nfhvzed7C00NNjBAxdlsLfgOK+s2u/TEJVS3ZMmAH8w7R44//ewfSH8+5qT3UScO6IX5wxL4rGluygs195ClVLupQnAX0y6Ay59EvYth39eAZXWDeMfuCidiuo6/rRYm4UqpdxLE4A/GXcDXPUCHF4HL18MxwsY0iuaG88awH++PMjWI6WtL0MppdpIE4C/GXk5XPtvyN8BL14ApTncM3MYsREh/GrhFm0WqpRyG00A/mjYHLjhLSg9DC/OJbbqMP9vznBW7y3io81HfR2dUqqb0ATgr9KmwbcWQEUxvDCXb6adYHhyNL/5YBuVNXW+jk4p1Q1oAvBnqePhlg/AWUfwKxfy6FRD9rEKnv98n68jU0p1Ax5LACIyXEQ2uDxKReQeT62v20oeCd/+CIIjGLv0Ru4cVMCTn+4mt7TS15Eppbo4jyUAY8wOY8xYY8xYYDxwAnjHU+vr1hIGW0mgRyI/yfspE50befSj7b6OSinVxXmrCmgmsMcYc8BL6+t+evaDWz7EET+If4T8ntINC9hwqNjXUSmlujBvJYBrgdeaGiEit4tIlohk5efneymcLio6GW5eiKSM5pnQv7D0v09qs1ClVIe1KQGIyA9EJEYsz4vIehGZ08Z5Q4FLgP82Nd4Y86wxJtMYk5mUlNT2yANVZDxBNy+gKGE895b8gQ3/e6zVWZRSqiltLQF82xhTCswB4oAbgd+1cd7zgfXGmNwOxKeaEhZN4u0LWBc6nnFfP0j1Z4/7OiKlVBfU1gQg9vMFwD+NMVtchrXmmzRT/aM6zhEWiePaV1lYN4nQpQ/AG9+yehS1O5JTSqnWBLdxunUisggYCNwnItFAq53Ui0gPYDZwR8dDVM0ZPziFu9N/y5Htj3Hr3hUEbX0XgiNg6CxIvxSGnQfhMb4OUynlp6QtJxFFxAGMBfYaY4pFJB5INcZsdGcwmZmZJisry52L7PYOF1cw80/L6N8zjCenVjC08BPYthDKj0JQKAw6FzIugeEXQGS8r8NVSrmZiKwzxmR2ZN62VgGdBeywD/43AD8HSjqyQuVefXtG8Ny3MimrNpz3LvyGW6n4/mb49scw4TbI2wrv3gV/GAKvXApZLzS4/aRSKnC1tQSwETgDGAO8BPwDuNoYc447g9ESQMeVVdbwyIfb+feag6QlRPLolWOYNCgBjIEjX8G2BbB1ARTtAQQGTIH0i61HbKqvw1dKdVBnSgBtTQDrjTFnisgvgMPGmOfrh3Vkpc3RBNB5X+wu4Kdvb+RQUQU3Th7AT88fQVSYfarHGKtEsHWBlRDytlrD+46HsdfBGddBaKTvgldKtZs3EsBy4CPg28B0IA/42hgzuiMrbY4mAPc4UV3LHz7ewUtf7KdPbASPXDGas4c1cY1FwW7Y9i5seQeOboLIBJh4B0y8Tc8XKNVFeCMBpADXAWuNMZ+JSH9ghjHmlY6stDmaANxr3YEifvzmRvbmH+fqzFR+dmEGsREhp09oDBz4AlY+Brs+hpBIGHcjnHUXxA3wfuBKqTbzeAKwV5IMTLDffmmMcfuZRE0A7ldZU8djS3fx7Iq9JPQI5TeXj2Z2RnLzM+Rtgy/+BhvfAOOEkZfBlOD6WfgAABoqSURBVLuhz1jvBa2UajNvlACuBv4ALMO6AGw68GNjzJsdWWlzNAF4zqbsEn785tdsP1rGJWf04cGLM0iICmt+hpLDsOZpyHoJqstg0AyY+gOrWam09RpApZSneSMBfA3Mrv/XLyJJwBJjzBkdWWlzNAF4VnWtk2eW7+Fvn+wiOjyEX14ykovG9EZaOqBXlkDWi7D6aevagpTRMPUeyLgMgtp6HaFSylO8cR2Ao1GVT2E75lV+IjTYwd0zh7Lw+9PpFxfB91/7ijv+uY68lm4uEx4L0+6BezbCJU9AbRW8dSs8Pg5WP6NdTyjVhbW1BPAHrGsA6vv0uQbYaIz5qTuD0RKA99TWOXlh5T7+tGgnYcEO7rsgnasz+xHkaKV6x+mEnR/BF4/DwVUQEQcTvgOZt0JMb+8Er5Q6yVsnga8EptpvPzPGuP3uXpoAvG9vfjnz397El/uKGNknhgcvHsnEgW1sAnpwjZUItr9vvU+bBiMvh4xLoUei54JWSp3klQTgDZoAfMMYw8KNOTzywTaOlFRy0Zje3HdBOn17RrRtAYV7rFZDW96Ggp0gQTDoHBh5BaRfZJUSlFIe4bEEICJlQFMTCGCMMW7talITgG9VVNfx9xV7eGb5HoyBO88ZzJ3nDCYiNKhtCzAGcjfD5retZHBsPzhCYMhMKxkMP197J1XKzbQEoNzqcHEFv/twO+99fYTeseHcd0E6F7fWWqix+j6INr8FW/4HpdkQFAZDZ8OoK2DYXAjt4bkPoVSA0ASgPOLLfUX88r0tbDlSSuaAOB68eCSjU2PbvyCnE7LXWqWCLe9Aea51tfGwuVYyGDIbQsLd/wGUCgCaAJTH1DkN/806xB8X7aDweDVXj+/Hj84bTlJ0CxeRtcRZZ3U7seVt6w5mJwohNNo6Z5CaCX0zoc84CIty7wdRqpvSBKA8rrSyhic+2c2LK/cRFhzE3TOHcPOUgYQGd+JykLpa2LfcKhUcWAlFe63h4oCkdEgdbyWE1AmQNBwcbTwXoVQA0QSgvGZvfjm/eX8bS7fnMTCxBz+/MJ1vjOjVvvMDzTleCIfXweEsyM6yXlcWW+NCo6ySQX0pITUTolM6v86Oqiq3WjwV7IT8HVBRZJ33wFh9KBlcXtvPmOZfR/e2mtEOmKpNaFW7aAJQXrdsRx6/XriVPfnHmT40kYcuGcngJDdX2xhjNTE9mRCyrG6rnbXW+JjUU6WExGHWgTMywXoOjXJPn0XHC6wDfMEOyN956rk0+9Q0jmCrqas4rAdirbvBa7FfO5p+XXwQauyrqpPSrWRQ/9CEoFqgCUD5RE2dk3+uOsBfluykutbJzy5M58bJA9xTGmh2pRWQs7FhUig+ePp0QWENE0JkYjPvE6FHAlSVuRzgdzT8Z18vJBISh0LSCCvhJA2HxOEQPxCCmuhmuz3qauDIBtj/Gez/HA6ubjohDJgKUU3c26Erqq22+pcqzbHO+fTK0I4GO0ATgPKpvNJKfvzmRpbvzOecYUn8Yd4YekV7sVVPeT4UH7D+rZ8ocHkuPP19TRv6LoqItw/uLgf5pGFWicPhpS6wWkwII1wSwjT/TAiVpVB6BMqOWAd419dlR6z3x/MbztNzwKnblKZO9N627uI0ASifM8bwr9UHePj9bUSGBvHIFWOYO8qHdfTNqaloOkGERtoH+uH+WeVSVwM5X59KCAdWNUwIySMhvCdE9Gz6OTzWeh0W075/2XW1UFVqPSpLrAN7Van1XFlyaviJQig9bB/gc6C6/PRlRcRDTB/rEd274XPpEdi+EPYug7pqiEqGERfCiIsgbToEh7plM3ZHmgCU39idV849r3/F5sOlXJPZjwcuzjh1T2LlPo0TQtFeqCi2Dsamrvn5xGElg8ZJQhwuB3eXA31TB/LGQnpYtxBt6sBe/zq6d9uu9agshV2LYNt7sGuxleTCY2HY+Va3IoNn6n2rG9EEoPxKda2Tx5bu5Olle0iNi+Qv14xl/ADtD8grjLHOZ1TayaCi2Hrd2rNxWgfasBg7QcRAWKzL65gmXsdCWHTnz380p6bCKhFsew92fAAVxyA4AobOghEXw7DzrOQV4DQBKL+0dn8R976+gSPFFXzv3CF8f+ZQQoK0Xld1QF2tda3ItvesqqKyHKv11cCz7XMG9t1qjdPl4dLUttmHa9Nd++Gsa2I5LS3DabVMq6mA2spmnqtaGFdptSL7f1s7tGk0ASi/VVZZw0MLtvLW+mzOSI3lL9eMZZC7m4uqwOJ0WteIbH/PSgj1FxD6i+AICA6DkAgIDm/0HGaNDwl3eQ63EsDZP+rQ6jQBKL/3waYc7n9nE1U1Th64KINvTuzn2eaiKjAYA3lboWDXqeswTntI68MQq9WROKzuzFua3tHEeEfQqQO/l3/XmgBUl5BbWsmP/vs1n+0qYOaIXjx61RgSW7oxvVKqVd64J7BSnZYcE87Lt0zkwYsz+Gx3AXP/uoKl23J9HZZSAUsTgPIqh0O4ZepAFn5/Gr2iw7n15Szuf2cTJ6prfR2aUgFHE4DyiWHJ0bxz1xTuPGcwr315kPP+uoJPd+T5OiylAoomAOUzYcFBzD9/BG/ccRZhwUHc8uJavvvqOo6WVPo6NKUCgkcTgIj0FJE3RWS7iGwTkbM8uT7VNU1Ii+eDu6fz4/OGs3RbHrP+vJwXV+6jzuk/DRSU6o48XQJ4DPjIGDMCOAPY5uH1qS4qNNjBXecOYdG9Z3PmgDh++d5WLntyJRuzi30dmlLdlscSgIjEAmcDzwMYY6qNMbo3qxYNSOjBy7dM4InrxnG0tJLLnlzJQwu2UFZZ4+vQlOp2PFkCGAjkAy+KyFci8g8R6dF4IhG5XUSyRCQrPz//9KWogCMiXDSmD0t/eA43TB7Ay6v2M/NPy3l/Yw7+dN2KUl2dJxNAMHAm8LQxZhxwHJjfeCJjzLPGmExjTGZSkh/2a658JiY8hF9dOop3vjuVxKgw7vr3em55aS2Hik74OjSlugVPJoBsINsYs8Z+/yZWQlCqXcb268mC703lgYsyWLuviNl/Wc6Tn+6mutbp69CU6tI8lgCMMUeBQyIy3B40E+hYd3cq4AUHObh12kCW/PAcZgzrxR8+3sGFj3/Gl/uKWp9ZKdUkT7cC+j7wqohsBMYCv/Xw+lQ31zs2gmduHM/zN2VyorqOq/++ip+8+TVFx6t9HZpSXY52Bqe6rBPVtTy2dBf/+GwfkSFB3Dp9ILdOG0h0uIduUKKUH9LO4FRAigwN5r7z0/nwB9OZMiSBvy7ZxfTff8ozy/dQUd3CbRGVUoCWAFQ3sjG7mD8t2snynfkkRoXxvXMH881J/QkLDvJ1aEp5jN4PQCkXX+4r4o+LdvDlviL6xIZz98yhXDk+VW9HqbolrQJSysXEgfG8fvtk/nXrJJJiwpn/9iZm/3k5//vqsPYvpJQLTQCqWxIRpg1N5H/fncI/vpVJeEgQ97y+gfMfW8FHm/WKYqVAE4Dq5kSEWRnJfHD3dJ64bhy1TsOd/1rPxU98zqc78jQRqICmCUAFBIfD6l9o0T1n88d5Z1B8ooZbXlzLvGdWsWpPoa/DU8on9CSwCkjVtU7eyDrE3z7ZRW5pFRPT4rllahqzM5IJ1pPFqgvRVkBKdVBlTR2vrjnIC5/v43BxBX1iw7nxrDSundCPuB6hvg5PqVZpAlCqk+qchiXbcnlp5X5W7S0kLNjB5eP6ctOUNNJ7x/g6PKWapQlAKTfafrSUl784wDtfZVNZ42TyoHhunjKQWem9tHpI+R1NAEp5QPGJal5fe4hXVh3gcHEFfXtG8K2zBnDNhH70jNTqIeUfNAEo5UG1dU6WbMvj5S+s6qHwEAeXj0vl5ilpDE+J9nV4KsBpAlDKS6zqof2889VhKmucnDUogZunpjErPZkgh/g6PBWANAEo5WXHjlfzetYh/mlXD/WJDeeq8alcNb4f/RMifR2eCiCaAJTykfrqof+sPciKnfk4DUwZnMDVmf2YOyqF8BDtiVR5liYApfxATkkFb63L5o2sbA4WnSA6PJhLzujDNRP6MbpvLCJaRaTcTxOAUn7E6TSs2VfEf7MO8cHmHCprnIxIiWZeZj8uH9eXeL3ATLmRJgCl/FRpZQ0Lv87h9axDfH2omJAgYXZGMvMy+3H20CQ9caw6TROAUl3AjqNlvJF1iHe+OkzR8WpSYqwTx/MyUxmQ0MPX4akuShOAUl1Ida2TT7bn8vraQyy3TxxPSIvjojF9OH9UCr1iwn0doupCNAEo1UUdLankrfXZLNhwhB25ZYjApIHxXGgng8SoMF+HqPycJgCluoFduWUs3JjDwo1H2JN/HIfAWYMTuGhMH84bmaInj1WTNAEo1Y0YY9iRW8b7G3NYuDGHfQXHCXIIU4ckctHo3swZmax9EamTNAEo1U0ZY9iaU3qyZHCoqIKQIGHakEQuHNOHOSOTiQkP8XWYyoc0ASgVAIwxbDpcwsKNOby/MYfDxRWEBjk4e1giF4zuzTdG9NKSQQDSBKBUgDHGsOFQ8clkcLS0kiCHMCEtjtkZKczJSKZfvPZJFAg0ASgVwJxOw8bDJSzeepTFW3PZmVsOwIiUaGZnJDM7I1m7oujGNAEopU46UHicxVtzWbQ1l6z9RTgNpMSEMyujF7MzUjhrUAKhwXpns+5CE4BSqklFx6v5ZHsei7ceZcXOAipq6ogKC+ac4UnMyUhmxvBexEboSeSuTBOAUqpVlTV1rNxdwOKtuSzZlkdBeRXBDmHSoHjOG5nCeSNTSNarkLscTQBKqXZxOg1fHSpm8dZcFm89yp7844jA+P5xnD+6N3NHpdC3Z4Svw1RtoAlAKdUpu3LL+HDzUT7cfJRtOaUAnNGvJ+ePSuH8USnaWZ0f89sEICL7gTKgDqhtLUhNAEr53r6C43y4OYePNh9lY3YJACP7xFjJYHRvBidF+ThC5crfE0CmMaagLdNrAlDKvxwqOsFHm4/y4eYc1h8sBmBYchTnj+rNBaN7Myw5SpuX+pgmAKWUx+WUVNjJ4Chr9xdhDAxK7MH5o60TyKP6xOLQG9x4nT8ngH3AMcAAfzfGPNvENLcDtwP0799//IEDBzwWj1LKPfLKKvl4Sy4fbc5h9d4i6pyG5JgwvjGiFzNHJDN1SCIRoUG+DjMg+HMC6GuMOSwivYDFwPeNMSuam15LAEp1PfXXGnyyPZcVOwsor6olLNjB1CGJzEzvxTdG9KJ3rLYo8hS/TQANViTyEFBujPljc9NoAlCqa6uudbJmXyFLt+WxdHsuh4oqAOsk8sz0ZGaO6MXovlpV5E5+mQBEpAfgMMaU2a8XA78yxnzU3DyaAJTqPowx7M4rZ8k2q3Sw7sAxnAaSosOYOcIqGUwbmkhkaLCvQ+3S/DUBDALesd8GA/82xvympXk0ASjVfRUdr2bZjjyWbs9jxY58yqpqCQ12MHVwAjOG92LyoASG9orS0kE7+WUC6AhNAEoFhupaJ1n7i1hiVxUdKDwBQHyPUCYNjGfSwHgmD05gWK9oTQit0ASglOrSDhWdYPXeQtbsK2L13kKyj1nnDuIiQ5g4MJ7JgxKYPCiB4cmaEBrrTALQyjellM/1i4+kX3wk8zL7AZB97ARr9lrJYPW+Qj7ekgtAz8gQJqbFM2lQApMHxZOeEqMJoRM0ASil/E5qXCSp4yO5cnwqAIeLK1izt9BKCHuLWLTVSgixESFMSItn2pAEZmUkkxqnd0FrD60CUkp1OUeKK1izr5DVe4pYva/w5DmE9N4xzM5IZk5GMiP7xARENxV6DkApFdD2FRw/eUvM+uamfWLD7VtipjBpUDwhQd3zLmiaAJRSylZYXsXS7Xks3prLZ7vyqaxxEh0ezLnDezE7I5kZw5OIDu8+d0HTBKCUUk2oqK7j890FLN56lKXb8ig8Xk1IkDB5UAJzMpKZlZHc5bup0ASglFKtqHMa1h88Zt8FLZd9BccBGN03llnpVsmgK3ZToQlAKaXawRjDnvxyFtnJYMOhYoyxLkQ7e2gi5wxP4uyhSSREhfk61FZpAlBKqU4oLK/i890FLNuRz4qd+RQer0bEKh2cMyyJGcOTOCO1J8F+eCJZE4BSSrmJ02nYfKSE5TvyWbYzn68OWq2KYiNCmDY00UoIw5LoFRPu61ABTQBKKeUxJSdq+Gx3Pst35LN8Zz55ZVWAdc1Bfelg/IA4nzUz1QSglFJeYIxhW04Zy3bmsXxHPusOHKPWaegRGsTEgfFMHZLI1CGJXu2zSBOAUkr5QFllDSt3F/L57nxW7i482bIooUcoZw1OsBLC4ET6J3iuiwrtDE4ppXwgOjyEuaNSmDsqBbC6qFi5u4Av9hSycncBCzfmAJAaF8G0IYlMGZLIlMEJJPpJ6yItASillAfUNzVdudtKBqv2FlJWWQvAiJRopgxOZOqQBCYNSiAqrOP/xbUKSCml/FxtnZPNR0rtEkIBWfuPUVXrJMghjO8fx2u3TyaoA+cNtApIKaX8XHCQg7H9ejK2X0/uOncIlTV1rD9wjJV7Cigsr+7Qwb/TMXl9jUoppQgPCbLOCQxJ9FkM/ndZm1JKKa/QBKCUUgFKE4BSSgUoTQBKKRWgNAEopVSA0gSglFIBShOAUkoFKE0ASikVoPyqKwgRyQcOdHD2RKDAjeG4m8bXORpf52h8nePP8Q0wxiR1ZEa/SgCdISJZHe0Pwxs0vs7R+DpH4+scf4+vo7QKSCmlApQmAKWUClDdKQE86+sAWqHxdY7G1zkaX+f4e3wd0m3OASillGqf7lQCUEop1Q6aAJRSKkB1uQQgInNFZIeI7BaR+U2MDxOR1+3xa0QkzYux9RORT0Vkq4hsEZEfNDHNDBEpEZEN9uMX3orPXv9+Edlkr/u0+2+K5XF7+20UkTO9GNtwl+2yQURKReSeRtN4dfuJyAsikicim12GxYvIYhHZZT/HNTPvTfY0u0TkJi/G9wcR2W5/f++ISM9m5m3xt+DB+B4SkcMu3+EFzczb4r7uwfhed4ltv4hsaGZej28/jzPGdJkHEATsAQYBocDXQEajab4LPGO/vhZ43Yvx9QbOtF9HAzubiG8GsNCH23A/kNjC+AuADwEBJgNrfPhdH8W6yMVn2w84GzgT2Owy7PfAfPv1fODRJuaLB/baz3H26zgvxTcHCLZfP9pUfG35LXgwvoeAH7Xh+29xX/dUfI3G/wn4ha+2n6cfXa0EMBHYbYzZa4ypBv4DXNpomkuBl+3XbwIzRcQrN9s0xuQYY9bbr8uAbUBfb6zbjS4FXjGW1UBPEentgzhmAnuMMR29MtwtjDErgKJGg11/Yy8DlzUx63nAYmNMkTHmGLAYmOuN+Iwxi4wxtfbb1UCqu9fbVs1sv7Zoy77eaS3FZx83rgZec/d6/UVXSwB9gUMu77M5/QB7chp7JygBErwSnQu76mkcsKaJ0WeJyNci8qGIjPRqYGCARSKyTkRub2J8W7axN1xL8zueL7cfQLIxJsd+fRRIbmIaf9mO38Yq0TWltd+CJ33PrqJ6oZkqNH/YftOBXGPMrmbG+3L7uUVXSwBdgohEAW8B9xhjShuNXo9VrXEG8Dfgf14Ob5ox5kzgfOAuETnby+tvlYiEApcA/21itK+3XwPGqgvwy7bUIvIzoBZ4tZlJfPVbeBoYDIwFcrCqWfzRN2n537/f70ut6WoJ4DDQz+V9qj2syWlEJBiIBQq9Ep21zhCsg/+rxpi3G483xpQaY8rt1x8AISKS6K34jDGH7ec84B2sorartmxjTzsfWG+MyW08wtfbz5ZbXy1mP+c1MY1Pt6OI3AxcBFxvJ6nTtOG34BHGmFxjTJ0xxgk818x6fb39goErgNebm8ZX28+duloCWAsMFZGB9r/Ea4EFjaZZANS3uLgK+KS5HcDd7DrD54Ftxpg/NzNNSv05CRGZiPUdeCVBiUgPEYmuf411snBzo8kWAN+yWwNNBkpcqju8pdl/Xr7cfi5cf2M3Ae82Mc3HwBwRibOrOObYwzxOROYCPwEuMcacaGaatvwWPBWf6zmly5tZb1v2dU+aBWw3xmQ3NdKX28+tfH0Wur0PrFYqO7FaCPzMHvYrrB87QDhW1cFu4EtgkBdjm4ZVHbAR2GA/LgDuBO60p/kesAWrVcNqYIoX4xtkr/drO4b67ecanwBP2tt3E5Dp5e+3B9YBPdZlmM+2H1YiygFqsOqhb8U6p7QU2AUsAeLtaTOBf7jM+237d7gbuMWL8e3Gqj+v/w3Wt4rrA3zQ0m/BS/H90/5tbcQ6qPduHJ/9/rR93Rvx2cNfqv/NuUzr9e3n6Yd2BaGUUgGqq1UBKaWUchNNAEopFaA0ASilVIDSBKCUUgFKE4BSSgUoTQBKuYHdS+lCX8ehVHtoAlBKqQClCUAFFBG5QUS+tPtw/7uIBIlIuYj8Rax7OCwVkSR72rEistqlX/04e/gQEVlid0i3XkQG24uPEpE37b74X/VWL7RKdZQmABUwRCQduAaYaowZC9QB12NdfZxljBkJLAcetGd5BfipMWYM1pWr9cNfBZ40Vod0U7CuJAWr99d7gAysK0WnevxDKdUJwb4OQCkvmgmMB9baf84jsDpyc3Kq069/AW+LSCzQ0xiz3B7+MvBfu/+XvsaYdwCMMZUA9vK+NHbfMfZdpNKAzz3/sZTqGE0AKpAI8LIx5r4GA0UeaDRdR/tHqXJ5XYfuX8rPaRWQCiRLgatEpBecvLfvAKz94Cp7muuAz40xJcAxEZluD78RWG6sO71li8hl9jLCRCTSq59CKTfRfygqYBhjtorIz7Hu4uTA6gHyLuA4MNEel4d1ngCsrp6fsQ/we4Fb7OE3An8XkV/Zy5jnxY+hlNtob6Aq4IlIuTEmytdxKOVtWgWklFIBSksASikVoLQEoJRSAUoTgFJKBShNAEopFaA0ASilVIDSBKCUUgHq/wNPaXpfVtJFRgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n",
        "\n",
        "1. Add inference from both branches on git, as implemented. Adjust variable names with above.\n",
        "2. Use same sample from test-set\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-hCKJt_PXWuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_translation(abs, pred, ground_truth):\n",
        "    print(f'{\"Input:\":15s}: {abs}')\n",
        "    print(f'{\"Prediction\":15s}: {pred}')\n",
        "    print(f'{\"Ground truth\":15s}: {ground_truth}')\n",
        "\n",
        "samples = random.sample(range(1087), 6)\n",
        "print(samples)\n",
        "rnn_x1, rnn_y1 = test_text[samples[0]], test_labels[samples[0]]\n",
        "rnn_x2, rnn_y2 = test_text[samples[1]], test_labels[samples[1]]\n",
        "gru_x1, gru_y1 = test_text[samples[2]], test_labels[samples[2]]\n",
        "gru_x2, gru_y2 = test_text[samples[3]], test_labels[samples[3]]\n",
        "tr_x1, tr_y1 = test_text[samples[4]], test_labels[samples[4]]\n",
        "tr_x2, tr_y2 = test_text[samples[5]], test_labels[samples[5]]\n",
        "\n",
        "# y1 = 'recognizing named entities in tweets'\n",
        "# x1 = 'the challenges of named entities recognition ( ner ) for tweets lie in the insufficient information in a tweet and the unavailability of training data . we propose to combine a k-nearest neighbors ( knn ) classifier with a linear conditional random fields ( crf ) model under a semi-supervised learning framework to tackle these challenges . the knn based classifier conducts pre-labeling to collect global coarse evidence across tweets while the crf model conducts sequential labeling to capture fine-grained information encoded in a tweet . the semi-supervised learning plus the gazetteers alleviate the lack of training data . extensive experiments show the advantages of our method over the baselines as well as the effectiveness of knn and semisupervised learning .'\n",
        "\n",
        "# y2 = 'interactive grammar development with wcdg'\n",
        "# x2 = 'the manual design of grammars for accurate natural language analysis is an iterative process ; while modelling decisions usually determine parser behaviour , evidence from analysing more or different input can suggest unforeseen regularities , which leads to a reformulation of rules , or even to a different model of previously analysed phenomena . we describe an implementation of weighted constraint dependency grammar that supports the grammar writer by providing display , automatic analysis , and diagnosis of dependency analyses and allows the direct exploration of alternative analyses and their status under the current grammar .'"
      ],
      "metadata": {
        "id": "jwSIBv_ofnln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212efc6e-29ed-44e3-8eea-c6ca63226cc7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[490, 739, 816, 775, 117, 729]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN"
      ],
      "metadata": {
        "id": "-ruIbY49YfKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_yhat1 = modelRNN.translate([rnn_x1])\n",
        "rnn_yhat2 = modelRNN.translate([rnn_x2])\n",
        "\n",
        "print_translation(rnn_x1, rnn_yhat1[0].numpy().decode(), rnn_y1)\n",
        "print_translation(rnn_x2, rnn_yhat2[0].numpy().decode(), rnn_y2)"
      ],
      "metadata": {
        "id": "4QVH8z1wYgpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d09301-b8e1-4cfa-9478-71b886590605"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : we propose a solution to the annotation bottleneck for statistical parsing , by exploiting the lexicalized nature of combinatory categorial grammar ( ccg ) . the parsing model uses predicate-argument dependencies for training , which are derived from sequences of ccg lexical categories rather than full derivations . a simple method is used for extracting dependencies from lexical category sequences , resulting in high precision , yet incomplete and noisy data . the dependency parsing model of clark and curran ( 2004b ) is extended to exploit this partial training data . remarkably , the accuracy of the parser trained on data derived from category sequences alone is only 1.3 % worse in terms of f-score than the parser trained on complete dependency structures .\n",
            "Prediction     : unsupervised learning of bilingual text classification using latent variable models \n",
            "Ground truth   : partial training for a lexicalized-grammar parser\n",
            "Input:         : this paper describes a probabilistic model for coordination disambiguation integrated into syntactic and case structure analysis . our model probabilistically assesses the parallelism of a candidate coordinate structure using syntactic/semantic similarities and cooccurrence statistics . we integrate these probabilities into the framework of fully-lexicalized parsing based on largescale case frames . this approach simultaneously addresses two tasks of coordination disambiguation : the detection of coordinate conjunctions and the scope disambiguation of coordinate structures . experimental results on web sentences indicate the effectiveness of our approach .\n",
            "Prediction     : a probabilistic model for unsupervised word sense disambiguation \n",
            "Ground truth   : probabilistic coordination disambiguation in a fully-lexicalized japanese parser\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "RX2SIIsyYg9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_yhat1 = modelGRU.translate([gru_x1])\n",
        "gru_yhat2 = modelGRU.translate([gru_x2])\n",
        "\n",
        "print_translation(gru_x1, gru_yhat1[0].numpy().decode(), gru_y1)\n",
        "print_translation(gru_x2, gru_yhat2[0].numpy().decode(), gru_y2)"
      ],
      "metadata": {
        "id": "UYIFwbO3YhCP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695dddb2-546d-4520-b5d3-fad681d91a20"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : towards deep analysis of compositional classes of paraphrases , we have examined a class-oriented framework for collecting paraphrase examples , in which sentential paraphrases are collected for each paraphrase class separately by means of automatic candidate generation and manual judgement . our preliminary experiments on building a paraphrase corpus have so far been producing promising results , which we have evaluated according to cost-efficiency , exhaustiveness , and reliability .\n",
            "Prediction     : a hybrid approach to automatic generation of language understanding \n",
            "Ground truth   : a class-oriented approach to building a paraphrase corpus\n",
            "Input:         : classifying what-type questions into proper semantic categories is found more challenging than classifying other types in question answering systems . in this paper , we propose to classify what-type questions by head noun tagging . the approach highlights the role of head nouns as the category discriminator of whattype questions . to reduce the semantic ambiguities of head noun , we integrate local syntactic feature , semantic feature and category dependency among adjacent nouns with conditional random fields ( crfs ) . experiments on standard question classification data set show that the approach achieves state-of-the-art performances .\n",
            "Prediction     : a hybrid approach to named entity recognition in a large scale information retrieval \n",
            "Ground truth   : classifying what-type questions by head noun tagging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "mOtapooZYhPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslatorT(tf.Module):\n",
        "  def __init__(self, tokenizer, detokenizer, transformer):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.detokenizer = detokenizer\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence):\n",
        "    # The input sentence is an abstract, hence adding the `[START]` and `[END]` tokens.\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    # TODO: use our own tokenizer\n",
        "    sentence = self.tokenizer(sentence).to_tensor()\n",
        "\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # As the output language a title, initialize the output with the\n",
        "    # `[START]` token.\n",
        "    # TODO: look up how to tokenize this\n",
        "    start_end = self.detokenizer([''])[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    # 50 is an arbitrary break-point\n",
        "    for i in tf.range(50):\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "      # Select the last token from the `seq_len` dimension.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate the `predicted_id` to the output which is given to the\n",
        "      # decoder as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "\n",
        "    tit_vocab = np.array(self.detokenizer.get_vocabulary())\n",
        "    tokens = tit_vocab[output.numpy()]\n",
        "    text = [' '.join(tok) for tok in tokens]\n",
        "\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    # text = self.detokenizer(output)[0]  # Shape: `()`.\n",
        "\n",
        "    #tokens = self.detokenizer lookup(output)[0]\n",
        "\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop.\n",
        "    # So, recalculate them outside the loop.\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    # return text, tokens, attention_weights\n",
        "    return text, attention_weights\n"
      ],
      "metadata": {
        "id": "tk8d_jb1YknO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transT = TranslatorT(abs_text_processor, tit_text_processor, modelT)"
      ],
      "metadata": {
        "id": "YZCEyih9e9Wt"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_yhat1, _ = transT(tf.constant(tr_x1))\n",
        "t_yhat2, _ = transT(tf.constant(tr_x2))\n",
        "\n",
        "t_yhat1 = t_yhat1[0].replace('[START] ', '').replace(' [END]', '')\n",
        "t_yhat2 = t_yhat2[0].replace('[START] ', '').replace(' [END]', '')\n",
        "\n",
        "print_translation(tr_x1, t_yhat1, tr_y1)\n",
        "print_translation(tr_x2, t_yhat2, tr_y2)"
      ],
      "metadata": {
        "id": "yHIHRv3_fIBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "215a1e36-14e6-459b-8edd-6139de8e4409"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : spoken language translation systems have usually been produced for such specific domains as health care or military use . ideally , such systems would be easily portable to other domains in which translation is mission critical , such as emergency response or law enforcement . however , porting has in practice proven difficult . this paper will comment on the sources of this difficulty and briefly present an approach to rapid inter-domain portability . three aspects will be discussed : ( 1 ) large general-purpose lexicons for automatic speech recognition and machine translation , made reliable and usable through interactive facilities for monitoring and correcting errors ; ( 2 ) easily modifiable facilities for instant translation of frequent phrases ; and ( 3 ) quickly modifiable custom glossaries . as support for our approach , we apply our current slt system , now optimized for the health care domain , to sample utterances from the military , emergency service , and law enforcement domains , with discussion of numerous specific sentences .\n",
            "Prediction     : learning of a hybrid model for spoken dialogue systems\n",
            "Ground truth   : rapid portability among domains in an interactive spoken language translation system\n",
            "Input:         : this paper presents an evaluation of indirect anaphor resolution which considers as lexical resource the semantic tagging provided by the palavras parser . we describe the semantic tagging process and a corpus experiment .\n",
            "Prediction     : a probabilistic model for unsupervised word sense disambiguation\n",
            "Ground truth   : semantic tagging for resolution of indirect anaphora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BestScore\n",
        "\n",
        "- https://github.com/Tiiiger/bert_score/blob/master/example/Demo.ipynb"
      ],
      "metadata": {
        "id": "jXsR9llQYlpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Tiiiger/bert_score\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "YCVDzIbrYlx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbbd44cc-026d-4d93-e712-60d6a32954a0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/Tiiiger/bert_score\n",
            "  Cloning https://github.com/Tiiiger/bert_score to /tmp/pip-req-build-4t1bvwii\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Tiiiger/bert_score /tmp/pip-req-build-4t1bvwii\n",
            "  Resolved https://github.com/Tiiiger/bert_score to commit cb582ed5c88b02230b8f101173fd959b68023dc6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from bert-score==0.3.12) (1.13.1+cu116)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from bert-score==0.3.12) (1.3.5)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from bert-score==0.3.12) (4.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bert-score==0.3.12) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from bert-score==0.3.12) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.8/dist-packages (from bert-score==0.3.12) (4.64.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from bert-score==0.3.12) (3.2.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from bert-score==0.3.12) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->bert-score==0.3.12) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->bert-score==0.3.12) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.1->bert-score==0.3.12) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.0.0->bert-score==0.3.12) (4.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score==0.3.12) (0.11.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score==0.3.12) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score==0.3.12) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score==0.3.12) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=3.0.0->bert-score==0.3.12) (6.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score==0.3.12) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->bert-score==0.3.12) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->bert-score==0.3.12) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->bert-score==0.3.12) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->bert-score==0.3.12) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->bert-score==0.3.12) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert-score==0.3.12) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_score import BERTScorer\n",
        "import logging\n",
        "import transformers"
      ],
      "metadata": {
        "id": "Yb9FBsdPkUgs"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformers.tokenization_utils.logger.setLevel(logging.ERROR)\n",
        "transformers.configuration_utils.logger.setLevel(logging.ERROR)\n",
        "transformers.modeling_utils.logger.setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "ixsHKxl-kVcO"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)"
      ],
      "metadata": {
        "id": "o9p64fnCYl2K"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_titles = [\n",
        "    'example generated title 1',\n",
        "    'example generated title 2',\n",
        "    'example generated title 3'\n",
        "    ]\n",
        "\n",
        "actual_titles = [\n",
        "    'example actual title 1',\n",
        "    'example actual title 2',\n",
        "    'example actual title 3'\n",
        "    ]\n",
        "\n",
        "# Precision, Recall, F1 scores \n",
        "# len(actual_titles) == len(generated_titles) == len(P) == len(R) == len(F1)\n",
        "P, R, F1 = scorer.score(generated_titles, actual_titles)"
      ],
      "metadata": {
        "id": "dIVmevkbYl6C"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P, R, F1"
      ],
      "metadata": {
        "id": "vopMYh9wYl9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe55283-59ae-46e9-81a7-081510b25bd5"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.7109, 0.7012, 0.6989]),\n",
              " tensor([0.7423, 0.7290, 0.7283]),\n",
              " tensor([0.7270, 0.7155, 0.7140]))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "P, R, F1 = scorer.score([rnn_yhat1.numpy()[0].decode('utf-8'),\n",
        "                         rnn_yhat2.numpy()[0].decode('utf-8')], \n",
        "                        [rnn_y1, rnn_y2])\n",
        "P, R, F1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR269xVfn-pK",
        "outputId": "b5be1c53-ba3d-49ad-e418-f3f696336066"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0229,  0.0186]),\n",
              " tensor([0.1963, 0.1946]),\n",
              " tensor([0.0858, 0.1065]))"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = rnn_x1\n",
        "x2 = rnn_x2\n",
        "y1, y2 = rnn_y1, rnn_y2\n",
        "\n",
        "rnn_yhat1 = modelRNN.translate([x1])\n",
        "rnn_yhat2 = modelRNN.translate([x2])\n",
        "\n",
        "print_translation(x1, rnn_yhat1[0].numpy().decode(), y1)\n",
        "print_translation(x2, rnn_yhat2[0].numpy().decode(), y2)\n",
        "print()\n",
        "\n",
        "gru_yhat1 = modelGRU.translate([x1])\n",
        "gru_yhat2 = modelGRU.translate([x2])\n",
        "\n",
        "print_translation(x1, gru_yhat1[0].numpy().decode(), y1)\n",
        "print_translation(x2, gru_yhat2[0].numpy().decode(), y2)\n",
        "print()\n",
        "\n",
        "t_yhat1, _ = transT(tf.constant(x1))\n",
        "t_yhat2, _ = transT(tf.constant(x2))\n",
        "\n",
        "t_yhat1 = t_yhat1[0].replace('[START] ', '').replace(' [END]', '')\n",
        "t_yhat2 = t_yhat2[0].replace('[START] ', '').replace(' [END]', '')\n",
        "\n",
        "print_translation(x1, t_yhat1, y1)\n",
        "print_translation(x2, t_yhat2, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xXdFdhZ144K",
        "outputId": "af96e715-3607-4327-eb49-063cf0f0b9a0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : we propose a solution to the annotation bottleneck for statistical parsing , by exploiting the lexicalized nature of combinatory categorial grammar ( ccg ) . the parsing model uses predicate-argument dependencies for training , which are derived from sequences of ccg lexical categories rather than full derivations . a simple method is used for extracting dependencies from lexical category sequences , resulting in high precision , yet incomplete and noisy data . the dependency parsing model of clark and curran ( 2004b ) is extended to exploit this partial training data . remarkably , the accuracy of the parser trained on data derived from category sequences alone is only 1.3 % worse in terms of f-score than the parser trained on complete dependency structures .\n",
            "Prediction     : unsupervised learning of bilingual text classification using latent variable models \n",
            "Ground truth   : partial training for a lexicalized-grammar parser\n",
            "Input:         : this paper describes a probabilistic model for coordination disambiguation integrated into syntactic and case structure analysis . our model probabilistically assesses the parallelism of a candidate coordinate structure using syntactic/semantic similarities and cooccurrence statistics . we integrate these probabilities into the framework of fully-lexicalized parsing based on largescale case frames . this approach simultaneously addresses two tasks of coordination disambiguation : the detection of coordinate conjunctions and the scope disambiguation of coordinate structures . experimental results on web sentences indicate the effectiveness of our approach .\n",
            "Prediction     : a probabilistic model for unsupervised word sense disambiguation \n",
            "Ground truth   : probabilistic coordination disambiguation in a fully-lexicalized japanese parser\n",
            "\n",
            "Input:         : we propose a solution to the annotation bottleneck for statistical parsing , by exploiting the lexicalized nature of combinatory categorial grammar ( ccg ) . the parsing model uses predicate-argument dependencies for training , which are derived from sequences of ccg lexical categories rather than full derivations . a simple method is used for extracting dependencies from lexical category sequences , resulting in high precision , yet incomplete and noisy data . the dependency parsing model of clark and curran ( 2004b ) is extended to exploit this partial training data . remarkably , the accuracy of the parser trained on data derived from category sequences alone is only 1.3 % worse in terms of f-score than the parser trained on complete dependency structures .\n",
            "Prediction     : a hybrid approach to automatic generation of language understanding \n",
            "Ground truth   : partial training for a lexicalized-grammar parser\n",
            "Input:         : this paper describes a probabilistic model for coordination disambiguation integrated into syntactic and case structure analysis . our model probabilistically assesses the parallelism of a candidate coordinate structure using syntactic/semantic similarities and cooccurrence statistics . we integrate these probabilities into the framework of fully-lexicalized parsing based on largescale case frames . this approach simultaneously addresses two tasks of coordination disambiguation : the detection of coordinate conjunctions and the scope disambiguation of coordinate structures . experimental results on web sentences indicate the effectiveness of our approach .\n",
            "Prediction     : a hybrid approach to named entity recognition in a large scale information retrieval \n",
            "Ground truth   : probabilistic coordination disambiguation in a fully-lexicalized japanese parser\n",
            "\n",
            "Input:         : we propose a solution to the annotation bottleneck for statistical parsing , by exploiting the lexicalized nature of combinatory categorial grammar ( ccg ) . the parsing model uses predicate-argument dependencies for training , which are derived from sequences of ccg lexical categories rather than full derivations . a simple method is used for extracting dependencies from lexical category sequences , resulting in high precision , yet incomplete and noisy data . the dependency parsing model of clark and curran ( 2004b ) is extended to exploit this partial training data . remarkably , the accuracy of the parser trained on data derived from category sequences alone is only 1.3 % worse in terms of f-score than the parser trained on complete dependency structures .\n",
            "Prediction     : joint parsing with dependency parsing with dependency parsing\n",
            "Ground truth   : partial training for a lexicalized-grammar parser\n",
            "Input:         : this paper describes a probabilistic model for coordination disambiguation integrated into syntactic and case structure analysis . our model probabilistically assesses the parallelism of a candidate coordinate structure using syntactic/semantic similarities and cooccurrence statistics . we integrate these probabilities into the framework of fully-lexicalized parsing based on largescale case frames . this approach simultaneously addresses two tasks of coordination disambiguation : the detection of coordinate conjunctions and the scope disambiguation of coordinate structures . experimental results on web sentences indicate the effectiveness of our approach .\n",
            "Prediction     : joint parsing of word alignment for parsing\n",
            "Ground truth   : probabilistic coordination disambiguation in a fully-lexicalized japanese parser\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test results"
      ],
      "metadata": {
        "id": "GxBhj-zZ3Fzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_preds, gru_preds, tra_preds = [], [], []\n",
        "counter = 0\n",
        "for text in test_text:\n",
        "    rnn_preds.append(modelRNN.translate([text])[0].numpy().decode())\n",
        "    gru_preds.append(modelGRU.translate([text])[0].numpy().decode())\n",
        "    \n",
        "    tp, _ = transT(tf.constant(text))\n",
        "    tp = tp[0].replace('[START] ', '').replace(' [END]', '')\n",
        "    \n",
        "    tra_preds.append(tp)\n",
        "\n",
        "    counter+=1\n",
        "    if counter % 100 == 0:\n",
        "        print(f'{counter/len(test_labels)}%')\n",
        "\n",
        "rnn_P, rnn_R, rnn_F1 = scorer.score(rnn_preds, test_labels)\n",
        "gru_P, gru_R, gru_F1 = scorer.score(gru_preds, test_labels)\n",
        "tra_P, tra_R, tra_F1 = scorer.score(tra_preds, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "PbvrSTms3i9n",
        "outputId": "112027ea-8084-4318-8d6a-cc6e2752883e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09199632014719411%\n",
            "0.18399264029438822%\n",
            "0.27598896044158233%\n",
            "0.36798528058877644%\n",
            "0.45998160073597055%\n",
            "0.5519779208831647%\n",
            "0.6439742410303588%\n",
            "0.7359705611775529%\n",
            "0.827966881324747%\n",
            "0.9199632014719411%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-7cd5cca72a11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mrnn_P\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_R\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_F1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgru_P\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_R\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_F1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtra_P\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtra_R\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtra_F1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtra_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/bert_score/scorer.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, cands, refs, verbose, batch_size, return_hash)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0midf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_token_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         all_preds = bert_cos_score_idf(\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mbert_cos_score_idf\u001b[0;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdedup_and_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhyps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m     \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0miter_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/bert_score/utils.py\u001b[0m in \u001b[0;36mdedup_and_sort\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdedup_and_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdedup_and_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhyps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_P.mean(), rnn_R.mean(), rnn_F1.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx9ajO9-5IZR",
        "outputId": "e287cd74-705a-4fed-a1bb-c8af48389ee3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0815), tensor(0.0960), tensor(0.0884))"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tra_preds2 = []\n",
        "for tp, _ in tra_preds:\n",
        "    tp = tp[0].replace('[START] ', '').replace(' [END]', '')\n",
        "    tra_preds2.append(tp)\n",
        "tra_P, tra_R, tra_F1 = scorer.score(tra_preds2, test_labels)"
      ],
      "metadata": {
        "id": "UyXt2iXs5QB8"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rnn_P.mean(), rnn_R.mean(), rnn_F1.mean())\n",
        "print(gru_P.mean(), gru_R.mean(), gru_F1.mean())\n",
        "print(tra_P.mean(), tra_R.mean(), tra_F1.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k3LbGEXEiis",
        "outputId": "8cef365e-a7e1-4262-b6a3-46e3155dd329"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0815) tensor(0.0960) tensor(0.0884)\n",
            "tensor(0.1782) tensor(0.0811) tensor(0.1289)\n",
            "tensor(0.2131) tensor(0.0697) tensor(0.1401)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rnn_P.std(), rnn_R.std(), rnn_F1.std())\n",
        "print(gru_P.std(), gru_R.std(), gru_F1.std())\n",
        "print(tra_P.std(), tra_R.std(), tra_F1.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1cc_YInFTYy",
        "outputId": "090533f6-4235-4495-b4c8-a5cebc49945f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1721) tensor(0.1838) tensor(0.1504)\n",
            "tensor(0.2354) tensor(0.2438) tensor(0.2212)\n",
            "tensor(0.1766) tensor(0.1913) tensor(0.1605)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tra_F1.argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cVUHZO-FbrF",
        "outputId": "d18fadac-ab15-4c44-c473-635030d9fa6c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(677)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tra_preds2[677], test_labels[677]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qvXEFa8Fh3j",
        "outputId": "2c45946b-6135-4a69-de76-0994ebee8238"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('unsupervised relation extraction from web documents',\n",
              " 'unsupervised relation extraction from web documents')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text[677]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "EemjnqpWFmVO",
        "outputId": "ce2df5e2-9984-4065-db36-12b88faadaba"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the idex system is a prototype of an interactive dynamic information extraction ( ie ) system . a user of the system expresses an information request in the form of a topic description , which is used for an initial search in order to retrieve a relevant set of documents . on basis of this set of documents , unsupervised relation extraction and clustering is done by the system . the results of these operations can then be interactively inspected by the user . in this paper we describe the relation extraction and clustering components of the idex system . preliminary evaluation results of these components are presented and an overview is given of possible enhancements to improve the relation extraction and clustering components .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(tra_F1)\n",
        "plt.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "9bjezHh1GYLD",
        "outputId": "54b65bf8-053d-425c-bc1a-705c0d7c209b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVGsC_keGj7m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}