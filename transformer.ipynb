{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtjon/infompr-group-project/blob/feature%2Ftransformer/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7f697fec28a"
      },
      "source": [
        "##### Copyright 2022 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T12:27:23.942469Z",
          "iopub.status.busy": "2022-12-14T12:27:23.941862Z",
          "iopub.status.idle": "2022-12-14T12:27:23.946032Z",
          "shell.execute_reply": "2022-12-14T12:27:23.945457Z"
        },
        "id": "GpAXuTgZ888M",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a934948f7030"
      },
      "source": [
        "# Neural machine translation with a Transformer and Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a241496dc3d9"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/transformer\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/transformer.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCg3ElKBUSBb"
      },
      "source": [
        "This tutorial demonstrates how to create and train a [sequence-to-sequence](https://developers.google.com/machine-learning/glossary#sequence-to-sequence-task) [Transformer](https://developers.google.com/machine-learning/glossary#Transformer) model to translate [Portuguese into English](https://www.tensorflow.org/datasets/catalog/ted_hrlr_translate#ted_hrlr_translatept_to_en). The Transformer was originally proposed in [\"Attention is all you need\"](https://arxiv.org/abs/1706.03762) by Vaswani et al. (2017).\n",
        "\n",
        "Transformers are deep neural networks that replace CNNs and RNNs with [self-attention](https://developers.google.com/machine-learning/glossary#self-attention). Self attention allows Transformers to easily transmit information across the input sequences.\n",
        "\n",
        "As explained in the [Google AI Blog post](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html):\n",
        "\n",
        "> Neural networks for machine translation typically contain an encoder reading the input sentence and generating a representation of it. A decoder then generates the output sentence word by word while consulting the representation generated by the encoder. The Transformer starts by generating initial representations, or embeddings, for each word... Then, using self-attention, it aggregates information from all of the other words, generating a new representation per word informed by the entire context, represented by the filled balls. This step is then repeated multiple times in parallel for all words, successively generating new representations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo1P7AN4lzdi"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/apply_the_transformer_to_machine_translation.gif\" alt=\"Applying the Transformer to machine translation\">\n",
        "\n",
        "Figure 1: Applying the Transformer to machine translation. Source: [Google AI Blog](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAxfGTJJYbQi"
      },
      "source": [
        "That's a lot to digest, the goal of this tutorial is to break it down into easy to understand parts. In this tutorial you will:\n",
        "\n",
        "- Prepare the data.\n",
        "- Implement necessary components:\n",
        "  - Positional embeddings.\n",
        "  - Attention layers.\n",
        "  - The encoder and decoder.\n",
        "- Build & train the Transformer.\n",
        "- Generate translations.\n",
        "- Export the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddvOmAXhaDXt"
      },
      "source": [
        "To get the most out of this tutorial, it helps if you know about [the basics of text generation](./text_generation.ipynb) and attention mechanisms. \n",
        "\n",
        "A Transformer is a sequence-to-sequence encoder-decoder model similar to the model in the [NMT with attention tutorial](https://www.tensorflow.org/text/tutorials/nmt_with_attention).\n",
        "A single-layer Transformer takes a little more code to write, but is almost identical to that encoder-decoder RNN model. The only difference is that the RNN layers are replaced with self attention layers.\n",
        "This tutorial builds a 4-layer Transformer which is larger and more powerful, but not fundamentally more complex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk40oPm8OD51"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "  <th>The <a href=https://www.tensorflow.org/text/tutorials/nmt_with_attention>RNN+Attention model</a></th>\n",
        "  <th>A 1-layer transformer</th>\n",
        "</tr>\n",
        "<tr>\n",
        "  <td>\n",
        "   <img width=411 src=\"https://www.tensorflow.org/images/tutorials/transformer/RNN+attention-words.png\"/>\n",
        "  </td>\n",
        "  <td>\n",
        "   <img width=400 src=\"https://www.tensorflow.org/images/tutorials/transformer/Transformer-1layer-words.png\"/>\n",
        "  </td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huJ97Eh-Ue4V"
      },
      "source": [
        "After training the model in this notebook, you will be able to input a Portuguese sentence and return the English translation.\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/attention_map_portuguese.png\" alt=\"Attention heatmap\">\n",
        "\n",
        "Figure 2: Visualized attention weights that you can generate at the end of this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZL6uTTE5137"
      },
      "source": [
        "## Why Transformers are significant\n",
        "\n",
        "- Transformers excel at modeling sequential data, such as natural language.\n",
        "- Unlike the [recurrent neural networks (RNNs)](./text_generation.ipynb), Transformers are parallelizable. This makes them efficient on hardware like GPUs and TPUs. The main reasons is that Transformers replaced recurrence with attention, and computations can happen simultaneously. Layer outputs can be computed in parallel, instead of a series like an RNN.\n",
        "- Unlike [RNNs](https://www.tensorflow.org/guide/keras/rnn) (like [seq2seq, 2014](https://arxiv.org/abs/1409.3215)) or [convolutional neural networks (CNNs)](https://www.tensorflow.org/tutorials/images/cnn) (for example, [ByteNet](https://arxiv.org/abs/1610.10099)), Transformers are able to capture distant or long-range contexts and dependencies in the data between distant positions in the input or output sequences. Thus, longer connections can be learned. Attention allows each location to have access to the entire input at each layer, while in RNNs and CNNs, the information needs to pass through many processing steps to move a long distance, which makes it harder to learn.\n",
        "- Transformers make no assumptions about the temporal/spatial relationships across the data. This is ideal for processing a set of objects (for example, [StarCraft units](https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii)).\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/encoder_self_attention_distribution.png\" width=\"800\" alt=\"Encoder self-attention distribution for the word it from the 5th to the 6th layer of a Transformer trained on English-to-French translation\">\n",
        "\n",
        "Figure 3: The encoder self-attention distribution for the word “it” from the 5th to the 6th layer of a Transformer trained on English-to-French translation (one of eight attention heads). Source: [Google AI Blog](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swymtxpl7W7w"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfV1batAwq9j"
      },
      "source": [
        "Begin by installing [TensorFlow Datasets](https://tensorflow.org/datasets) for loading the dataset and [TensorFlow Text](https://www.tensorflow.org/text) for text preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T12:27:23.950400Z",
          "iopub.status.busy": "2022-12-14T12:27:23.949816Z",
          "iopub.status.idle": "2022-12-14T12:27:51.412794Z",
          "shell.execute_reply": "2022-12-14T12:27:51.411793Z"
        },
        "id": "XFG0NDRu5mYQ"
      },
      "outputs": [],
      "source": [
        "# Install the most re version of TensorFlow to use the improved\n",
        "# masking support for `tf.keras.layers.MultiHeadAttention`.\n",
        "#!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "#!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
        "#!pip install -q tensorflow_datasets\n",
        "# !pip install -q -U tensorflow-text==2.9.* tensorflow==2.9.*\n",
        "#!pip install -q -U tensorflow-text tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GYpLBSjxJmG"
      },
      "source": [
        "Import the necessary modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T12:27:51.417726Z",
          "iopub.status.busy": "2022-12-14T12:27:51.417012Z",
          "iopub.status.idle": "2022-12-14T12:27:54.278760Z",
          "shell.execute_reply": "2022-12-14T12:27:54.278044Z"
        },
        "id": "JjJJyJTZYebt"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Onze Data\n",
        "\n",
        "Benodigd:\n",
        "- [x] tf datasets object\n",
        "- [x] Data inlezen (splitting train, val, test)\n",
        "- [x] START and END tokens\n",
        "- [ ] \n"
      ],
      "metadata": {
        "id": "J11uLxSL0lOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Necessary when upload fails (Firefox+Colab issue)\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "metadata": {
        "id": "WTBjvP0clT_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # get data\n",
        "# import requests\n",
        "# target_url = \"https://raw.githubusercontent.com/EagleW/ACL_titles_abstracts_dataset/master/acl_titles_and_abstracts.txt\"\n",
        "# response = requests.get(target_url)\n",
        "# data = response.text\n",
        "# print(len(data))\n",
        "# with open('acl_titles_and_abstracts.txt', 'w') as file:\n",
        "#     file.writelines(data)"
      ],
      "metadata": {
        "id": "yUgXkFWdmHiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data\n",
        "\n",
        "Code van:\n",
        "- https://github.com/EagleW/Writing-editing-Network/blob/master/split_data.py"
      ],
      "metadata": {
        "id": "scExk4340-Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from random import shuffle\n",
        "# Seed voor herhaalbaarheid\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "T3gZWA3d079y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modified data externally to remove all blank lines\n",
        "def write_data(f, ext, mod):\n",
        "    # Code van https://github.com/EagleW/Writing-editing-Network/blob/master/split_data.py\n",
        "    file1=open(f, 'r')\n",
        "    lines=file1.readlines()\n",
        "    file1.close()\n",
        "    abs_t = []\n",
        "    abstracts = []\n",
        "    titles = []\n",
        "    i = 0\n",
        "    # TODO: possibly generates wrong tibs/abs when encounter\n",
        "    for line in lines:\n",
        "        if i % mod == 0:\n",
        "            titles.append(line)\n",
        "        elif i % mod == 1:\n",
        "            abstracts.append(line)\n",
        "        i += 1\n",
        "    for i in range(len(abstracts)):\n",
        "        if len(titles[i]) > 0 and len(abstracts[i]) > 0:\n",
        "            h_a_pair = (titles[i], abstracts[i])\n",
        "            abs_t.append(h_a_pair)\n",
        "    shuffle(abs_t)\n",
        "    total = len(abs_t)\n",
        "    dev = total//10\n",
        "    train  = total - dev - dev\n",
        "    i = 0\n",
        "    file1=open(\"val{}.txt\".format(ext), 'w')\n",
        "    for i in range(dev):\n",
        "        file1.writelines(abs_t[i][0])\n",
        "        file1.writelines(abs_t[i][1])\n",
        "    #    file1.writelines(\"\\n\")\n",
        "    file1.close()\n",
        "    file1=open(\"test{}.txt\".format(ext), 'w')\n",
        "    for i in range(dev, 2 * dev):\n",
        "        file1.writelines(abs_t[i][0])\n",
        "        file1.writelines(abs_t[i][1])\n",
        "    #    file1.writelines(\"\\n\")\n",
        "    file1.close()\n",
        "    file1=open(\"train{}.txt\".format(ext), 'w')\n",
        "    for i in range(2 * dev, total):\n",
        "        file1.writelines(abs_t[i][0])\n",
        "        file1.writelines(abs_t[i][1])\n",
        "    #    file1.writelines(\"\\n\")\n",
        "    file1.close()"
      ],
      "metadata": {
        "id": "SzGQFaNqtytb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is nu in vorm:\n",
        "- title \\n\n",
        "- abstract \\n"
      ],
      "metadata": {
        "id": "LzXdALcf1q84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_abs_and_titles_from_raw(path_to_file):\n",
        "    abstracts, titles = [], []\n",
        "    with open(path_to_file) as data:\n",
        "        lines = data.readlines()\n",
        "        for abs in lines[1::2]:\n",
        "            abstracts.append(abs.strip())\n",
        "        for title in lines[0::2]:\n",
        "            # // TODO: check if we need to add start and end tokens\n",
        "            titles.append(title.strip())\n",
        "            # titles.append('[START] ' + title.strip() + ' [END]')\n",
        "    return abstracts, titles"
      ],
      "metadata": {
        "id": "-UUraV6x9EiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_data(\"acl_titles_and_abstracts_mod.txt\", \"\", 2)"
      ],
      "metadata": {
        "id": "61LzptxPA9xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, train_labels = get_abs_and_titles_from_raw('train.txt')\n",
        "val_text, val_labels = get_abs_and_titles_from_raw('val.txt')"
      ],
      "metadata": {
        "id": "TvpwFE879gXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels[0])\n",
        "print(train_text[0])"
      ],
      "metadata": {
        "id": "65RkvLBO3w5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45cee3b9-623a-40f8-9afc-688ea235e815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heideltime : tuning english and developing spanish resources\n",
            "in this paper , we describe our participation in the tempeval-3 challenge . with our multilingual temporal tagger heideltime , we addressed task a , the extraction and normalization of temporal expressions for english and spanish . exploiting heideltimes strict separation between source code and languagedependent parts , we tuned heideltimes existing english resources and developed new spanish resources . for both languages , we achieved the best results among all participants for task a , the combination of extraction and normalization . both the improved english and the new spanish resources are publicly available with heideltime .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_labels[0])\n",
        "print(val_text[0])"
      ],
      "metadata": {
        "id": "4Cbdpp8o3uyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc85b8ea-14f2-44cb-d3b2-ea130fd95b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computational analysis to explore authors depiction of characters cecilia ovesdotter alm\n",
            "this study involves automatically identifying the sociolinguistic characteristics of fictional characters in plays by analyzing their written speech . we discuss three binary classification problems : predicting the characters gender ( male vs. female ) , age ( young vs. old ) , and socioeconomic standing ( upper-middle class vs. lower class ) . the text corpus used is an annotated collection of august strindberg and henrik ibsen plays , translated into english , which are in the public domain . these playwrights were chosen for their known attention to relevant socioeconomic issues in their work . linguistic and textual cues are extracted from the characters lines ( turns ) for modeling purposes . we report on the dataset as well as the performance and important features when predicting each of the sociolinguistic characteristics , comparing intra- and inter-author testing .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_text, train_labels)).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_text, val_labels)).batch(BATCH_SIZE)\n",
        "# ((train_text, train_inputs), train_labels) <-- tokenized"
      ],
      "metadata": {
        "id": "aHwIk0M8DSgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for abs, tit in train_dataset.take(1):\n",
        "    print('> Abstract examples:')\n",
        "    for a in abs.numpy():\n",
        "        print(a.decode('utf-8'))\n",
        "    print()\n",
        "    \n",
        "    print('> Title examples:')\n",
        "    for t in tit.numpy():\n",
        "        print(t.decode('utf-8'))"
      ],
      "metadata": {
        "id": "GZtWaQtzHe2S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d540e3c-1251-4f4f-c7ea-547fe27c3fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Abstract examples:\n",
            "in this paper , we describe our participation in the tempeval-3 challenge . with our multilingual temporal tagger heideltime , we addressed task a , the extraction and normalization of temporal expressions for english and spanish . exploiting heideltimes strict separation between source code and languagedependent parts , we tuned heideltimes existing english resources and developed new spanish resources . for both languages , we achieved the best results among all participants for task a , the combination of extraction and normalization . both the improved english and the new spanish resources are publicly available with heideltime .\n",
            "we present three novel methods of compactly storing very large n-gram language models . these methods use substantially less space than all known approaches and allow n-gram probabilities or counts to be retrieved in constant time , at speeds comparable to modern language modeling toolkits . our basic approach generates an explicit minimal perfect hash function , that maps all n-grams in a model to distinct integers to enable storage of associated values . extensions of this approach exploit distributional characteristics of n-gram data to reduce storage costs , including variable length coding of values and the use of tiered structures that partition the data for more efficient storage . we apply our approach to storing the full google web1t n-gram set and all 1-to-5 grams of the gigaword newswire corpus . for the 1.5 billion n-grams of gigaword , for example , we can store full count information at a cost of 1.66 bytes per n-gram ( around 30 % of the cost when using the current stateof-the-art approach ) , or quantized counts for 1.41 bytes per n-gram . for applications that are tolerant of a certain class of relatively innocuous errors ( where unseen n-grams may be accepted as rare n-grams ) , we can reduce the latter cost to below 1 byte per n-gram .\n",
            "a poll consists of a question and a set of predefined answers from which voters can select . we present the new problem of vote prediction on comments , which involves determining which of these answers a voter selected given a comment she wrote after voting . to address this task , we exploit not only the information extracted from the comments but also extra-textual information such as user demographic information and inter-comment constraints . in an evaluation involving nearly one million comments collected from the popular sodahead social polling website , we show that a vote prediction system that exploits only textual information can be improved significantly when extended with extra-textual information .\n",
            "this paper examines two problems in document-level sentiment analysis : ( 1 ) determining whether a given document is a review or not , and ( 2 ) classifying the polarity of a review as positive or negative . we first demonstrate that review identification can be performed with high accuracy using only unigrams as features . we then examine the role of four types of simple linguistic knowledge sources in a polarity classification system .\n",
            "tree kernel is an effective technique for relation extraction . however , the traditional syntactic tree representation is often too coarse or ambiguous to accurately capture the semantic relation information between two entities . in this paper , we propose a new tree kernel , called feature-enriched tree kernel ( ftk ) , which can enhance the traditional tree kernel by : 1 ) refining the syntactic tree representation by annotating each tree node with a set of discriminant features ; and 2 ) proposing a new tree kernel which can better measure the syntactic tree similarity by taking all features into consideration . experimental results show that our method can achieve a 5.4 % f-measure improvement over the traditional convolution tree kernel .\n",
            "the work reported in this article presents a computational model of interpretation . the model proposes a cognitive architecture for intelligent agents to reason about competing analyses during interpretation and leverages the positive reinforcement principle .\n",
            "this article describes the construction of a morphological , syntactic and semantic analyzer to operate a high-grade search engine for hebrew texts . a good search engine must be complete and accurate . in hebrew or arabic script most of the vowels are not written , many particles are attached to the word without space , a double consonant is written with one letter , and some letters signify both vowels and consonants . thus , almost every string of characters may designate many words ( the average in hebrew is almost three words ) . as a consequence , deciphering a word necessitates reading the whole sentence . our model is fillmores framework of an expression with a verb as its center . the engine eliminates readings of words unsuited to the syntax or the semantic structure of the sentence . in every verbal entry of our conceptual dictionary the features of the noun phrases ( nps ) required by the verb are included . when all the correct readings of all the strings of characters in the sentence have been identified , the program chooses the proper occurrences of the searched word in the text . approximately 95 % of the results by our search engine match those in the query .\n",
            "in this paper we present a family of kernel functions , named syntagmatic kernels , which can be used to model syntagmatic relations . syntagmatic relations hold among words that are typically collocated in a sequential order , and thus they can be acquired by analyzing word sequences . in particular , syntagmatic kernels are defined by applying a word sequence kernel to the local contexts of the words to be analyzed . in addition , this approach allows us to define a semi supervised learning schema where external lexical knowledge is plugged into the supervised learning process . lexical knowledge is acquired from both unlabeled data and hand-made lexical resources , such as wordnet . we evaluated the syntagmatic kernel on two standard word sense disambiguation tasks ( i.e . english and italian lexical-sample tasks of senseval-3 ) , where the syntagmatic information plays a crucial role . we compared the syntagmatic kernel with the standard approach , showing promising improvements in performance .\n",
            "we introduce new features for incorporating semantic predicate-argument structures in machine translation ( mt ) . the methods focus on the completeness of the semantic structures of the translations , as well as the order of the translated semantic roles . we experiment with translation rules which contain the core arguments for the predicates in the source side of a mt system , and observe that using these rules significantly improves the translation quality . we also present a new semantic feature that resembles a language model . our results show that the language model feature can also significantly improve mt results .\n",
            "the most accurate unsupervised word segmentation systems that are currently available ( brent , 1999 ; venkataraman , 2001 ; goldwater , 2007 ) use a simple unigram model of phonotactics . while this simplifies some of the calculations , it overlooks cues that infant language acquisition researchers have shown to be useful for segmentation ( mattys et al , 1999 ; mattys and jusczyk , 2001 ) . here we explore the utility of using bigram and trigram phonotactic models by enhancing brents ( 1999 ) mbdp-1 algorithm . the results show the improved mbdp-phon model outperforms other unsupervised word segmentation systems ( e.g. , brent , 1999 ; venkataraman , 2001 ; goldwater , 2007 ) .\n",
            "word sense induction aims to discover different senses of a word from a corpus by using unsupervised learning approaches . once a sense inventory is obtained for an ambiguous word , word sense discrimination approaches choose the best-fitting single sense for a given context from the induced sense inventory . however , there may not be a clear distinction between one sense and another , although for a context , more than one induced sense can be suitable . graded word sense method allows for labeling a word in more than one sense . in contrast to the most common approach which is to apply clustering or graph partitioning on a representation of first or second order co-occurrences of a word , we propose a system that creates a substitute vector for each target word from the most likely substitutes suggested by a statistical language model . word samples are then taken according to probabilities of these substitutes and the results of the co-occurrence model are clustered . this approach outperforms the other systems on graded word sense induction task in semeval-2013 .\n",
            "we consider the problem of answering complex questions that require inferencing and synthesizing information from multiple documents and can be seen as a kind of topicoriented , informative multi-document summarization . the stochastic , graph-based method for computing the relative importance of textual units ( i.e . sentences ) is very successful in generic summarization . in this method , a sentence is encoded as a vector in which each component represents the occurrence frequency ( tf*idf ) of a word . however , the major limitation of the tf*idf approach is that it only retains the frequency of the words and does not take into account the sequence , syntactic and semantic information . in this paper , we study the impact of syntactic and shallow semantic information in the graph-based method for answering complex questions .\n",
            "this paper presents our system to address the cogalex-iv 2014 shared task of identifying a single word most semantically related to a group of 5 words ( queries ) . our system uses an implementation of a neural language model and identifies the answer word by finding the most semantically similar word representation to the sum of the query representations . it is a fully unsupervised system which learns on around 20 % of the ukwac corpus . it correctly identifies 85 exact correct targets out of 2,000 queries , 285 approximate targets in lists of 5 suggestions .\n",
            "this paper describes a series of french semantic role labelling experiments which show that a small set of manually annotated training data is superior to a much larger set containing semantic role labels which have been projected from a source language via word alignment . using universal part-of-speech tags and dependencies makes little difference over the original fine-grained tagset and dependency scheme . moreover , there seems to be no improvement gained from projecting semantic roles between direct translations than between indirect translations .\n",
            "the brown and the berkeley parsers are two state-of-the-art generative parsers . since both parsers produce n-best lists , it is possible to apply reranking techniques to the output of both of these parsers , and to their union . we note that the standard reranker feature set distributed with the brown parser does not do well with the berkeley parser , and propose an extended set that does better . an ablation experiment shows that different parsers benefit from different reranker features .\n",
            "this paper presents our error tolerable system for coreference resolution in conll2011 ( pradhan et al , 2011 ) shared task ( closed track ) . different from most previous reported work , we detect mention candidates based on packed forest instead of single parse tree , and we use beam search algorithm based on the bell tree to create entities . experimental results show that our methods achieve promising results on the development set .\n",
            "we describe our approach to the construction and evaluation of a large-scale database called catvar which contains categorial variations of english lexemes . due to the prevalence of cross-language categorial variation in multilingual applications , our categorial-variation resource may serve as an integral part of a diverse range of natural language applications . thus , the research reported herein overlaps heavily with that of the machine-translation , lexicon-construction , and information-retrieval communities . we apply the information-retrieval metrics of precision and recall to evaluate the accuracy and coverage of our database with respect to a human-produced gold standard . this evaluation reveals that the categorial database achieves a high degree of precision and recall . additionally , we demonstrate that the database improves on the linkability of porter stemmer by over 30 % .\n",
            "a general characteristic of most biomedical disciplines is their primarily experimental character . discoveries are obtained through molecular biology and biochemical techniques that allow understanding of biological processes at the molecular level . to qualify biological events , it is of practical significance to detect specific types of negations that can imply either that a given event is not observed under specific conditions or even the opposite , that a given event is true by altering the bio-entities studied ( e.g . introducing specific modifications like mutations ) . of special interest is also to determine if a detected assertion is linked to experimental support provided by the authors . finding experimental qualifier cues and detecting experimental technique mentions is of great interest to the biological community in general and particularly for annotation databases . a short overview of different types of negations and biological qualifiers of practical relevance will be provided .\n",
            "an external lexicon quality measure called the l-measure is derived from the f-measure ( rijsbergen , 1979 ; larsen and aone , 1999 ) . the typically small sample sizes available for minority languages and the evaluation of semitic language lexicons are two main factors considered . large-scale evaluation results for the maltilex corpus are presented ( rosner et al. , 1999 ) .\n",
            "vector-based distributional models of semantics have proven useful and adequate in a variety of natural language processing tasks . however , most of them lack at least one key requirement in order to serve as an adequate representation of natural language , namely sensitivity to structural information such as word order . we propose a novel approach that offers a potential of integrating order-dependent word contexts in a completely unsupervised manner by assigning to words characteristic distributional matrices . the proposed model is applied to the task of free associations . in the end , the first results as well as directions for future work are discussed .\n",
            "this paper presents the carnegie mellon university statistical transfer mt system submitted to the 2009 wmt shared task in french-to-english translation . we describe a syntax-based approach that incorporates both syntactic and non-syntactic phrase pairs in addition to a syntactic grammar . after reporting development test results , we conduct a preliminary analysis of the coverage and effectiveness of the systems components .\n",
            "sentence types typical to swedish clinical text were extracted by comparing sentence part-of-speech tag sequences in clinical and in standard swedish text . parsings by a syntactic dependency parser , trained on standard swedish , were manually analysed for the 33 sentence types most typical to clinical text . this analysis resulted in the identification of eight error types , and for two of these error types , preprocessing rules were constructed to improve the performance of the parser . for all but one of the ten sentence types affected by these two rules , the parsing was improved by pre-processing .\n",
            "wouldnt it be helpful if your text editor automatically suggested papers that are relevant to your research wouldnt it be even better if those suggestions were contextually relevant in this paper we name a system that would accomplish this a context-based citation recommendation ( cbcr ) system . we specifically present citation resolution , a method for the evaluation of cbcr systems which exclusively uses readily-available scientific articles . exploiting the human judgements that are already implicit in available resources , we avoid purpose-specific annotation . we apply this evaluation to three sets of methods for representing a document , based on a ) the contents of the document , b ) the surrounding contexts of citations to the document found in other documents , and c ) a mixture of the two .\n",
            "results from psychology show a connection between a speakers expertise in a task and the language he uses to talk about it . in this paper , we present an empirical study on using linguistic evidence to predict the expertise of a speaker in a task : playing chess . instructional chess literature claims that the mindsets of amateur and expert players differ fundamentally ( silman , 1999 ) ; psychological science has empirically arrived at similar results ( e.g. , pfau and murphy ( 1988 ) ) . we conduct experiments on automatically predicting chess player skill based on their natural language game commentary . we make use of annotated chess games , in which players provide their own interpretation of game in prose . based on a dataset collected from an online chess forum , we predict player strength through svm classification and ranking . we show that using textual and chess-specific features achieves both high classification accuracy and significant correlation . finally , we compare our findings to claims from the chess literature and results from psychology .\n",
            "this work explores the utility of sentiment and arguing opinions for classifying stances in ideological debates . in order to capture arguing opinions in ideological stance taking , we construct an arguing lexicon automatically from a manually annotated corpus . we build supervised systems employing sentiment and arguing opinions and their targets as features . our systems perform substantially better than a distribution-based baseline . additionally , by employing both types of opinion features , we are able to perform better than a unigrambased system .\n",
            "in this paper , we put forward an information theoretic definition of the redundancy that is observed across the sound inventories of the worlds languages . through rigorous statistical analysis , we find that this redundancy is an invariant property of the consonant inventories . the statistical analysis further unfolds that the vowel inventories do not exhibit any such property , which in turn points to the fact that the organizing principles of the vowel and the consonant inventories are quite different in nature .\n",
            "search-based structured prediction andreas vlachos and mark craven department of biostatistics and medical informatics university of wisconsin-madison { vlachos , craven } @ biostat.wisc.edu abstract in this paper we describe our approach to the bionlp 2011 shared task on biomedical event extraction from abstracts and full papers . we employ a joint inference system developed using the search-based structured prediction framework and show that it improves on a pipeline using the same features and it is better able to handle the domain shift from abstracts to full papers . in addition , we report on experiments using a simple domain adaptation method .\n",
            "named entity phrases are some of the most difficult phrases to translate because new phrases can appear from nowhere , and because many are domain specific , not to be found in bilingual dictionaries . we present a novel algorithm for translating named entity phrases using easily obtainable monolingual and bilingual resources . we report on the application and evaluation of this algorithm in translating arabic named entities to english . we also compare our results with the results obtained from human translations and a commercial system for the same task .\n",
            "this paper studies the impact of written language variations and the way it affects the capitalization task over time . a discriminative approach , based on maximum entropy models , is proposed to perform capitalization , taking the language changes into consideration . the proposed method makes it possible to use large corpora for training . the evaluation is performed over newspaper corpora using different testing periods . the achieved results reveal a strong relation between the capitalization performance and the elapsed time between the training and testing data periods .\n",
            "mental modeling is crucial for natural humanrobot interactions ( hri ) . yet , effective mechanisms that enable reasoning about and communication of mental states are not available . we propose to utilize adverbial cues , routinely employed by humans , for this goal and present a novel algorithm that integrates adverbial modifiers with belief revision and expression , phrasing utterances based on gricean conversational maxims . the algorithm is demonstrated in a simple hri scenario .\n",
            "much natural language processing still depends on the euclidean ( cosine ) distance function between two feature vectors , but this has severe problems with regard to feature weightings and feature correlations . to answer these problems , we propose an optimal metric distance that can be used as an alternative to the cosine distance , thus accommodating the two problems at the same time . this metric is optimal in the sense of global quadratic minimization , and can be obtained from the clusters in the training data in a supervised fashion . we confirmed the effect of the proposed metric distance by a synonymous sentence retrieval task , document retrieval task and the k-means clustering of general vectorial data . the results showed constant improvement over the baseline method of euclid and tf.idf , and were especially prominent for the sentence retrieval task , showing a 33 % increase in the 11-point average precision .\n",
            "in this paper , we propose a novel method for semi-supervised learning of nonprojective log-linear dependency parsers using directly expressed linguistic prior knowledge ( e.g . a nouns parent is often a verb ) . model parameters are estimated using a generalized expectation ( ge ) objective function that penalizes the mismatch between model predictions and linguistic expectation constraints . in a comparison with two prominent unsupervised learning methods that require indirect biasing toward the correct syntactic structure , we show that ge can attain better accuracy with as few as 20 intuitive constraints . we also present positive experimental results on longer sentences in multiple languages .\n",
            "we propose a structure called dependency forest for statistical machine translation . a dependency forest compactly represents multiple dependency trees . we develop new algorithms for extracting string-todependency rules and training dependency language models . our forest-based string-to-dependency system obtains significant improvements ranging from 1.36 to 1.46 bleu points over the tree-based baseline on the nist 2004/2005/2006 chinese-english test sets .\n",
            "the extension to new languages is a well known bottleneck for rule-based systems . considerable human effort , which typically consists in re-writing from scratch huge amounts of rules , is in fact required to transfer the knowledge available to the system from one language to a new one . provided sufficient annotated data , machine learning algorithms allow to minimize the costs of such knowledge transfer but , up to date , proved to be ineffective for some specific tasks . among these , the recognition and normalization of temporal expressions still remains out of their reach . focusing on this task , and still adhering to the rule-based framework , this paper presents a bunch of experiments on the automatic porting to italian of a system originally developed for spanish . different automatic rule translation strategies are evaluated and discussed , providing a comprehensive overview of the challenge .\n",
            "a hybrid system is described which combines the strength of manual rulewriting and statistical learning , obtaining results superior to both methods if applied separately . the combination of a rule-based system and a statistical one is not parallel but serial : the rule-based system performing partial disambiguation with recall close to 100 % is applied first , and a trigram hmm tagger runs on its results . an experiment in czech tagging has been performed with encouraging results .\n",
            "we explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums , an increasingly popular means of providing customer service . in particular , we investigate the effectiveness of various features and machine learners for this task . while a simple bag-of-words approach provides a solid baseline , we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance ; learners that account for sequential dependencies ( crfs ) show the best performance . we report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data .\n",
            "we address the problem dealing with a large collection of data , and investigate the use of automatically constructing category hierarchy from a given set of categories to improve classification of large corpora . we use two wellknown techniques , partitioning clustering , means and a to create category hierarchy . -means is to cluster the given categories in a hierarchy . to select the proper number of , we use a which measures the degree of our disappointment in any differences between the true distribution over inputs and the learners prediction . once the optimal number of is selected , for each cluster , the procedure is repeated . our evaluation using the 1996 reuters corpus which consists of 806,791 documents shows that automatically constructing hierarchy improves classification accuracy .\n",
            "techniques that compare short text segments using dependency paths ( or simply , paths ) appear in a wide range of automated language processing applications including question answering ( qa ) . however , few models in ad hoc information retrieval ( ir ) use paths for document ranking due to the prohibitive cost of parsing a retrieval collection . in this paper , we introduce a flexible notion of paths that describe chains of words on a dependency path . these chains , or catenae , are readily applied in standard ir models . informative catenae are selected using supervised machine learning with linguistically informed features and compared to both non-linguistic terms and catenae selected heuristically with filters derived from work on paths . automatically selected catenae of 1-2 words deliver significant performance gains on three trec collections .\n",
            "the main area of this paper concerns the neural methods for mapping scientific and technical information ( articles , patents ) and for assisting a user in carrying out the complex process of analysing large quantities of such information . in the procedure of information analysis , like in the domain of patent analysis , the complexity of the studied topics and the accuracy of the question to be answered may often lead the analyst to partition his reasoning into viewpoints . most of the classical information analysis tools can only manage an analysis of the studied domain in a global way . the information analysis tool that will be considered in our study is the multisom tool whose core model represents a significant extension of the classical kohonen som neural model . the multisom neural-based tool introduces the concepts of viewpoints and dynamics into the information analysis with its multi-maps displays and its intermap communication process . the dynamic information exchange between maps can be exploited by an analyst in order to perform cooperative deduction between several different analyzes that have been performed on the same data . the paper demonstrates the efficiency of a viewpoint-oriented-analysis as compared to a global analysis in the domain of patents . both objective and subjective quality criteria are taken into account for quality evaluation . the experimental context of the paper is constituted by a patent database of 1000 patents related to oil engineering . the patents structure and the patents field semantics are firstly exploited in order to generate different viewpoints corresponding to different areas of interest for the analysts .\n",
            "social media texts are significant information sources for several application areas including trend analysis , event monitoring , and opinion mining . unfortunately , existing solutions for tasks such as named entity recognition that perform well on formal texts usually perform poorly when applied to social media texts . in this paper , we report on experiments that have the purpose of improving named entity recognition on turkish tweets , using two different annotated data sets . in these experiments , starting with a baseline named entity recognition system , we adapt its recognition rules and resources to better fit twitter language by relaxing its capitalization constraint and by diacritics-based expansion of its lexical resources , and we employ a simplistic normalization scheme on tweets to observe the effects of these on the overall named entity recognition performance on turkish tweets . the evaluation results of the system with these different settings are provided with discussions of these results .\n",
            "prior work has shown that generalization of data in an example based machine translation ( ebmt ) system , reduces the amount of pre-translated text required to achieve a certain level of accuracy ( brown , 2000 ) . several word clustering algorithms have been suggested to perform these generalizations , such as kmeans clustering or group average clustering . the hypothesis is that better contextual clustering can lead to better translation accuracy with limited training data . in this paper , we use a form of spectral clustering to cluster words , and this is shown to result in as much as 29.08 % improvement over the baseline ebmt system .\n",
            "developing better methods for segmenting continuous text into words is important for improving the processing of asian languages , and may shed light on how humans learn to segment speech . we propose two new bayesian word segmentation methods that assume unigram and bigram models of word dependencies respectively . the bigram model greatly outperforms the unigram model ( and previous probabilistic models ) , demonstrating the importance of such dependencies for word segmentation . we also show that previous probabilistic models rely crucially on suboptimal search procedures .\n",
            "this paper presents a chinese word segmentation system for the closed track of cips-sighan word segmentation bakeoff 2010. this system adopts a character-based joint approach , which combines a character-based generative model and a character-based discriminative model . to further improve the crossdomain performance , we use an additional semi-supervised learning procedure to incorporate the unlabeled corpus . the final performance on the closed track for the simplified-character text shows that our system achieves comparable results with other state-of-the-art systems .\n",
            "identification of transliterated names is a particularly difficult task of named entity recognition ( ner ) , especially in the chinese context . of all possible variations of transliterated named entities , the difference between prc and taiwan is the most prevalent and most challenging . in this paper , we introduce a novel approach to the automatic extraction of diverging transliterations of foreign named entities by bootstrapping cooccurrence statistics from tagged and segmented chinese corpus . preliminary experiment yields promising results and shows its potential in nlp applications .\n",
            "traditional question answering systems adopt the following framework : parsing questions , searching for relevant documents , and identifying/generating answers . however , this framework does not work well for questions with hidden assumptions and implicatures . in this paper , we describe a novel idea , a cascading guidance strategy , which can not only identify potential traps in questions but further guide the answer extraction procedure by recognizing whether there are multiple answers for a question . this is the first attempt to solve implicature problem for complex qa in a cascading fashion using n-gram language models as features . we here investigate questions with implicatures related to biography facts in a web-based qa system , powerbio . we compare the performances of decision tree , nave bayes , svm ( support vector machine ) , and me ( maximum entropy ) classification methods . the integration of the cascading guidance strategy can help extract answers for questions with implicatures and produce satisfactory results in our experiments .\n",
            "in this paper , we explore the use of automatic syntactic simplification for improving content selection in multi-document summarization . in particular , we show how simplifying parentheticals by removing relative clauses and appositives results in improved sentence clustering , by forcing clustering based on central rather than background information . we argue that the inclusion of parenthetical information in a summary is a reference-generation task rather than a content-selection one , and implement a baseline reference rewriting module . we perform our evaluations on the test sets from the 2003 and 2004 document understanding conference and report that simplifying parentheticals results in significant improvement on the automated evaluation metric rouge .\n",
            "patent images are very important for patent examiners to understand the contents of an invention . therefore there is a need for automatic labelling of patent images in order to support patent search tasks . towards this goal , recent research works propose classification-based approaches for patent image annotation . however , one of the main drawbacks of these methods is that they rely upon large annotated patent image datasets , which require substantial manual effort to be obtained . in this context , the proposed work performs extraction of concepts from patent images building upon a supervised machine learning framework , which is trained with limited annotated data and automatically generated synthetic data . the classification is realised with random forests ( rf ) and a combination of visual and textual features . first , we make use of rfs implicit ability to detect outliers to rid our data of unnecessary noise . then , we generate new synthetic data cases by means of synthetic minority over-sampling technique ( smote ) . we evaluate the different retrieval parts of the framework by using a dataset from the footwear domain . the results of the experiments indicate the benefits of using the proposed methodology .\n",
            "this study investigates similarity judgments from two angles . first , we look at models suggested in the psychology and philosophy literature which capture the essence of concept similarity evaluation for humans . second , we analyze the properties of many metrics which simulate such evaluation capabilities . the first angle reveals that non-experts can judge similarity and that their judgments need not be based on predefined traits . we use such conclusions to inform us on how gold standards for word sense disambiguation tasks could be established . from the second angle , we conclude that more attention should be paid to metric properties before assigning them to perform a particular task .\n",
            "the purpose of this study is to construct a semantic analysis method for disambiguating japanese compound verbs . japanese speakers produce a rich variety of compound verbs , making it difficult to process them by computer . we construct a method employing 110 disambiguation rules based on the semantic features of the first verb of a compound and syntactic patterns consisting of co-occurrence between verbs and nouns . the disambiguation rules are evaluated by applying them to compound verbs in the dictionary . the obtained accuracy is 87.19 % for our rules . this result shows the advantage of our method .\n",
            "our submission was a reduced version of the system described in haghighi and klein ( 2010 ) , with extensions to improve mention detection to suit the ontonotes annotation scheme . including exact matching mention detection in this shared task added a new and challenging dimension to the problem , particularly for our system , which previously used a very permissive detection method . we improved this aspect of the system by adding filters based on the annotation scheme for ontonotes and analysis of system behavior on the development set . these changes led to improvements in coreference f-score of 10.06 , 5.71 , 6.78 , 6.63 and 3.09 on the muc , b3 , ceaf-e , ceaf-m and blanc , metrics , respectively , and a final task score of 47.10 .\n",
            "recent evaluation techniques applied to corpusbased systems have been introduced that can predict quantitatively how well surface realizers will generate unseen sentences in isolation . we introduce a similar method for determining the coverage on the fuf/surge symbolic surface realizer , report that its coverage and accuracy on the penn treebank is higher than that of a similar statistics-based generator , describe several bene ts that can be used in other areas of computational linguistics , and present an updated version of surge for use in the nlg community .\n",
            "our research organization has been constructing a large scale database named shachi by collecting detailed meta information on language resources ( lrs ) in asia and western countries . the metadata database contains more than 2,000 compiled lrs such as corpora , dictionaries , thesauruses and lexicons , forming a large scale metadata of lrs archive . its metadata , an extended version of olac metadata set conforming to dublin core , have been collected semi-automatically . this paper explains the design and the structure of the metadata database , as well as the realization of the catalogue search tool .\n",
            "we present a novel model , freestyle , that learns to improvise rhyming and fluent responses upon being challenged with a line of hip hop lyrics , by combining both bottomup token based rule induction and top-down rule segmentation strategies to learn a stochastic transduction grammar that simultaneously learns both phrasing and rhyming associations . in this attack on the woefully under-explored natural language genre of music lyrics , we exploit a strictly unsupervised transduction grammar induction approach . our task is particularly ambitious in that no use of any a priori linguistic or phonetic information is allowed , even though the domain of hip hop lyrics is particularly noisy and unstructured . we evaluate the performance of the learned model against a model learned only using the more conventional bottom-up token based rule induction , and demonstrate the superiority of our combined token based and rule segmentation induction method toward generating higher quality improvised responses , measured on fluency and rhyming criteria as judged by human evaluators . to highlight some of the inherent challenges in adapting other algorithms to this novel task , we also compare the quality of the responses generated by our model to those generated by an out-ofthe-box phrase based smt system . we tackle the challenge of selecting appropriate training data for our task via a dedicated rhyme scheme detection module , which is also acquired via unsupervised learning and report improved quality of the generated responses . finally , we report results with maghrebi french hip hop lyrics indicating that our model performs surprisingly well with no special adaptation to other languages .\n",
            "this paper presents an unsupervised topic identification method integrating linguistic and visual information based on hidden markov models ( hmms ) . we employ hmms for topic identification , wherein a state corresponds to a topic and various features including linguistic , visual and audio information are observed . our experiments on two kinds of cooking tv programs show the effectiveness of our proposed method .\n",
            "in this paper , we present a word sense disambiguation ( wsd ) based system for multilingual lexical substitution . our method depends on having a wsd system for english and an automatic word alignment method . crucially the approach relies on having parallel corpora . for task 2 ( sinha et al , 2009 ) we apply a supervised wsd system to derive the english word senses . for task 3 ( lefever & hoste , 2009 ) , we apply an unsupervised approach to the training and test data . both of our systems that participated in task 2 achieve a decent ranking among the participating systems . for task 3 we achieve the highest ranking on several of the language pairs : french , german and italian .\n",
            "statistical machine translation relies heavily on available parallel corpora , but smt may not have the ability or intelligence to make full use of the training set . instead of col-lecting more and more parallel training cor-pora , this paper aims to improve smt performance by exploiting the full potential of existing parallel corpora . we first iden-tify literally translated sentence pairs via lexical and grammatical compatibility , and then use these data to train smt models . one experiment indicates that larger train-ing corpora do not always lead to higher de-coding performance when the added data are not literal translations . and another ex-periment shows that properly enlarging the contribution of literal translation can im-prove smt performance significantly .\n",
            "consumers increasingly rate , review and research products online ( jansen , 2010 ; litvin et al , 2008 ) . consequently , websites containing consumer reviews are becoming targets of opinion spam . while recent work has focused primarily on manually identifiable instances of opinion spam , in this work we study deceptive opinion spamfictitious opinions that have been deliberately written to sound authentic . integrating work from psychology and computational linguistics , we develop and compare three approaches to detecting deceptive opinion spam , and ultimately develop a classifier that is nearly 90 % accurate on our gold-standard opinion spam dataset . based on feature analysis of our learned models , we additionally make several theoretical contributions , including revealing a relationship between deceptive opinions and imaginative writing .\n",
            "this paper describes the system used by the lipn team in the task 10 , multilingual semantic textual similarity , at semeval 2014 , in both the english and spanish sub-tasks . the system uses a support vector regression model , combining different text similarity measures as features . with respect to our 2013 participation , we included a new feature to take into account the geographical context and a new semantic distance based on the bhattacharyya distance calculated on cooccurrence distributions derived from the spanish google books n-grams dataset .\n",
            "data preprocessing plays a crucial role in phrase-based statistical machine translation ( pb-smt ) . in this paper , we show how single-tokenization of two types of multi-word expressions ( mwe ) , namely named entities ( ne ) and compound verbs , as well as their prior alignment can boost the performance of pb-smt . single-tokenization of compound verbs and named entities ( ne ) provides significant gains over the baseline pb-smt system . automatic alignment of nes substantially improves the overall mt performance , and thereby the word alignment quality indirectly . for establishing ne alignments , we transliterate source nes into the target language and then compare them with the target nes . target language nes are first converted into a canonical form before the comparison takes place . our best system achieves statistically significant improvements ( 4.59 bleu points absolute , 52.5 % relative improvement ) on an englishbangla translation task .\n",
            "real document collections do not fit the independence assumptions asserted by most statistical topic models , but how badly do they violate them we present a bayesian method for measuring how well a topic model fits a corpus . our approach is based on posterior predictive checking , a method for diagnosing bayesian models in user-defined ways . our method can identify where a topic model fits the data , where it falls short , and in which directions it might be improved .\n",
            "transforming syntactic representations in order to improve parsing accuracy has been exploited successfully in statistical parsing systems using constituency-based representations . in this paper , we show that similar transformations can give substantial improvements also in data-driven dependency parsing . experiments on the prague dependency treebank show that systematic transformations of coordinate structures and verb groups result in a 10 % error reduction for a deterministic data-driven dependency parser . combining these transformations with previously proposed techniques for recovering nonprojective dependencies leads to state-ofthe-art accuracy for the given data set .\n",
            "most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features . this approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones . to overcome this problem , we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision . each tier builds on the previous tiers entity cluster output . further , our model propagates global information by sharing attributes ( e.g. , gender and number ) across mentions in the same cluster . this cautious sieve guarantees that stronger features are given precedence over weaker ones and that each decision is made using all of the information available at the time . the framework is highly modular : new coreference modules can be plugged in without any change to the other modules . in spite of its simplicity , our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora . this suggests that sievebased approaches could be applied to other nlp tasks .\n",
            "this paper presents a cross platform multilingual multimedia indian sign language ( isl ) dictionary building tool . isl is a linguistically under-investigated language with no source of well documented electronic data . research on isl linguistics also gets hindered due to a lack of isl knowledge and the unavailability of any educational tools . our system can be used to associate signs corresponding to a given text . the current system also facilitates the phonological annotation of indian signs in the form of hamnosys structure . the generated hamnosys string can be given as input to an avatar module to produce an animated sign representation .\n",
            "efforts to automatically acquire world knowledge from text suffer from the lack of an easy means of evaluating the resulting knowledge . we describe initial experiments using mechanical turk to crowdsource evaluation to nonexperts for little cost , resulting in a collection of factoids with associated quality judgements . we describe the method of acquiring usable judgements from the public and the impact of such large-scale evaluation on the task of knowledge acquisition .\n",
            "\n",
            "> Title examples:\n",
            "heideltime : tuning english and developing spanish resources\n",
            "storing the web in memory : space efficient language models with constant time retrieval\n",
            "vote prediction on comments in social polls\n",
            "examining the role of linguistic knowledge sources in the automatic identification and classification of reviews\n",
            "a feature-enriched tree kernel for relation extraction\n",
            "interpretation in a cognitive architecture\n",
            "uzzi ornan scientific director , multitext , multidimensional publishing systems\n",
            "a word sense disambiguation case study\n",
            "comparing representations of semantic roles for\n",
            "improving word segmentation by simultaneously learning phonotactics computer & information sciences linguistics & cognitive science\n",
            "ai-ku : using substitute vectors and co-occurrence modeling for word\n",
            "improving the performance of the random walk model for answering\n",
            "predicting sense convergence with distributional semantics : an\n",
            "experiments with french\n",
            "reranking the berkeley and brown parsers ahmet engin ural\n",
            "ets : an error tolerable system for coreference resolution\n",
            "a categorial variation database for english\n",
            "importance of negations and experimental qualifiers in biomedical\n",
            "adaptation of the f-measure to cluster based lexicon quality\n",
            "towards a matrix-based distributional model of meaning fzi forschungszentrum informatik\n",
            "an improved statistical transfer system for frenchenglish\n",
            "adapting a parser to clinical text by simple pre-processing rules\n",
            "citation resolution : a method for evaluating context-based citation\n",
            "picking the amateurs mind predicting chess player strength from and language processing\n",
            "recognizing stances in ideological on-line debates the intelligent systems program\n",
            "redundancy ratio : an invariant property of the consonant inventories of the worlds languages\n",
            "biomedical event extraction from abstracts and full papers using\n",
            "translating named entities using monolingual and bilingual resources\n",
            "language dynamics and capitalization using maximum entropy\n",
            "through adverbial cues\n",
            "learning nonstructural distance metric by minimum cluster distortions atr spoken language translation\n",
            "semi-supervised learning of dependency parsers using generalized expectation criteria\n",
            "dependency forest for statistical machine translation\n",
            "evaluating knowledge-based approaches to the multilingual extension of a temporal expression normalizer povo - trento , italy\n",
            "serial combination of rules and statistics : a case study in czech\n",
            "classifying dialogue acts in one-on-one live chats su nam kim , lawrence cavedon and timothy baldwin\n",
            "a comparison of manual and automatic constructions of category hierarchy for classifying large corpora\n",
            "feature-based selection of dependency paths in ad hoc information retrieval\n",
            "intelligent patent analysis through the use of a neural network : experiment of multi-viewpoint analysis with the multisom model shadi al shehabi\n",
            "experiments to improve named entity recognition on turkish tweets\n",
            "spectral clustering for example based machine translation\n",
            "contextual dependencies in unsupervised word segmentation\n",
            "a character-based joint model behavior design corporation\n",
            "automatic discovery of named entity variants grammar-driven approaches to non-alphabetical transliterations\n",
            "handling biographical questions with implicature donghui feng eduard hovy\n",
            "syntactic simplication for improving content selection in multi-document\n",
            "and proximity-driven generation of synthetic data\n",
            "similarity judgments : philosophical , psychological and mathematical\n",
            "a disambiguation method for japanese compound verbs\n",
            "mention detection : heuristics for the ontonotes annotations\n",
            "wide coverage symbolic surface realization\n",
            "construction of an infrastructure for providing users with suitable language resources hitomi tohyama shunsuke kozawa kiyotaka uchimoto\n",
            "learning to freestyle : hip hop challenge-response induction via transduction rule segmentation\n",
            "unsupervised topic identification by integrating linguistic and visual information based on hidden markov models\n",
            "coleur and colslm : a wsd approach to multilingual lexical\n",
            "train the machine with what it can learn corpus selection for smt\n",
            "finding deceptive opinion spam by any stretch of the imagination\n",
            "lipn : introducing a new geographical context similarity measure and a statistical similarity measure based on the bhattacharyya coefficient em priego sanchez\n",
            "handling named entities and compound verbs in phrase-based statistical machine translation\n",
            "bayesian checking for topic models\n",
            "graph transformations in data-driven dependency parsing\n",
            "a multi-pass sieve for coreference resolution\n",
            "a multilingual multimedia indian sign language dictionary tool\n",
            "evaluation of commonsense knowledge with mechanical turk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def title_preprocessor(text):\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.strip(text)\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text\n",
        "\n",
        "def abstract_preprocessor(text):\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.strip(text)\n",
        "    return text\n",
        "# https://www.tensorflow.org/tutorials/load_data/text#example_1_predict_the_tag_for_a_stack_overflow_question\n",
        "# VOCAB_SIZE = 10000\n",
        "# MAX_SEQUENCE_LENGTH = 250\n",
        "\n",
        "# int_vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "#     max_tokens=VOCAB_SIZE,\n",
        "#     output_mode='int',\n",
        "#     output_sequence_length=MAX_SEQUENCE_LENGTH\n",
        "#     )\n",
        "\n",
        "abs_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=abstract_preprocessor,\n",
        "    ragged=True,\n",
        "    output_mode='int'\n",
        "    )\n",
        "\n",
        "tit_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=title_preprocessor,\n",
        "    ragged=True,\n",
        "    output_mode='int'\n",
        "    )\n",
        "\n",
        "# int_vectorize_layer.adapt(train_dataset)\n",
        "# print(len(int_vectorize_layer.get_vocabulary()))\n",
        "\n",
        "abs_text_processor.adapt(train_dataset.map(lambda abs, tit: abs))\n",
        "tit_text_processor.adapt(train_dataset.map(lambda abs, tit: tit))"
      ],
      "metadata": {
        "id": "TLSPC-SqI0YG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a474ef1-7ddf-444d-c9e4-f07d94bec659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abs_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "id": "gxRmuaZU6oyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57f6b10-b7f5-4095-b71b-410c690f0e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', '.', ',', 'of', 'a', 'and', 'to', 'in']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tit_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "id": "AUxVcwsr6wt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127d78dc-6d3a-46d8-f3e1-2b736ccfce18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', 'for', 'of', 'and', 'a', 'in', ':']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for example_abs_strings, example_tit_strings in train_dataset.take(1):\n",
        "  print(example_abs_strings[:5])\n",
        "  print()\n",
        "  print(example_tit_strings[:5])\n",
        "  break"
      ],
      "metadata": {
        "id": "cupCSTNf7B3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4edbe539-dc9e-4ab6-f7f6-ad876a5a8455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'in this paper , we describe our participation in the tempeval-3 challenge . with our multilingual temporal tagger heideltime , we addressed task a , the extraction and normalization of temporal expressions for english and spanish . exploiting heideltimes strict separation between source code and languagedependent parts , we tuned heideltimes existing english resources and developed new spanish resources . for both languages , we achieved the best results among all participants for task a , the combination of extraction and normalization . both the improved english and the new spanish resources are publicly available with heideltime .'\n",
            " b'we present three novel methods of compactly storing very large n-gram language models . these methods use substantially less space than all known approaches and allow n-gram probabilities or counts to be retrieved in constant time , at speeds comparable to modern language modeling toolkits . our basic approach generates an explicit minimal perfect hash function , that maps all n-grams in a model to distinct integers to enable storage of associated values . extensions of this approach exploit distributional characteristics of n-gram data to reduce storage costs , including variable length coding of values and the use of tiered structures that partition the data for more efficient storage . we apply our approach to storing the full google web1t n-gram set and all 1-to-5 grams of the gigaword newswire corpus . for the 1.5 billion n-grams of gigaword , for example , we can store full count information at a cost of 1.66 bytes per n-gram ( around 30 % of the cost when using the current stateof-the-art approach ) , or quantized counts for 1.41 bytes per n-gram . for applications that are tolerant of a certain class of relatively innocuous errors ( where unseen n-grams may be accepted as rare n-grams ) , we can reduce the latter cost to below 1 byte per n-gram .'\n",
            " b'a poll consists of a question and a set of predefined answers from which voters can select . we present the new problem of vote prediction on comments , which involves determining which of these answers a voter selected given a comment she wrote after voting . to address this task , we exploit not only the information extracted from the comments but also extra-textual information such as user demographic information and inter-comment constraints . in an evaluation involving nearly one million comments collected from the popular sodahead social polling website , we show that a vote prediction system that exploits only textual information can be improved significantly when extended with extra-textual information .'\n",
            " b'this paper examines two problems in document-level sentiment analysis : ( 1 ) determining whether a given document is a review or not , and ( 2 ) classifying the polarity of a review as positive or negative . we first demonstrate that review identification can be performed with high accuracy using only unigrams as features . we then examine the role of four types of simple linguistic knowledge sources in a polarity classification system .'\n",
            " b'tree kernel is an effective technique for relation extraction . however , the traditional syntactic tree representation is often too coarse or ambiguous to accurately capture the semantic relation information between two entities . in this paper , we propose a new tree kernel , called feature-enriched tree kernel ( ftk ) , which can enhance the traditional tree kernel by : 1 ) refining the syntactic tree representation by annotating each tree node with a set of discriminant features ; and 2 ) proposing a new tree kernel which can better measure the syntactic tree similarity by taking all features into consideration . experimental results show that our method can achieve a 5.4 % f-measure improvement over the traditional convolution tree kernel .'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'heideltime : tuning english and developing spanish resources'\n",
            " b'storing the web in memory : space efficient language models with constant time retrieval'\n",
            " b'vote prediction on comments in social polls'\n",
            " b'examining the role of linguistic knowledge sources in the automatic identification and classification of reviews'\n",
            " b'a feature-enriched tree kernel for relation extraction'], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokens = abs_text_processor(example_abs_strings)\n",
        "example_tokens[:3, :]"
      ],
      "metadata": {
        "id": "NAzz_5BE7CD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c951ab7-6d05-4da8-a818-46786fde25da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[9, 15, 25, 4, 10, 110, 22, 1294, 9, 2, 10954, 515, 3, 18, 22, 436, 376,\n",
              "  680, 5607, 4, 10, 1671, 36, 6, 4, 2, 95, 7, 1053, 5, 376, 260, 11, 91, 7,\n",
              "  744, 3, 912, 12775, 2278, 3561, 65, 187, 1577, 7, 7139, 934, 4, 10, 1893,\n",
              "  12775, 177, 91, 180, 7, 271, 70, 744, 180, 3, 11, 71, 84, 4, 10, 298, 2,\n",
              "  144, 34, 356, 129, 1024, 11, 36, 6, 4, 2, 291, 5, 95, 7, 1053, 3, 71, 2,\n",
              "  370, 91, 7, 2, 70, 744, 180, 20, 1443, 202, 18, 5607, 3]                 ,\n",
              " [10, 46, 159, 116, 68, 5, 6683, 4252, 227, 108, 517, 29, 48, 3, 53, 68, 54,\n",
              "  1224, 528, 303, 86, 129, 537, 120, 7, 740, 517, 774, 59, 1346, 8, 32,\n",
              "  2065, 9, 2630, 193, 4, 81, 4658, 368, 8, 1228, 29, 306, 6839, 3, 22, 581,\n",
              "  35, 1011, 21, 816, 1152, 2402, 4753, 444, 4, 12, 2212, 129, 975, 9, 6, 27,\n",
              "  8, 1219, 20887, 8, 1207, 2434, 5, 602, 943, 3, 1775, 5, 15, 35, 794, 378,\n",
              "  920, 5, 517, 33, 8, 662, 2434, 2224, 4, 294, 1320, 778, 2634, 5, 943, 7,\n",
              "  2, 54, 5, 8846, 263, 12, 4289, 2, 33, 11, 75, 347, 2434, 3, 10, 357, 22,\n",
              "  35, 8, 4252, 2, 615, 1855, 6796, 517, 73, 7, 129, 26948, 12840, 5, 2,\n",
              "  4758, 1646, 49, 3, 11, 2, 4424, 2933, 975, 5, 4758, 4, 11, 665, 4, 10, 31,\n",
              "  3940, 615, 2526, 38, 81, 6, 852, 5, 26916, 13700, 1133, 517, 17, 1041,\n",
              "  2085, 43, 5, 2, 852, 114, 30, 2, 331, 1728, 35, 16, 4, 59, 11614, 1346,\n",
              "  11, 26928, 13700, 1133, 517, 3, 11, 219, 12, 20, 8834, 5, 6, 709, 511, 5,\n",
              "  888, 20930, 250, 17, 190, 1289, 975, 284, 32, 3012, 19, 2709, 975, 16, 4,\n",
              "  10, 31, 662, 2, 1502, 852, 8, 3642, 341, 24332, 1133, 517, 3]             ,\n",
              " [6, 9252, 735, 5, 6, 207, 7, 6, 73, 5, 2499, 671, 24, 28, 14715, 31, 759,\n",
              "  3, 10, 46, 2, 70, 83, 5, 4431, 435, 14, 2578, 4, 28, 1181, 1115, 28, 5,\n",
              "  53, 671, 6, 10642, 753, 158, 6, 3758, 3685, 7546, 715, 1973, 3, 8, 363,\n",
              "  15, 36, 4, 10, 794, 62, 117, 2, 38, 249, 24, 2, 2578, 106, 64, 9873, 38,\n",
              "  57, 19, 189, 5306, 38, 7, 20876, 323, 3, 9, 21, 69, 1088, 2210, 94, 1308,\n",
              "  2578, 741, 24, 2, 988, 16403, 480, 18025, 3661, 4, 10, 41, 12, 6, 4431,\n",
              "  435, 26, 12, 1126, 117, 351, 38, 31, 32, 370, 197, 114, 825, 18, 9873, 38,\n",
              "  3]                                                                        ]>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abs_vocab = np.array(abs_text_processor.get_vocabulary())\n",
        "tokens = abs_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ],
      "metadata": {
        "id": "uxfJWxsz7CR_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "eed2db29-6a23-43d5-c4a7-0159771e73a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'in this paper , we describe our participation in the tempeval-3 challenge . with our multilingual temporal tagger heideltime , we addressed task a , the extraction and normalization of temporal expressions for english and spanish . exploiting heideltimes strict separation between source code and languagedependent parts , we tuned heideltimes existing english resources and developed new spanish resources . for both languages , we achieved the best results among all participants for task a , the combination of extraction and normalization . both the improved english and the new spanish resources are publicly available with heideltime .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(example_tokens.to_tensor())\n",
        "plt.title('Token IDs')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(example_tokens.to_tensor() != 0)\n",
        "plt.title('Mask')"
      ],
      "metadata": {
        "id": "0x6h44Rx7DLO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "064be988-4d80-4a1a-a5cb-ae7b41e1ae31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Mask')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(context, target):\n",
        "    context = abs_text_processor(context).to_tensor()\n",
        "    target = tit_text_processor(target)\n",
        "    targ_in = target[:,:-1].to_tensor()\n",
        "    targ_out = target[:,1:].to_tensor()\n",
        "    return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_dataset.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_dataset.map(process_text, tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "YKikU7rU7DBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "    print(ex_context_tok[0, :10].numpy()) \n",
        "    print()\n",
        "    print(ex_tar_in[0, :10].numpy()) \n",
        "    print(ex_tar_out[0, :10].numpy()) "
      ],
      "metadata": {
        "id": "CjMi1gDh7C25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c92ee02-643c-47fe-f3cb-235b90d32720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   9   15   25    4   10  110   22 1294    9    2]\n",
            "\n",
            "[   2 2793    9  740   95    6  454  529  150    0]\n",
            "[2793    9  740   95    6  454  529  150    3    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model components"
      ],
      "metadata": {
        "id": "E9ocw4rC9XLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "    depth = depth / 2\n",
        "    positions = np.arange(length)[:, np.newaxis]  # (seq, 1)\n",
        "    depths = np.arange(depth)[np.newaxis, :] / depth  # (1, depth)\n",
        "    angle_rates = 1 / (10000 ** depths)  # (1, depth)\n",
        "    angle_rads = positions * angle_rates  # (pos, depth)\n",
        "    pos_encoding = np.concatenate(\n",
        "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "        axis=-1)\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "        self.pos_encoding = self.positional_encoding(length=2048, depth=d_model)\n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "        return x\n",
        "    def positional_encoding(self, length, depth):\n",
        "      depth = depth/2\n",
        "\n",
        "      positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "      depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "      angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "      angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "      pos_encoding = np.concatenate(\n",
        "          [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "          axis=-1) \n",
        "\n",
        "      return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "class CrossAttention(BaseAttention):\n",
        "    def call(self, x, context):\n",
        "        attn_output, attn_scores = self.mha(\n",
        "            query=x,\n",
        "            key=context,\n",
        "            value=context,\n",
        "            return_attention_scores=True)\n",
        "        # Cache the attention scores for plotting later.\n",
        "        self.last_attn_scores = attn_scores\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "class GlobalSelfAttention(BaseAttention):\n",
        "    def call(self, x):\n",
        "        attn_output = self.mha(\n",
        "            query=x,\n",
        "            value=x,\n",
        "            key=x)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "class CausalSelfAttention(BaseAttention):\n",
        "    def call(self, x):\n",
        "        attn_output = self.mha(\n",
        "            query=x,\n",
        "            value=x,\n",
        "            key=x,\n",
        "            use_causal_mask = True)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.seq = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "    def call(self, x):\n",
        "        x = self.add([x, self.seq(x)])\n",
        "        x = self.layer_norm(x)\n",
        "        return x\n",
        "\n",
        "# class EncoderLayer(tf.keras.layers.Layer):\n",
        "#     def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "#         super().__init__()\n",
        "#         self.self_attention = GlobalSelfAttention(\n",
        "#             num_heads=num_heads,\n",
        "#             key_dim=d_model,\n",
        "#             dropout=dropout_rate)\n",
        "#         self.ffn = FeedForward(d_model, dff)\n",
        "#     def call(self, x):\n",
        "#         x = self.self_attention(x)\n",
        "#         x = self.ffn(x)\n",
        "#         return x"
      ],
      "metadata": {
        "id": "1w0JGabs9ZT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder\n",
        "\n",
        "```python\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "_Dvn5e_c84IP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attention = GlobalSelfAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=d_model,\n",
        "            dropout=dropout_rate)\n",
        "\n",
        "        self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.self_attention(x)\n",
        "        x = self.ffn(x)\n",
        "        return x\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads,\n",
        "                dff, vocab_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Wanneer we translator maken moeten we het volgende gebruiken:\n",
        "        # self.text_processor = text_processor\n",
        "        # self.vocab_size = vocab_size\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(\n",
        "            vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(d_model=d_model,\n",
        "                            num_heads=num_heads,\n",
        "                            dff=dff,\n",
        "                            dropout_rate=dropout_rate)\n",
        "            for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "        # `x` is token-IDs shape: (batch, seq_len)\n",
        "        x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "        # Add dropout.\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x)\n",
        "\n",
        "        return x  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    def convert_input(self, texts):\n",
        "        pass"
      ],
      "metadata": {
        "id": "1DAm7jXk8q_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0fsff308q1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder\n",
        "\n",
        "- https://github.com/mtjon/infompr-group-project/blob/feature/rnn/nmt_with_attention.ipynb\n"
      ],
      "metadata": {
        "id": "ZBmoCGLB8-Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "    \n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "                dropout_rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        ### TODO:\n",
        "        # word_to_id etc, zie RNN decoder van Nick en Jan\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                                    d_model=d_model)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.dec_layers = [\n",
        "            DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                            dff=dff, dropout_rate=dropout_rate)\n",
        "            for _ in range(num_layers)]\n",
        "\n",
        "        self.last_attn_scores = None\n",
        "\n",
        "    def call(self, x, context):\n",
        "        # `x` is token-IDs shape (batch, target_seq_len)\n",
        "        x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x  = self.dec_layers[i](x, context)\n",
        "\n",
        "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "        return x"
      ],
      "metadata": {
        "id": "PF8nBzyp8qsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PX4kE6je8qhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer|"
      ],
      "metadata": {
        "id": "toz57X_a9AJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "                input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                                num_heads=num_heads, dff=dff,\n",
        "                                vocab_size=input_vocab_size,\n",
        "                                dropout_rate=dropout_rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                                num_heads=num_heads, dff=dff,\n",
        "                                vocab_size=target_vocab_size,\n",
        "                                dropout_rate=dropout_rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "        # first argument.\n",
        "        context, x = inputs\n",
        "\n",
        "        context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "        x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "        # Final linear layer output.\n",
        "        logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "        try:\n",
        "            # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "            # b/250038731\n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        # Return the final output and the attention weights.\n",
        "        return logits\n",
        "\n"
      ],
      "metadata": {
        "id": "JeGisT4M8qVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "lf_hZel3Bmnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "    mask = label != 0\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "    loss = loss_object(label, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "    pred = tf.argmax(pred, axis=2)\n",
        "    label = tf.cast(label, pred.dtype)\n",
        "    match = label == pred\n",
        "\n",
        "    mask = label != 0\n",
        "\n",
        "    match = match & mask\n",
        "\n",
        "    match = tf.cast(match, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vz6aZoYKBm4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Van een paper:\n",
        "# d_model 1024, dff 4096, num heads 16\n",
        "# https://ufal.mff.cuni.cz/pbml/110/art-popel-bojar.pdf\n",
        "\n",
        "num_layers = 6\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8 # was 8\n",
        "dropout_rate = 0.1\n",
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=len(abs_text_processor.get_vocabulary()),\n",
        "    target_vocab_size=len(tit_text_processor.get_vocabulary()),\n",
        "    dropout_rate=dropout_rate)\n",
        "\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "#                                      epsilon=1e-9)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IEBDnkF0BzaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warmup step 16000 op basis van paper advies\n",
        "# beta 2 .98 zoals in paper\n",
        "# https://ufal.mff.cuni.cz/pbml/110/art-popel-bojar.pdf\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "  \n",
        "  def get_config(self):\n",
        "      config = {\n",
        "      'd_model': self.d_model,\n",
        "      'warmup_steps': self.warmup_steps,\n",
        "\n",
        "        }\n",
        "      return config\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "pyJ2rnxXJ7ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer.compile(\n",
        "#     loss=masked_loss,\n",
        "#     optimizer='adam',\n",
        "#     metrics=[masked_accuracy])\n",
        "\n",
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "lOQN8CL1KY0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    history = transformer.fit(train_ds,\n",
        "                            epochs=30,\n",
        "                            validation_data=val_ds,\n",
        "                            callbacks=tf.keras.callbacks.EarlyStopping(\n",
        "                                monitor='val_loss',\n",
        "                                patience=3))"
      ],
      "metadata": {
        "id": "Nfnd_dBVDdVc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7895d9a0-29ee-4ae8-b0ed-7ab304b9437d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "136/136 [==============================] - 150s 680ms/step - loss: 9.0237 - masked_accuracy: 0.0798 - val_loss: 8.7383 - val_masked_accuracy: 0.0951\n",
            "Epoch 2/30\n",
            "136/136 [==============================] - 73s 539ms/step - loss: 8.2828 - masked_accuracy: 0.0968 - val_loss: 7.8066 - val_masked_accuracy: 0.0951\n",
            "Epoch 3/30\n",
            "136/136 [==============================] - 76s 555ms/step - loss: 7.2268 - masked_accuracy: 0.0968 - val_loss: 6.9296 - val_masked_accuracy: 0.0951\n",
            "Epoch 4/30\n",
            "136/136 [==============================] - 74s 541ms/step - loss: 6.5822 - masked_accuracy: 0.1097 - val_loss: 6.6056 - val_masked_accuracy: 0.1196\n",
            "Epoch 5/30\n",
            "136/136 [==============================] - 74s 540ms/step - loss: 6.2407 - masked_accuracy: 0.1451 - val_loss: 6.3628 - val_masked_accuracy: 0.1554\n",
            "Epoch 6/30\n",
            "136/136 [==============================] - 75s 551ms/step - loss: 5.9345 - masked_accuracy: 0.1675 - val_loss: 6.2062 - val_masked_accuracy: 0.1760\n",
            "Epoch 7/30\n",
            "136/136 [==============================] - 75s 552ms/step - loss: 5.6667 - masked_accuracy: 0.1894 - val_loss: 6.1105 - val_masked_accuracy: 0.1873\n",
            "Epoch 8/30\n",
            "136/136 [==============================] - 75s 550ms/step - loss: 5.4394 - masked_accuracy: 0.2037 - val_loss: 6.0460 - val_masked_accuracy: 0.1933\n",
            "Epoch 9/30\n",
            "136/136 [==============================] - 75s 548ms/step - loss: 5.2294 - masked_accuracy: 0.2195 - val_loss: 6.0231 - val_masked_accuracy: 0.2039\n",
            "Epoch 10/30\n",
            "136/136 [==============================] - 75s 550ms/step - loss: 5.0298 - masked_accuracy: 0.2342 - val_loss: 6.0256 - val_masked_accuracy: 0.2092\n",
            "Epoch 11/30\n",
            "136/136 [==============================] - 75s 550ms/step - loss: 4.8308 - masked_accuracy: 0.2493 - val_loss: 5.9938 - val_masked_accuracy: 0.2154\n",
            "Epoch 12/30\n",
            "136/136 [==============================] - 75s 549ms/step - loss: 4.6533 - masked_accuracy: 0.2630 - val_loss: 5.9692 - val_masked_accuracy: 0.2125\n",
            "Epoch 13/30\n",
            "136/136 [==============================] - 75s 550ms/step - loss: 4.4750 - masked_accuracy: 0.2760 - val_loss: 5.8663 - val_masked_accuracy: 0.2156\n",
            "Epoch 14/30\n",
            "136/136 [==============================] - 75s 549ms/step - loss: 4.2958 - masked_accuracy: 0.2885 - val_loss: 5.8458 - val_masked_accuracy: 0.2172\n",
            "Epoch 15/30\n",
            "136/136 [==============================] - 75s 549ms/step - loss: 4.1291 - masked_accuracy: 0.3015 - val_loss: 5.8252 - val_masked_accuracy: 0.2233\n",
            "Epoch 16/30\n",
            "136/136 [==============================] - 73s 538ms/step - loss: 3.9568 - masked_accuracy: 0.3174 - val_loss: 5.8026 - val_masked_accuracy: 0.2195\n",
            "Epoch 17/30\n",
            "136/136 [==============================] - 75s 550ms/step - loss: 3.7701 - masked_accuracy: 0.3353 - val_loss: 5.8808 - val_masked_accuracy: 0.2163\n",
            "Epoch 18/30\n",
            "136/136 [==============================] - 73s 539ms/step - loss: 3.6019 - masked_accuracy: 0.3513 - val_loss: 5.9587 - val_masked_accuracy: 0.2141\n",
            "Epoch 19/30\n",
            "136/136 [==============================] - 75s 551ms/step - loss: 3.4508 - masked_accuracy: 0.3669 - val_loss: 6.0323 - val_masked_accuracy: 0.2096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "id": "7hOIyJX4CZ5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2438ae7-1bf8-4579-bb47-97bd512f676e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  7458432   \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  8474752   \n",
            "                                                                 \n",
            " dense_24 (Dense)            multiple                  1360563   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,293,747\n",
            "Trainable params: 17,293,747\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "yi3jvjni56Bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d59350-d3dc-48f2-cff3-25c324fc6bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save('/content/gdrive/My Drive/model_19012023_01', save_format=\"tf\")"
      ],
      "metadata": {
        "id": "7vJftqLz6IP6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "7ee5e763-38e6-46e6-a762-31d613c69b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, positional_embedding_layer_call_fn, positional_embedding_layer_call_and_return_conditional_losses, dropout_6_layer_call_fn, dropout_6_layer_call_and_return_conditional_losses while saving (showing 5 of 469). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-f41d14d77de0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/model_19012023_01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;31mTypeError\u001b[0m: Unable to serialize 128.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "id": "p3n9uT-CDZbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b7e7ee-0b5e-446a-e388-184bba80dc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'masked_accuracy', 'val_loss', 'val_masked_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['masked_accuracy'])\n",
        "plt.plot(history.history['val_masked_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pR_oGMsj6UQP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "93de7728-d8d5-441f-cb8c-683002d78fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "qnUy4A9QGm_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: we need to swap out the tokenizer from the original for our own tokenizer defined earlier\n",
        "# However, our tokenizer does not have a detokenize method and is just a simple function\n",
        "# as opposed to a Class instance with several methods.\n",
        "# We will likely want to define a `detokenize` function and pass that to the Translator\n",
        "# constructor as well.\n",
        "class Translator(tf.Module):\n",
        "  def __init__(self, tokenizer, detokenizer, transformer):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.detokenizer = detokenizer\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence):\n",
        "    # The input sentence is an abstract, hence adding the `[START]` and `[END]` tokens.\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    # TODO: use our own tokenizer\n",
        "    sentence = self.tokenizer(sentence).to_tensor()\n",
        "\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # As the output language a title, initialize the output with the\n",
        "    # `[START]` token.\n",
        "    # TODO: look up how to tokenize this\n",
        "    start_end = self.detokenizer([''])[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    # 50 is an arbitrary break-point\n",
        "    for i in tf.range(50):\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "      # Select the last token from the `seq_len` dimension.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate the `predicted_id` to the output which is given to the\n",
        "      # decoder as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "\n",
        "    tit_vocab = np.array(self.detokenizer.get_vocabulary())\n",
        "    tokens = tit_vocab[output.numpy()]\n",
        "    text = [' '.join(tok) for tok in tokens]\n",
        "\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    # text = self.detokenizer(output)[0]  # Shape: `()`.\n",
        "\n",
        "    #tokens = self.detokenizer lookup(output)[0]\n",
        "\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop.\n",
        "    # So, recalculate them outside the loop.\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    # return text, tokens, attention_weights\n",
        "    return text, attention_weights\n",
        "\n",
        "translator = Translator(abs_text_processor, tit_text_processor, transformer)\n",
        "\n",
        "def print_translation(abs, pred, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {abs}')\n",
        "  print(f'{\"Prediction\":15s}: {pred}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')\n"
      ],
      "metadata": {
        "id": "K0O3vIvaGjsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Output"
      ],
      "metadata": {
        "id": "iSqG_PgsoFJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = 'recognizing named entities in tweets'\n",
        "sentence = 'the challenges of named entities recognition ( ner ) for tweets lie in the insufficient information in a tweet and the unavailability of training data . we propose to combine a k-nearest neighbors ( knn ) classifier with a linear conditional random fields ( crf ) model under a semi-supervised learning framework to tackle these challenges . the knn based classifier conducts pre-labeling to collect global coarse evidence across tweets while the crf model conducts sequential labeling to capture fine-grained information encoded in a tweet . the semi-supervised learning plus the gazetteers alleviate the lack of training data . extensive experiments show the advantages of our method over the baselines as well as the effectiveness of knn and semisupervised learning .'"
      ],
      "metadata": {
        "id": "2np3nenYVbKy"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_text, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUVnjPlUGusk",
        "outputId": "83ac6675-e888-4271-9872-3a0beb69d099"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : the challenges of named entities recognition ( ner ) for tweets lie in the insufficient information in a tweet and the unavailability of training data . we propose to combine a k-nearest neighbors ( knn ) classifier with a linear conditional random fields ( crf ) model under a semi-supervised learning framework to tackle these challenges . the knn based classifier conducts pre-labeling to collect global coarse evidence across tweets while the crf model conducts sequential labeling to capture fine-grained information encoded in a tweet . the semi-supervised learning plus the gazetteers alleviate the lack of training data . extensive experiments show the advantages of our method over the baselines as well as the effectiveness of knn and semisupervised learning .\n",
            "Prediction     : ['[START] a hybrid approach to build a supervised approach to named entity recognition in community question answering [END]']\n",
            "Ground truth   : recognizing named entities in tweets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second Output"
      ],
      "metadata": {
        "id": "rHs1--ZPoJAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = 'interactive grammar development with wcdg'\n",
        "sentence = 'the manual design of grammars for accurate natural language analysis is an iterative process ; while modelling decisions usually determine parser behaviour , evidence from analysing more or different input can suggest unforeseen regularities , which leads to a reformulation of rules , or even to a different model of previously analysed phenomena . we describe an implementation of weighted constraint dependency grammar that supports the grammar writer by providing display , automatic analysis , and diagnosis of dependency analyses and allows the direct exploration of alternative analyses and their status under the current grammar .'"
      ],
      "metadata": {
        "id": "PZWgIPqEfi09"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_text, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zYDjbxjoRiQ",
        "outputId": "7070a154-d5f2-4f59-c288-1a31352a7b39"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : the manual design of grammars for accurate natural language analysis is an iterative process ; while modelling decisions usually determine parser behaviour , evidence from analysing more or different input can suggest unforeseen regularities , which leads to a reformulation of rules , or even to a different model of previously analysed phenomena . we describe an implementation of weighted constraint dependency grammar that supports the grammar writer by providing display , automatic analysis , and diagnosis of dependency analyses and allows the direct exploration of alternative analyses and their status under the current grammar .\n",
            "Prediction     : ['[START] a hybrid approach to the scope of the automatic discourse structure of noun phrases in the mitre corporation [END]']\n",
            "Ground truth   : interactive grammar development with wcdg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rhE_LW7TZ40"
      },
      "source": [
        "Create a function that plots the attention when a token is generated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:16.568111Z",
          "iopub.status.busy": "2022-12-14T13:16:16.567554Z",
          "iopub.status.idle": "2022-12-14T13:16:16.572702Z",
          "shell.execute_reply": "2022-12-14T13:16:16.572043Z"
        },
        "id": "gKlxYO0JTXzD"
      },
      "outputs": [],
      "source": [
        "def plot_attention_head(in_tokens, translated_tokens, attention):\n",
        "  # The model didn't generate `<START>` in the output. Skip it.\n",
        "  translated_tokens = translated_tokens[1:]\n",
        "\n",
        "  ax = plt.gca()\n",
        "  ax.matshow(attention)\n",
        "  ax.set_xticks(range(len(in_tokens)))\n",
        "  ax.set_yticks(range(len(translated_tokens)))\n",
        "\n",
        "  labels = [label for label in in_tokens]\n",
        "  ax.set_xticklabels(\n",
        "      labels, rotation=90)\n",
        "\n",
        "  labels = [label for label in translated_tokens]\n",
        "  ax.set_yticklabels(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:16.575517Z",
          "iopub.status.busy": "2022-12-14T13:16:16.575276Z",
          "iopub.status.idle": "2022-12-14T13:16:16.581279Z",
          "shell.execute_reply": "2022-12-14T13:16:16.580678Z"
        },
        "id": "yI4YWU2uXDeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4724c016-f9ba-4184-d7f3-76036a561b07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([19, 96])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "head = 0\n",
        "# Shape: `(batch=1, num_heads, seq_len_q, seq_len_k)`.\n",
        "attention_heads = tf.squeeze(attention_weights, 0)\n",
        "attention = attention_heads[head]\n",
        "attention.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "facNouzOXMSu"
      },
      "source": [
        "These are the input (abstracts) tokens:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_tokens = tf.convert_to_tensor([sentence])\n",
        "abs_vocab = np.array(abs_text_processor.get_vocabulary())\n",
        "in_tokens = abs_text_processor(in_tokens).to_tensor()\n",
        "in_tokens = abs_vocab[in_tokens.numpy()]\n",
        "in_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5w2dBCEkxFX",
        "outputId": "c28fd894-b448-4273-fc42-be3005a843eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['the', 'manual', 'design', 'of', 'grammars', 'for', 'accurate',\n",
              "        'natural', 'language', 'analysis', 'is', 'an', 'iterative',\n",
              "        'process', ';', 'while', 'modelling', 'decisions', 'usually',\n",
              "        'determine', 'parser', 'behaviour', ',', 'evidence', 'from',\n",
              "        'analysing', 'more', 'or', 'different', 'input', 'can',\n",
              "        'suggest', '[UNK]', 'regularities', ',', 'which', 'leads', 'to',\n",
              "        'a', 'reformulation', 'of', 'rules', ',', 'or', 'even', 'to',\n",
              "        'a', 'different', 'model', 'of', 'previously', 'analysed',\n",
              "        'phenomena', '.', 'we', 'describe', 'an', 'implementation', 'of',\n",
              "        'weighted', 'constraint', 'dependency', 'grammar', 'that',\n",
              "        'supports', 'the', 'grammar', 'writer', 'by', 'providing',\n",
              "        'display', ',', 'automatic', 'analysis', ',', 'and', 'diagnosis',\n",
              "        'of', 'dependency', 'analyses', 'and', 'allows', 'the', 'direct',\n",
              "        'exploration', 'of', 'alternative', 'analyses', 'and', 'their',\n",
              "        'status', 'under', 'the', 'current', 'grammar', '.']],\n",
              "      dtype='<U43')"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLg9HTKCXPKz"
      },
      "source": [
        "And these are the output (titles) tokens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:16.612946Z",
          "iopub.status.busy": "2022-12-14T13:16:16.612247Z",
          "iopub.status.idle": "2022-12-14T13:16:16.616814Z",
          "shell.execute_reply": "2022-12-14T13:16:16.616184Z"
        },
        "id": "GzvIo5uYTnHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce37af6-ddc6-4552-c4d3-ccccbee13ae7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['[START]', '[UNK]', 'a', 'hybrid', 'approach', 'to', 'the',\n",
              "        'scope', 'of', 'the', 'automatic', 'discourse', 'structure',\n",
              "        'of', 'noun', 'phrases', 'in', 'the', 'mitre', 'corporation',\n",
              "        '[UNK]', '[END]']], dtype='<U30')"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "out_tokens = tf.convert_to_tensor([translated_text])\n",
        "tit_vocab = np.array(tit_text_processor.get_vocabulary())\n",
        "out_tokens = tit_text_processor(out_tokens).to_tensor()\n",
        "out_tokens = tit_vocab[out_tokens.numpy()]\n",
        "out_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:16.620043Z",
          "iopub.status.busy": "2022-12-14T13:16:16.619420Z",
          "iopub.status.idle": "2022-12-14T13:16:16.856634Z",
          "shell.execute_reply": "2022-12-14T13:16:16.855927Z"
        },
        "id": "lrNh47D1ToBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "bfddf9b7-1778-481a-c1aa-cb1a2e4b0da2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_attention_head(in_tokens[0], out_tokens[0], attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:16.860091Z",
          "iopub.status.busy": "2022-12-14T13:16:16.859496Z",
          "iopub.status.idle": "2022-12-14T13:16:16.864552Z",
          "shell.execute_reply": "2022-12-14T13:16:16.863896Z"
        },
        "id": "iMZr-rI_TrGh"
      },
      "outputs": [],
      "source": [
        "def plot_attention_weights(sentence, translated_tokens, attention_heads):\n",
        "  # in_tokens = tf.convert_to_tensor([sentence])\n",
        "  # in_tokens = tokenizer(in_tokens).to_tensor()\n",
        "  # tit_vocab = np.array(tit_text_processor.get_vocabulary())\n",
        "  # out_tokens = tit_vocab[in_tokens.numpy()]\n",
        "  # in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n",
        "\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "  for h, head in enumerate(attention_heads):\n",
        "    ax = fig.add_subplot(2, 4, h+1)\n",
        "\n",
        "    plot_attention_head(in_tokens, translated_tokens, head)\n",
        "\n",
        "    ax.set_xlabel(f'Head {h+1}')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:16.867603Z",
          "iopub.status.busy": "2022-12-14T13:16:16.867130Z",
          "iopub.status.idle": "2022-12-14T13:16:18.483047Z",
          "shell.execute_reply": "2022-12-14T13:16:18.482333Z"
        },
        "id": "lBMujUb1Tr4C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dde027a1-1c23-444b-9f1d-4ed1d06d61b3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-72e561f810e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plot_attention_weights(sentence,\n\u001b[0m\u001b[1;32m      2\u001b[0m                        \u001b[0mout_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                        attention_weights[0])\n",
            "\u001b[0;32m<ipython-input-98-79f83f03f6d1>\u001b[0m in \u001b[0;36mplot_attention_weights\u001b[0;34m(sentence, translated_tokens, attention_heads)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplot_attention_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Head {h+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-1a472b7e538b>\u001b[0m in \u001b[0;36mplot_attention_head\u001b[0;34m(in_tokens, translated_tokens, attention)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0min_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   ax.set_xticklabels(\n\u001b[0m\u001b[1;32m     12\u001b[0m       labels, rotation=90)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mset_xticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   3386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3387\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3388\u001b[0;31m         ret = self.xaxis.set_ticklabels(labels,\n\u001b[0m\u001b[1;32m   3389\u001b[0m                                         minor=minor, **kwargs)\n\u001b[1;32m   3390\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0;31m# deal with label1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0;31m# deal with label2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mset_text\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <function install_repl_displayhook.<locals>.post_execute at 0x7f2617dc5280> (for post_execute):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpost_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# IPython >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1229\u001b[0m                                                                 renderer)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_ticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mminor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_label1\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mset_text\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1229\u001b[0m                                                                 renderer)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_ticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mminor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_label1\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mset_text\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_attention_weights(sentence,\n",
        "                       out_tokens,\n",
        "                       attention_weights[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N5S5IptTtHI"
      },
      "source": [
        "The model can handle unfamiliar words. Neither `'triceratops'` nor `'encyclopédia'` are in the input dataset, and the model attempts to transliterate them even without a shared vocabulary. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:18.486936Z",
          "iopub.status.busy": "2022-12-14T13:16:18.486381Z",
          "iopub.status.idle": "2022-12-14T13:16:22.147119Z",
          "shell.execute_reply": "2022-12-14T13:16:22.146371Z"
        },
        "id": "w0-5gjfWT0CS"
      },
      "outputs": [],
      "source": [
        "sentence = 'Eu li sobre triceratops na enciclopédia.'\n",
        "ground_truth = 'I read about triceratops in the encyclopedia.'\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)\n",
        "\n",
        "plot_attention_weights(sentence, translated_tokens, attention_weights[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zz4uIDbT1OU"
      },
      "source": [
        "## Export the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zunHPJJzT4Cz"
      },
      "source": [
        "You have tested the model and the inference is working. Next, you can export it as a `tf.saved_model`. To learn about saving and loading a model in the SavedModel format, use [this guide](https://www.tensorflow.org/guide/saved_model).\n",
        "\n",
        "Create a class called `ExportTranslator` by subclassing the `tf.Module` subclass with a `tf.function` on the `__call__` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:22.151498Z",
          "iopub.status.busy": "2022-12-14T13:16:22.151229Z",
          "iopub.status.idle": "2022-12-14T13:16:22.156095Z",
          "shell.execute_reply": "2022-12-14T13:16:22.155449Z"
        },
        "id": "NZhv5h4AT_n5"
      },
      "outputs": [],
      "source": [
        "class ExportTranslator(tf.Module):\n",
        "  def __init__(self, translator):\n",
        "    self.translator = translator\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
        "  def __call__(self, sentence):\n",
        "    (result,\n",
        "     tokens,\n",
        "     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wad7lUtPUAnf"
      },
      "source": [
        "In the above `tf.function` only the output sentence is returned. Thanks to the [non-strict execution](https://tensorflow.org/guide/intro_to_graphs) in `tf.function` any unnecessary values are never computed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7KJEFWI5v84"
      },
      "source": [
        "Wrap `translator` in the newly created `ExportTranslator`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:22.159813Z",
          "iopub.status.busy": "2022-12-14T13:16:22.159363Z",
          "iopub.status.idle": "2022-12-14T13:16:22.162487Z",
          "shell.execute_reply": "2022-12-14T13:16:22.161926Z"
        },
        "id": "wm1_eRPvUCUm"
      },
      "outputs": [],
      "source": [
        "translator = ExportTranslator(translator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VPH4T5XUDnc"
      },
      "source": [
        "Since the model is decoding the predictions using `tf.argmax` the predictions are deterministic. The original model and one reloaded from its `SavedModel` should give identical predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:22.165485Z",
          "iopub.status.busy": "2022-12-14T13:16:22.165065Z",
          "iopub.status.idle": "2022-12-14T13:16:26.842584Z",
          "shell.execute_reply": "2022-12-14T13:16:26.841908Z"
        },
        "id": "GITRCiAYUE5w"
      },
      "outputs": [],
      "source": [
        "translator('este é o primeiro livro que eu fiz.').numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:26.846081Z",
          "iopub.status.busy": "2022-12-14T13:16:26.845503Z",
          "iopub.status.idle": "2022-12-14T13:16:53.800376Z",
          "shell.execute_reply": "2022-12-14T13:16:53.799520Z"
        },
        "id": "_v--e1XmUFw3"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(translator, export_dir='translator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:16:53.810934Z",
          "iopub.status.busy": "2022-12-14T13:16:53.810215Z",
          "iopub.status.idle": "2022-12-14T13:17:01.854627Z",
          "shell.execute_reply": "2022-12-14T13:17:01.853874Z"
        },
        "id": "5KJSQEzlUGo-"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load('translator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-14T13:17:01.859084Z",
          "iopub.status.busy": "2022-12-14T13:17:01.858547Z",
          "iopub.status.idle": "2022-12-14T13:17:03.872200Z",
          "shell.execute_reply": "2022-12-14T13:17:03.871451Z"
        },
        "id": "lIVpKWBNUHhr"
      },
      "outputs": [],
      "source": [
        "reloaded('este é o primeiro livro que eu fiz.').numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri2i6cTxUI00"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial you learned about:\n",
        "\n",
        "* The Transformers and their significance in machine learning\n",
        "* Attention, self-attention and multi-head attention\n",
        "* Positional encoding with embeddings\n",
        "* The encoder-decoder architecture of the original Transformer\n",
        "* Masking in self-attention\n",
        "* How to put it all together to translate text\n",
        "\n",
        "The downsides of this architecture are:\n",
        "\n",
        "- For a time-series, the output for a time-step is calculated from the *entire history* instead of only the inputs and current hidden-state. This _may_ be less efficient.\n",
        "- If the input has a temporal/spatial relationship, like text or images, some positional encoding must be added or the model will effectively see a bag of words.\n",
        "\n",
        "If you want to practice, there are many things you could try with it. For example:\n",
        "\n",
        "* Use a different dataset to train the Transformer.\n",
        "* Create the \"Base Transformer\" or \"Transformer XL\" configurations from the original paper by changing the hyperparameters.\n",
        "* Use the layers defined here to create an implementation of [BERT](https://arxiv.org/abs/1810.04805)t beam search to get better predictions.\n",
        "\n",
        "There are a wide variety of Transformer-based models, many of which improve upon the 2017 version of the original Transformer with encoder-decoder, encoder-only and decoder-only architectures.\n",
        "\n",
        "Some of these models are covered in the following research publications:\n",
        "\n",
        "* [\"Efficient Transformers: a survey\"](https://arxiv.org/abs/2009.06732) (Tay et al., 2022)\n",
        "* [\"Formal algorithms for Transformers\"](https://arxiv.org/abs/2207.09238) (Phuong and Hutter, 2022).\n",
        "* [T5 (\"Exploring the limits of transfer learning with a unified text-to-text Transformer\")](https://arxiv.org/abs/1910.10683) (Raffel et al., 2019)\n",
        "\n",
        "You can learn more about other models in the following Google blog posts:\n",
        "\n",
        "* [PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html).\n",
        "* [LaMDA](https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html)\n",
        "* [MUM](https://blog.google/products/search/introducing-mum/)\n",
        "* [Reformer](https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html)\n",
        "* [BERT](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html)\n",
        "\n",
        "If you're interested in studying how attention-based models have been applied in tasks outside of natural language processing, check out the following resources:\n",
        "\n",
        "- Vision Transformer (ViT): [Transformers for image recognition at scale](https://ai.googleblog.com/2020/12/transformers-for-image-recognition-at.html)\n",
        "- [Multi-task multitrack music transcription (MT3)](https://magenta.tensorflow.org/transcription-with-transformers) with a Transformer\n",
        "- [Code generation with AlphaCode](https://www.deepmind.com/blog/competitive-programming-with-alphacode)\n",
        "- [Reinforcement learning with multi-game decision Transformers](https://ai.googleblog.com/2022/07/training-generalist-agents-with-multi.html)\n",
        "- [Protein structure prediction with AlphaFold](https://www.nature.com/articles/s41586-021-03819-2)\n",
        "- [OptFormer: Towards universal hyperparameter optimization with Transformers](http://ai.googleblog.com/2022/08/optformer-towards-universal.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kk6IeFbP0ei"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}