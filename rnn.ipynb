{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtjon/infompr-group-project/blob/feature%2Frnn/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nma_JWh-W-IF"
      },
      "source": [
        "# Title Generation through Abstract Summarisation with RNNs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N0RTnvaqU4P"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_vHnSLfBZo2",
        "outputId": "629e8b44-5b32-4dff-d488-f42ca566651f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcudnn8 is already the newest version (8.1.0.77-1+cuda11.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "# Install the most re version of TensorFlow to use the improved\n",
        "# masking support for `tf.keras.layers.MultiHeadAttention`.\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "!pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q -U tensorflow-text==2.9.* tensorflow==2.9.*\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJr_9dXGpJ05"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text\n",
        "import tensorflow_text as tf_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gE-Ez1qtyIA"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfxDR9Gt_0ix"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from random import shuffle\n",
        "# Seed voor herhaalbaarheid\n",
        "random.seed(42)\n",
        "\n",
        "TRAIN_PCT = 70\n",
        "TEST_PCT = 25\n",
        "VAL_PCT = 5\n",
        "\n",
        "TOTAL_PCT = TRAIN_PCT + TEST_PCT + VAL_PCT\n",
        "\n",
        "# modified data externally to remove all blank lines\n",
        "def write_data(f, ext, mod):\n",
        "    # Code van https://github.com/EagleW/Writing-editing-Network/blob/master/split_data.py\n",
        "    file1=open(f, 'r')\n",
        "    lines=file1.readlines()\n",
        "    file1.close()\n",
        "    abs_t = []\n",
        "    abstracts = []\n",
        "    titles = []\n",
        "    i = 0\n",
        "    # TODO: possibly generates wrong tibs/abs when encounter\n",
        "    for line in lines:\n",
        "        if i % mod == 0:\n",
        "            titles.append(line)\n",
        "        elif i % mod == 1:\n",
        "            abstracts.append(line)\n",
        "        i += 1\n",
        "    for i in range(len(abstracts)):\n",
        "        if len(titles[i]) > 0 and len(abstracts[i]) > 0:\n",
        "            h_a_pair = (titles[i], abstracts[i])\n",
        "            abs_t.append(h_a_pair)\n",
        "\n",
        "    GRANULARITY_FACTOR = 100\n",
        "\n",
        "    shuffle(abs_t)\n",
        "    total_lines = len(abs_t)\n",
        "    train_lines = (((total_lines * GRANULARITY_FACTOR) // TOTAL_PCT) * TRAIN_PCT) // GRANULARITY_FACTOR\n",
        "    test_lines = (((total_lines * GRANULARITY_FACTOR) // TOTAL_PCT) * TEST_PCT) // GRANULARITY_FACTOR\n",
        "    val_lines = total_lines - (train_lines + test_lines) # different calculation to ensure no lines get left out\n",
        "\n",
        "    i = 0\n",
        "    with open(\"val{}.txt\".format(ext), 'w') as file1:\n",
        "      for i in range(train_lines):\n",
        "          file1.writelines(abs_t[i][0])\n",
        "          file1.writelines(abs_t[i][1])\n",
        "      #    file1.writelines(\"\\n\")\n",
        "\n",
        "    with open(\"test{}.txt\".format(ext), 'w') as file1:\n",
        "      for i in range(train_lines, train_lines+test_lines):\n",
        "          file1.writelines(abs_t[i][0])\n",
        "          file1.writelines(abs_t[i][1])\n",
        "      #    file1.writelines(\"\\n\")\n",
        "\n",
        "    with open(\"train{}.txt\".format(ext), 'w') as file1:\n",
        "      for i in range(train_lines+test_lines, total_lines):\n",
        "          file1.writelines(abs_t[i][0])\n",
        "          file1.writelines(abs_t[i][1])\n",
        "      #    file1.writelines(\"\\n\")\n",
        "\n",
        "    print(\"Split data into (train, test, validate) as follows: \", (train_lines, test_lines, val_lines), \"from total lines:\", total_lines)\n",
        "\n",
        "\n",
        "def get_abs_and_titles_from_raw(path_to_file):\n",
        "    abstracts, titles = [], []\n",
        "    with open(path_to_file) as data:\n",
        "        lines = data.readlines()\n",
        "        for abs in lines[1::2]:\n",
        "            abstracts.append(abs.strip())\n",
        "        for title in lines[0::2]:\n",
        "            # // TODO: check if we need to add start and end tokens\n",
        "            titles.append(title.strip())\n",
        "            # titles.append('[START] ' + title.strip() + ' [END]')\n",
        "    return abstracts, titles\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary when upload fails (Firefox+Colab issue)\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "1cdZ-lfi6w1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39UNm84FHK5Z",
        "outputId": "dcbcd470-a2e9-45eb-f135-f6843d63abff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split data into (train, test, validate) as follows:  (7612, 2718, 545) from total lines: 10875\n"
          ]
        }
      ],
      "source": [
        "write_data(\"acl_titles_and_abstracts_mod.txt\", \"\", 2) # writes train, val, test.txt\n",
        "\n",
        "train_text, train_labels = get_abs_and_titles_from_raw('train.txt')\n",
        "val_text, val_labels = get_abs_and_titles_from_raw('val.txt')\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_text, train_labels)).batch(16)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_text, val_labels)).batch(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzLBGVwDJ5hC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28bccf5c-d923-4a03-8c7d-443e4bdf5342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Abstract examples:\n",
            "1 the computation of meaning similarity as operationalized by vector-based models has found widespread use in many tasks ranging from the acquisition of synonyms and paraphrases to word sense disambiguation and textual entailment . vector-based models are typically directed at representing words in isolation and thus best suited for measuring similarity out of context . in his paper we propose a probabilistic framework for measuring similarity in context . central to our approach is the intuition that word meaning is represented as a probability distribution over a set of latent senses and is modulated by context . experimental results on lexical substitution and word similarity show that our algorithm outperforms previously proposed models .\n",
            "2 this paper ties up some loose ends in finite-state optimality theory . first , it discusses how to perform comprehension under optimality theory grammars consisting of finite-state constraints . comprehension has not been much studied in ot ; we show that unlike production , it does not always yield a regular set , making finite-state methods inapplicable . however , after giving a suitably flexible presentation of ot , we show carefully how to treat comprehension under recent variants of ot in which grammars can be compiled into finite-state transducers . we then unify these variants , showing that compilation is possible if all components of the grammar are regular relations , including the harmony ordering on scored candidates . a side benefit of our construction is a far simpler implementation of directional ot ( eisner , 2000 ) .\n",
            "3 code-switched documents are common in social media , providing evidence for polylingual topic models to infer aligned topics across languages . we present code-switched lda ( cslda ) , which infers language specific topic distributions based on code-switched documents to facilitate multi-lingual corpus analysis . we experiment on two code-switching corpora ( english-spanish twitter data and english-chinese weibo data ) and show that cslda improves perplexity over lda , and learns semantically coherent aligned topics as judged by human annotators .\n",
            "4 in cases in which there is no standard orthography for a language or language variant , written texts will display a variety of orthographic choices . this is problematic for natural language processing ( nlp ) because it creates spurious data sparseness . we study the transformation of spontaneously spelled egyptian arabic into a conventionalized orthography which we have previously proposed for nlp purposes . we show that a two-stage process can reduce divergences from this standard by 69 % , making subsequent processing of egyptian arabic easier .\n",
            "5 this paper describes a system designed to disambiguate person names in a set of web pages . in our approach web documents are represented as different sets of features or terms of different types ( bag of words , urls , names and numbers ) . we apply agglomerative vector space clustering that uses the similarity between pairs of analogous feature sets . this system achieved a value of 66 % for f=0.2 and a value of 48 % for f=0.5 in the web people search task at semeval-2007 .\n",
            "6 we introduce a social media text normalization system that can be deployed as a preprocessing step for machine translation and various nlp applications to handle social media text . the proposed system is based on unsupervised learning of the normalization equivalences from unlabeled text . the proposed approach uses random walks on a contextual similarity bipartite graph constructed from n-gram sequences on large unlabeled text corpus . we show that the proposed approach has a very high precision of ( 92.43 ) and a reasonable recall of ( 56.4 ) . when used as a preprocessing step for a state-of-the-art machine translation system , the translation quality on social media text improved by 6 % . the proposed approach is domain and language independent and can be deployed as a preprocessing step for any nlp application to handle social media text .\n",
            "7 information extraction ( ie ) systems assist analysts to assimilate information from electronic documents . this paper focuses on ie tasks designed to support information discovery applications . since information discovery implies examining large volumes of documents drawn from various sources for situations that can not be anticipated a priori , they require ie systems to have breadth as well as depth . this implies the need for a domain-independent ie system that can easily be customized for specific domains : end users must be given tools to customize the system on their own . it also implies the need for defining new intermediate level ie tasks that are richer than the subject-verb-object ( svo ) triples produced by shallow systems , yet not as complex as the domain-specific scenarios defined by the message understanding conference ( muc ) . this paper describes a robust , scalable ie engine designed for such purposes . it describes new ie tasks such as entity profiles , and concept-based general events which represent realistic goals in terms of what can be accomplished in the near-term as well as providing useful , actionable information . these new tasks also facilitate the correlation of output from an ie engine with existing structured data . benchmarking results for the core engine and applications utilizing the engine are presented .\n",
            "8 in this paper we investigate the efficiency of the novel term weighting algorithm for opinion mining and topic categorization of articles from newspapers and internet . we compare the novel term weighting technique with existing approaches such as tf-idf and confweight . the performance on the data from the text-mining campaigns deft07 and deft08 shows that the proposed method can compete with existing information retrieval models in classification quality and that it is computationally faster . the proposed text preprocessing method can be applied in large-scale information retrieval and data mining problems and it can be easily transported to different domains and different languages since it does not require any domain-related or linguistic information .\n",
            "9 frequency counts from very large corpora , such as the web 1t dataset , have recently become available for language modeling . omission of low frequency n-gram counts is a practical necessity for datasets of this size . naive implementations of standard smoothing methods do not realize the full potential of such large datasets with missing counts . in this paper i present a new smoothing algorithm that combines the dirichlet prior form of ( mackay and peto , 1995 ) with the modified back-off estimates of ( kneser and ney , 1995 ) that leads to a 31 % perplexity reduction on the brown corpus compared to a baseline implementation of kneser-ney discounting .\n",
            "10 we introduce several ideas that improve the performance of supervised information extraction systems with a pipeline architecture , when they are customized for new domains . we show that : ( a ) a combination of a sequence tagger with a rule-based approach for entity mention extraction yields better performance for both entity and relation mention extraction ; ( b ) improving the identification of syntactic heads of entity mentions helps relation extraction ; and ( c ) a deterministic inference engine captures some of the joint domain structure , even when introduced as a postprocessing step to a pipeline system . all in all , our contributions yield a 20 % relative increase in f1 score in a domain significantly different from the domains used during the development of our information extraction system .\n",
            "11 this paper presents an approach to the question whether it is possible to construct a parser based on ideas from case-based reasoning . such a parser would employ a partial analysis of the input sentence to select a ( nearly ) complete syntax tree and then adapt this tree to the input sentence . the experiments performed on german data from the tuba-d/z treebank and the karopars partial parser show that a wide range of levels of generality can be reached , depending on which types of information are used to determine the similarity between input sentence and training sentences . the results are such that it is possible to construct a case-based parser . the optimal setting out of those presented here need to be determined empirically .\n",
            "12 in modern biology , digitization of biosystematics publications is an important task . extraction of taxonomic names from such documents is one of its major issues . this is because these names identify the various genera and species . this article reports on our experiences with learning techniques for this particular task . we say why established named-entity recognition techniques are somewhat difficult to use in our context . one reason is that we have only very little training data available . our experiments show that a combining approach that relies on regular expressions , heuristics , and word-level language recognition achieves very high precision and recall and allows to cope with those difficulties .\n",
            "13 sentence compression has been shown to benefit from joint inference involving both n-gram and dependency-factored objectives but this typically requires expensive integer programming . we explore instead the use of lagrangian relaxation to decouple the two subproblems and solve them separately . while dynamic programming is viable for bigram-based sentence compression , finding optimal compressed trees within graphs is np-hard . we recover approximate solutions to this problem using lp relaxation and maximum spanning tree algorithms , yielding techniques that can be combined with the efficient bigrambased inference approach using lagrange multipliers . experiments show that these approximation strategies produce results comparable to a state-of-the-art integer linear programming formulation for the same joint inference task along with a significant improvement in runtime .\n",
            "14 we approached the problem as learning how to order documents by estimated relevance with respect to a user query . our support vector machines based classifier learns from the relevance judgments available with the standard test collections and generalizes to new , previously unseen queries . for this , we have designed a representation scheme , which is based on the discrete representation of the local ( lw ) and global ( gw ) weighting functions , thus is capable of reproducing and enhancing the properties of such popular ranking functions as tf.idf , bm25 or those based on language models . our tests with the standard test collections have demonstrated the capability of our approach to achieve the performance of the best known scoring functions solely from the labeled examples and without taking advantage of knowing those functions or their important properties or parameters .\n",
            "15 this paper presents a method for automatic topic identification using a graph-centrality algorithm applied to an encyclopedic graph derived from wikipedia . when tested on a data set with manually assigned topics , the system is found to significantly improve over a simpler baseline that does not make use of the external encyclopedic knowledge .\n",
            "16 a lack of standard datasets and evaluation metrics has prevented the field of paraphrasing from making the kind of rapid progress enjoyed by the machine translation community over the last 15 years . we address both problems by presenting a novel data collection framework that produces highly parallel text data relatively inexpensively and on a large scale . the highly parallel nature of this data allows us to use simple n-gram comparisons to measure both the semantic adequacy and lexical dissimilarity of paraphrase candidates . in addition to being simple and efficient to compute , experiments show that these metrics correlate highly with human judgments .\n",
            "\n",
            "> Title examples:\n",
            "1 measuring distributional similarity in context\n",
            "2 comprehension and compilation in optimality theory\n",
            "3 learning polylingual topic models from code-switched social media documents\n",
            "4 processing spontaneous orthography\n",
            "5 composition of simple bags of typed terms escuela politcnica superior legans ( madrid ) spain\n",
            "6 social text normalization using contextual graph random walks\n",
            "7 infoxtract : a customizable intermediate level information\n",
            "8 opinion mining and topic categorization with novel term weighting\n",
            "9 smoothing a tera-word language model\n",
            "10 customizing an information extraction system to a new domain\n",
            "11 towards case-based parsing : are chunks reliable indicators for syntax trees\n",
            "12 the difficulties of taxonomic name extraction and a solution guido sautter klemens bhm\n",
            "13 approximation strategies for multi-structure sentence compression\n",
            "14 discretization based learning approach to information retrieval dmitri roussinov weiguo fan\n",
            "15 topic identification using wikipedia graph centrality\n",
            "16 collecting highly parallel data for paraphrase evaluation\n"
          ]
        }
      ],
      "source": [
        "for abs, tit in train_dataset.take(1):\n",
        "    print('> Abstract examples:')\n",
        "    for i, a in enumerate(abs.numpy()):\n",
        "        print(i+1, a.decode('utf-8'))\n",
        "        \n",
        "    print()\n",
        "    \n",
        "    print('> Title examples:')\n",
        "    for i, t in enumerate(tit.numpy()):\n",
        "        print(i+1, t.decode('utf-8'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv9eKCJpJ6ER"
      },
      "outputs": [],
      "source": [
        "def title_preprocessor(text):\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.strip(text)\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text\n",
        "\n",
        "def abstract_preprocessor(text):\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.strip(text)\n",
        "    return text\n",
        "\n",
        "abs_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=abstract_preprocessor,\n",
        "    ragged=True,\n",
        "    output_mode='int'\n",
        "    )\n",
        "\n",
        "tit_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=title_preprocessor,\n",
        "    ragged=True,\n",
        "    output_mode='int'\n",
        "    )\n",
        "\n",
        "abs_text_processor.adapt(train_dataset.map(lambda abs, tit: abs))\n",
        "tit_text_processor.adapt(train_dataset.map(lambda abs, tit: tit))\n",
        "\n",
        "\n",
        "\n",
        "def process_text(context, target):\n",
        "    context = abs_text_processor(context).to_tensor()\n",
        "    target = tit_text_processor(target)\n",
        "    targ_in = target[:,:-1].to_tensor()\n",
        "    targ_out = target[:,1:].to_tensor()\n",
        "    return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_dataset.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_dataset.map(process_text, tf.data.AUTOTUNE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import einops\n",
        "\n",
        "#@title\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "    for name, new_dim in parsed.items():\n",
        "      old_dim = self.shapes.get(name, None)\n",
        "      \n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "metadata": {
        "id": "QVwvbAJKQdjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32JH-g8bIXq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f6c636-e82a-4f83-a54f-167c5f43bb27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   2 1856    5  349  116   19 4431   20 2499   53]\n",
            "\n",
            "[  2 216 130  40   8 104   0   0   0   0]\n",
            "[216 130  40   8 104   3   0   0   0   0]\n",
            "Context tokens, shape (batch, s): (16, 223)\n",
            "Encoder output, shape (batch, s, units): (16, 223, 256)\n"
          ]
        }
      ],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.units = units\n",
        "    \n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                               mask_zero=True)\n",
        "\n",
        "    # The RNN layer processes those vectors sequentially.\n",
        "    self.rnn = tf.keras.layers.Bidirectional(\n",
        "        merge_mode='sum',\n",
        "        layer=tf.keras.layers.GRU(units,\n",
        "                            # Return the sequence and state\n",
        "                            return_sequences=True,\n",
        "                            recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "  def call(self, x):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch s')\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding vector for each token.\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 3. The GRU processes the sequence of embeddings.\n",
        "    x = self.rnn(x)\n",
        "    shape_checker(x, 'batch s units')\n",
        "\n",
        "    # 4. Returns the new sequence of embeddings.\n",
        "    return x\n",
        "\n",
        "  def convert_input(self, texts):\n",
        "    texts = tf.convert_to_tensor(texts)\n",
        "    if len(texts.shape) == 0:\n",
        "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "    context = self.text_processor(texts).to_tensor()\n",
        "    context = self(context)\n",
        "    return context\n",
        "\n",
        "UNITS = 256\n",
        "\n",
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "  print(ex_context_tok[0, :10].numpy()) \n",
        "  print()\n",
        "  print(ex_tar_in[0, :10].numpy()) \n",
        "  print(ex_tar_out[0, :10].numpy()) \n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(abs_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWKtdJ4PIY9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b0e4211-ec3b-423e-b690-d9634b09abce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (16, 223, 256)\n",
            "Target sequence, shape (batch, t, units): (16, 16, 256)\n",
            "Attention result, shape (batch, t, units): (16, 16, 256)\n",
            "Attention weights, shape (batch, t, s):    (16, 16, 223)\n"
          ]
        }
      ],
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n",
        "\n",
        "  def call(self, x, context):\n",
        "    shape_checker = ShapeChecker()\n",
        " \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "    \n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(attn_scores, 'batch heads t s')\n",
        "    \n",
        "    # Cache the attention scores for plotting later.\n",
        "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "    shape_checker(attn_scores, 'batch t s')\n",
        "    self.last_attention_weights = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(tit_text_processor.vocabulary_size(),\n",
        "                                  output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmyB2Y4wIlud"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, text_processor, units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.text_processor = text_processor\n",
        "    self.vocab_size = text_processor.vocabulary_size()\n",
        "    self.word_to_id = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]')\n",
        "    self.id_to_word = tf.keras.layers.StringLookup(\n",
        "        vocabulary=text_processor.get_vocabulary(),\n",
        "        mask_token='', oov_token='[UNK]',\n",
        "        invert=True)\n",
        "    self.start_token = self.word_to_id('[START]')\n",
        "    self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "    self.units = units\n",
        "\n",
        "\n",
        "    # 1. The embedding layer converts token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                               units, mask_zero=True)\n",
        "\n",
        "    # 2. The RNN keeps track of what's been generated so far.\n",
        "    self.rnn = tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = CrossAttention(units)\n",
        "\n",
        "    # 4. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)\n",
        "\n",
        "\n",
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(x, 'batch t')\n",
        "  shape_checker(context, 'batch s units')\n",
        "\n",
        "  # 1. Lookup the embeddings\n",
        "  x = self.embedding(x)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 2. Process the target sequence.\n",
        "  x, state = self.rnn(x, initial_state=state)\n",
        "  shape_checker(x, 'batch t units')\n",
        "\n",
        "  # 3. Use the RNN output as the query for the attention over the context.\n",
        "  x = self.attention(x, context)\n",
        "  self.last_attention_weights = self.attention.last_attention_weights\n",
        "  shape_checker(x, 'batch t units')\n",
        "  shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "  # Step 4. Generate logit predictions for the next token.\n",
        "  logits = self.output_layer(x)\n",
        "  shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "  if return_state:\n",
        "    return logits, state\n",
        "  else:\n",
        "    return logits\n",
        "\n",
        "decoder = Decoder(tit_text_processor, UNITS)\n",
        "logits = decoder(ex_context, ex_tar_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEvEyuBiIvR_"
      },
      "outputs": [],
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "  batch_size = tf.shape(context)[0]\n",
        "  start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "  embedded = self.embedding(start_tokens)\n",
        "  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]\n",
        "\n",
        "\n",
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "  words = self.id_to_word(tokens)\n",
        "  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "  return result\n",
        "\n",
        "\n",
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "  logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "  if temperature == 0.0:\n",
        "    next_token = tf.argmax(logits, axis=-1)\n",
        "  else:\n",
        "    logits = logits[:, -1, :]/temperature\n",
        "    next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "  # If a sequence produces an `end_token`, set it `done`\n",
        "  done = done | (next_token == self.end_token)\n",
        "  # Once a sequence is done it only produces 0-padding.\n",
        "  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "  \n",
        "  return next_token, done, state\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJfnv6diIv9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6dfaaa-a4e9-4175-b252-e73f48ae926b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'c-rater tabular interpretable transitivity out portability vocabulary open bag-of-opinions self-training',\n",
              "       b'mathias soufian metadata modernizing topic-based adaptive & ambiguities slovene (',\n",
              "       b'la assignment variation terms verification kurosawa clarification peng tor method'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ],
      "source": [
        "# Generation loop\n",
        "\n",
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EusdLzuIK2I1"
      },
      "outputs": [],
      "source": [
        "class SummarisationModel(tf.keras.Model):\n",
        "  @classmethod\n",
        "  def add_method(cls, fun):\n",
        "    setattr(cls, fun.__name__, fun)\n",
        "    return fun\n",
        "\n",
        "  def __init__(self, units,\n",
        "               context_text_processor,\n",
        "               target_text_processor):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(context_text_processor, units)\n",
        "    decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def call(self, inputs):\n",
        "    context, x = inputs\n",
        "    context = self.encoder(context)\n",
        "    logits = self.decoder(context, x)\n",
        "\n",
        "    #TODO(b/250038731): remove this\n",
        "    try:\n",
        "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhJV6mg-K7FY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dc1494-f7f3-4467-fc17-1dd35ed5cf71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (16, 223)\n",
            "Target tokens, shape: (batch, t) (16, 16)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (16, 16, 1807)\n"
          ]
        }
      ],
      "source": [
        "model = SummarisationModel(UNITS, abs_text_processor, tit_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-x8BU8oLN1D"
      },
      "outputs": [],
      "source": [
        "def masked_loss(label, pred):\n",
        "    mask = label != 0\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "    loss = loss_object(label, pred)\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask\n",
        "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "    return loss\n",
        "def masked_acc(label, pred):\n",
        "    pred = tf.argmax(pred, axis=2)\n",
        "    label = tf.cast(label, pred.dtype)\n",
        "    match = label == pred\n",
        "    mask = label != 0\n",
        "    match = match & mask\n",
        "    match = tf.cast(match, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
        "model.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer='adam',\n",
        "    metrics=[masked_acc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-PvstfpPAC3"
      },
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "model.compile(optimizer='adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIJLxTLdJPts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15366a44-42dd-462e-c6e6-4bf6b606f295"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 7.4994235, 'expected_acc': 0.0005534034311012728}"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ],
      "source": [
        "vocab_size = 1.0 * tit_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.evaluate(val_ds, steps=20, return_dict=True)"
      ],
      "metadata": {
        "id": "0-TazbuZWptd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLQEOBueJRnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d4a749-5792-4eac-bec2-28012116229f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "100/100 [==============================] - 29s 165ms/step - loss: 5.7102 - masked_acc: 0.1545 - masked_loss: 5.7008 - val_loss: 6.2495 - val_masked_acc: 0.1563 - val_masked_loss: 6.2496\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 15s 147ms/step - loss: 3.3378 - masked_acc: 0.4212 - masked_loss: 3.2923 - val_loss: 6.5437 - val_masked_acc: 0.1512 - val_masked_loss: 6.5436\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 1.6526 - masked_acc: 0.7124 - masked_loss: 1.6144 - val_loss: 6.9989 - val_masked_acc: 0.1383 - val_masked_loss: 6.9988\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.8980 - masked_acc: 0.8464 - masked_loss: 0.8852 - val_loss: 7.4950 - val_masked_acc: 0.1245 - val_masked_loss: 7.4947\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.6124 - masked_acc: 0.8809 - masked_loss: 0.6025 - val_loss: 8.1069 - val_masked_acc: 0.1327 - val_masked_loss: 8.1068\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.3410 - masked_acc: 0.9346 - masked_loss: 0.3321 - val_loss: 8.3028 - val_masked_acc: 0.1396 - val_masked_loss: 8.3026\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 0.1622 - masked_acc: 0.9775 - masked_loss: 0.1586 - val_loss: 8.6193 - val_masked_acc: 0.1216 - val_masked_loss: 8.6191\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.0441 - masked_acc: 0.9979 - masked_loss: 0.0433 - val_loss: 8.8400 - val_masked_acc: 0.1297 - val_masked_loss: 8.8398\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 10s 105ms/step - loss: 0.0179 - masked_acc: 0.9995 - masked_loss: 0.0175 - val_loss: 9.0082 - val_masked_acc: 0.1322 - val_masked_loss: 9.0080\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0138 - masked_acc: 0.9994 - masked_loss: 0.0135 - val_loss: 9.1267 - val_masked_acc: 0.1304 - val_masked_loss: 9.1265\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.0102 - masked_acc: 0.9995 - masked_loss: 0.0100 - val_loss: 9.2256 - val_masked_acc: 0.1302 - val_masked_loss: 9.2254\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0082 - masked_acc: 0.9997 - masked_loss: 0.0080 - val_loss: 9.3165 - val_masked_acc: 0.1296 - val_masked_loss: 9.3162\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0071 - masked_acc: 0.9996 - masked_loss: 0.0069 - val_loss: 9.3928 - val_masked_acc: 0.1294 - val_masked_loss: 9.3925\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0057 - masked_acc: 0.9998 - masked_loss: 0.0056 - val_loss: 9.4762 - val_masked_acc: 0.1294 - val_masked_loss: 9.4759\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0048 - masked_acc: 0.9998 - masked_loss: 0.0047 - val_loss: 9.5283 - val_masked_acc: 0.1278 - val_masked_loss: 9.5280\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0045 - masked_acc: 0.9998 - masked_loss: 0.0044 - val_loss: 9.5937 - val_masked_acc: 0.1277 - val_masked_loss: 9.5934\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 0.0040 - masked_acc: 0.9998 - masked_loss: 0.0039 - val_loss: 9.6599 - val_masked_acc: 0.1279 - val_masked_loss: 9.6597\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 0.0035 - masked_acc: 0.9998 - masked_loss: 0.0034 - val_loss: 9.7274 - val_masked_acc: 0.1280 - val_masked_loss: 9.7271\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.0030 - masked_acc: 0.9999 - masked_loss: 0.0029 - val_loss: 9.7973 - val_masked_acc: 0.1278 - val_masked_loss: 9.7970\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.0027 - masked_acc: 0.9998 - masked_loss: 0.0027 - val_loss: 9.8377 - val_masked_acc: 0.1269 - val_masked_loss: 9.8374\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.0026 - masked_acc: 0.9999 - masked_loss: 0.0026 - val_loss: 9.8788 - val_masked_acc: 0.1259 - val_masked_loss: 9.8785\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.0023 - masked_acc: 0.9999 - masked_loss: 0.0023 - val_loss: 9.9708 - val_masked_acc: 0.1278 - val_masked_loss: 9.9705\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.0022 - masked_acc: 0.9999 - masked_loss: 0.0021 - val_loss: 9.9585 - val_masked_acc: 0.1251 - val_masked_loss: 9.9582\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.0022 - masked_acc: 0.9998 - masked_loss: 0.0021 - val_loss: 10.0437 - val_masked_acc: 0.1275 - val_masked_loss: 10.0434\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 0.0018 - masked_acc: 0.9998 - masked_loss: 0.0018 - val_loss: 10.1030 - val_masked_acc: 0.1270 - val_masked_loss: 10.1027\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=25,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    # callbacks=[ tf.keras.callbacks.EarlyStopping(patience=3) ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_ds, steps=20, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLQJ6KTbWHTY",
        "outputId": "b2a2c02e-15b5-402b-b022-b92154b6f750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 1s 24ms/step - loss: 10.1910 - masked_acc: 0.1272 - masked_loss: 10.1910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 10.190996170043945,\n",
              " 'masked_acc': 0.1272369772195816,\n",
              " 'masked_loss': 10.190996170043945}"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdD7mDuaPZXl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d62f5501-b2d7-4d8c-9c10-511e373758a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1dbdd9e700>"
            ]
          },
          "metadata": {},
          "execution_count": 287
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}